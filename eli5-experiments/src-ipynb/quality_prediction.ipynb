{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Related works:\n",
    "    - Dialogue-Act Prediction of Future Responses based on Conversation History (http://aclanthology.lst.uni-saarland.de/P19-2027.pdf)\n",
    "    - DeliData: A dataset for deliberation in multi-party problem solving (https://arxiv.org/pdf/2108.05271.pdf)\n",
    "    - Identifying Agreement/Disagreement in Conversational Speech: A Cross-lingual Study (https://www.sri.com/wp-content/uploads/2021/12/identifying_agreement-disagreement_in_conversational_speech.pdf)\n",
    "    - The Role of Conversational Structure in Agreement and Disagreement Detection in Online Discussions (https://aclanthology.org/W15-4625.pdf)\n",
    "    - Modeling Long-Range Context for Concurrent Dialogue Acts Recognition https://arxiv.org/pdf/1909.00521.pdf\n",
    "    - User Satisfaction Estimation with Sequential Dialogue Act Modeling in Goal-oriented Conversational Systems https://arxiv.org/pdf/2202.02912.pdf\n",
    "    - \n",
    "\n",
    "- Implementatoin based on https://github.com/coastalcph/hierarchical-transformers and LongFormer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Experiments:\n",
    "    - Predict understanding vs non-understanding signals in dialogue -> That indicates quality of explanation (baseline)\n",
    "    - LongFormer that consumes all the text up to window_size and predict the quality\n",
    "    - Modeling quality by the degree of non-understanding explanation_moves in the dialogue: Average probability of all uternaces of being a non-understanding explanation move.\n",
    "    - RQ: Can we predict ahead whether the dialogue will lead to non-understanding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "sys.path.insert(0, '../src-py')\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "\n",
    "#wandb.init(project=\"test-project\", entity=\"milad-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob \n",
    "from tabulate import tabulate\n",
    "import math\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_df(path, quality_df_path):\n",
    "    eli5_df  = pd.read_pickle(path)\n",
    "    eli5_dlg_quality_df = pd.read_csv(quality_df_path)\n",
    "    quality_scores = pd.Series(eli5_dlg_quality_df.rating_label.values, index = eli5_dlg_quality_df.task_id).to_dict()\n",
    "    \n",
    "    eli5_df = eli5_df.groupby('task_id').agg({'turn_text': lambda rows: list(rows),\n",
    "                                          'topic': lambda rows: list(rows)[0],\n",
    "                                          'topic_func_label': lambda rows: list(rows),\n",
    "                                          'dlg_act_label': lambda rows: list(rows),\n",
    "                                          'exp_type_label' : lambda rows: list(rows),\n",
    "                                          'exp_act_label': lambda rows: list(rows)}).reset_index()\n",
    "\n",
    "    eli5_df['labels'] = eli5_df.task_id.apply(lambda x: quality_scores[x])\n",
    "    eli5_df['input_texts'] = eli5_df.turn_text.apply(lambda row: [x['text'] for x in row])\n",
    "\n",
    "    eli5_df['exp_act_label'] =  eli5_df['exp_act_label'].apply(lambda row: [int(x[2:4]) for x in row])\n",
    "    eli5_df['dlg_act_label'] =  eli5_df['dlg_act_label'].apply(lambda row: [int(x[2:4]) for x in row])\n",
    "    eli5_df['topic_func_label'] =  eli5_df['topic_func_label'].apply(lambda row: [int(x[2:4]) for x in row])\n",
    "\n",
    "    print('Maximum seq num:', max([len(x) for x in eli5_df.input_texts.tolist()]))\n",
    "    print('Maximum seq len:', max([len(turn.split(' ')) for turns in eli5_df.input_texts.tolist() for turn in turns]))\n",
    "    print('Data size:', len(eli5_df))\n",
    "    return eli5_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experiments on HIT models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../../../third-party/hierarchical-transformers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "from models.hat import HATConfig, HATTokenizer, HATForSequenceClassification\n",
    "from models.longformer import LongformerTokenizer, LongformerModelForSequenceClassification\n",
    "from language_modelling.data_collator import DataCollatorForDocumentClassification\n",
    "from datasets import load_dataset, Dataset, load_metric\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5_training_df= load_and_prepare_df('../../data/eli5_ds/annotation-results/MACE-measure/final_mace_predictions_training.pkl', '../../data/eli5_ds/annotation-results/MACE-measure/final_mace_rating_predictions.csv')\n",
    "eli5_testing_df = load_and_prepare_df('../../data/eli5_ds/annotation-results/MACE-measure/final_mace_predictions_testing.pkl', '../../data/eli5_ds/annotation-results/MACE-measure/final_mace_rating_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path = 'kiddothe2b/hierarchical-transformer-base-4096'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_hat_model(model_name_or_path, output_dir, df, wandb_run_name, input_clm='turn_text', \n",
    "                                 num_train_epochs=5, eval_steps=500, lr=2e-6, batch_size=4, \n",
    "                                 max_seq_length=256, max_num_sequences=40, extra_encoder_configs=[]):\n",
    "\n",
    "\n",
    "    model_revision=\"main\"\n",
    "    do_lower_case=False\n",
    "    pooling=\"max\" #Which pooling method to use (max, cls, attentive)\n",
    "\n",
    "    config = HATConfig.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        num_labels=1,\n",
    "        finetuning_task=\"document-classification\",\n",
    "        revision=\"main\",\n",
    "        use_auth_token=None\n",
    "    )\n",
    "\n",
    "    tokenizer = HATTokenizer.from_pretrained(\n",
    "        model_name_or_path,\n",
    "        do_lower_case=False,\n",
    "        revision=model_revision,\n",
    "        use_auth_token=None,\n",
    "    )\n",
    "\n",
    "    wandb.init(settings=wandb.Settings(start_method=\"fork\"), project=\"test-project\", entity=\"milad-it\", name='{}-hat-former'.format(wandb_run_name))\n",
    "\n",
    "    rmse_scores = []\n",
    "\n",
    "    \n",
    "    #split by topic\n",
    "    topics  = df.topic.unique()\n",
    "    train_topics, test_topics  = train_test_split(topics, test_size=0.2, shuffle=True, random_state=123)\n",
    "    train_topics, valid_topics = train_test_split(train_topics, test_size=0.2, shuffle=True, random_state=123)\n",
    "    \n",
    "    train_df = df[df.topic.isin(train_topics)]\n",
    "    valid_df = df[df.topic.isin(valid_topics)]\n",
    "    test_df  = df[df.topic.isin(test_topics)]\n",
    "    \n",
    "    #balance the data\n",
    "    train_df, y = ros.fit_resample(train_df, train_df['labels'])\n",
    "    train_df['labels'] = y\n",
    "    print(train_df.labels.value_counts())\n",
    "\n",
    "    training_ds = Dataset.from_pandas(train_df)\n",
    "    valid_ds    = Dataset.from_pandas(valid_df)\n",
    "    test_ds     = Dataset.from_pandas(test_df)\n",
    "\n",
    "    training_ds = training_ds.map(lambda examples: preprocess_hat_function(tokenizer, examples, max_seq_length, False), \n",
    "                        batched=True, load_from_cache_file=False, remove_columns=['labels'])\n",
    "    valid_ds    = valid_ds.map(lambda examples: preprocess_hat_function(tokenizer, examples, max_seq_length, False), \n",
    "                        batched=True, load_from_cache_file=False, remove_columns=['labels'])\n",
    "    test_ds     = test_ds.map(lambda examples: preprocess_hat_function(tokenizer, examples, max_seq_length, False), \n",
    "                        batched=True, load_from_cache_file=False, remove_columns=['labels'])\n",
    "\n",
    "    print('Training {}, Valid {}, and Test {}'.format(len(training_ds), len(valid_ds), len(test_ds)))\n",
    "\n",
    "    if extra_encoder_configs != []:\n",
    "        model = MyHATForSequenceClassification.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            pooling=pooling,\n",
    "            config=config,\n",
    "            revision=model_revision,\n",
    "            use_auth_token=None,\n",
    "            extra_encoders_configs=extra_encoder_configs)\n",
    "    else:\n",
    "        model = HATForSequenceClassification.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            pooling=pooling,\n",
    "            config=config,\n",
    "            revision=model_revision,\n",
    "            use_auth_token=None\n",
    "        )\n",
    "\n",
    "\n",
    "    args = TrainingArguments(\n",
    "            output_dir= '{}/{}/-{}-fold'.format(output_dir, wandb_run_name, 0),\n",
    "            overwrite_output_dir=True,\n",
    "            evaluation_strategy = \"steps\",\n",
    "            save_strategy = \"steps\",\n",
    "            logging_strategy=\"steps\",\n",
    "            save_total_limit=5,\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            weight_decay=0.01,\n",
    "            eval_steps=eval_steps,\n",
    "            logging_steps=eval_steps,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model='rmse'\n",
    "        )\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=training_ds,\n",
    "        eval_dataset=valid_ds,\n",
    "        compute_metrics=lambda x: compute_metrics(x),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_results = trainer.evaluate(test_ds)\n",
    "    wandb.log(eval_results)\n",
    "    rmse_scores.append(eval_results['eval_rmse'])\n",
    "    model.save_pretrained('{}/{}/{}-fold'.format(output_dir, wandb_run_name, 0))\n",
    "    test_ds.to_json('{}/{}/{}-fold/test_set.json'.format(output_dir, wandb_run_name, 0))\n",
    "    json.dump(eval_results, open('{}/{}/{}-fold/eval_results.json'.format(output_dir, wandb_run_name, 0), 'w'))\n",
    "\n",
    "    wandb.finish()\n",
    "        \n",
    "    return rmse_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train the basic hat model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmiladalsh-it\u001b[0m (\u001b[33mmilad-it\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_171940-6jtsziit</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/6jtsziit\" target=\"_blank\">hat-model-test-no-encoder-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function train_and_evaluate_hat_model.<locals>.<lambda> at 0x7f338593fd30> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ec2095e482496a855e3852c59cbf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9470f53b49984b6ca58edde21578ca07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "265a2f51a0674f148273cf46bb9ed13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing HATForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing HATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set  don't have a corresponding argument in `HATForSequenceClassification.forward` and have been ignored: input_texts, topic. If input_texts, topic are not expected by `HATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.381000</td>\n",
       "      <td>2.341297</td>\n",
       "      <td>1.530130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.880400</td>\n",
       "      <td>2.119221</td>\n",
       "      <td>1.455754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.246500</td>\n",
       "      <td>2.027580</td>\n",
       "      <td>1.423931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.937100</td>\n",
       "      <td>1.980022</td>\n",
       "      <td>1.407133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.742300</td>\n",
       "      <td>1.988872</td>\n",
       "      <td>1.410274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `HATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic. If __index_level_0__, input_texts, topic are not expected by `HATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `HATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic. If __index_level_0__, input_texts, topic are not expected by `HATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `HATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic. If __index_level_0__, input_texts, topic are not expected by `HATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `HATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic. If __index_level_0__, input_texts, topic are not expected by `HATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `HATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic. If __index_level_0__, input_texts, topic are not expected by `HATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `HATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic. If __index_level_0__, input_texts, topic are not expected by `HATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-no-encoder/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-no-encoder/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9594314678d24cce89c3f887604c7fce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>▆▃▂▁▁█</td></tr><tr><td>eval/rmse</td><td>▆▃▂▁▁█</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▇▇██▇▁</td></tr><tr><td>eval/steps_per_second</td><td>████▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.49152</td></tr><tr><td>eval/rmse</td><td>1.57846</td></tr><tr><td>eval/runtime</td><td>0.7282</td></tr><tr><td>eval/samples_per_second</td><td>102.989</td></tr><tr><td>eval/steps_per_second</td><td>13.732</td></tr><tr><td>eval_loss</td><td>2.49152</td></tr><tr><td>eval_rmse</td><td>1.57846</td></tr><tr><td>eval_runtime</td><td>0.7282</td></tr><tr><td>eval_samples_per_second</td><td>102.989</td></tr><tr><td>eval_steps_per_second</td><td>13.732</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7423</td></tr><tr><td>train/total_flos</td><td>2682215990756352.0</td></tr><tr><td>train/train_loss</td><td>1.40005</td></tr><tr><td>train/train_runtime</td><td>80.0769</td></tr><tr><td>train/train_samples_per_second</td><td>25.6</td></tr><tr><td>train/train_steps_per_second</td><td>3.247</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-no-encoder-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/6jtsziit\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/6jtsziit</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_171940-6jtsziit/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_types_rmse_scores = train_and_evaluate_hat_model(model_name_or_path, '../data/quality_models/hat-models/', \n",
    "                                                     eli5_annotation_df[['topic', 'input_texts', 'labels']], 'hat-model-test-no-encoder',\n",
    "                                                     extra_encoder_configs=[],\n",
    "                                                     num_train_epochs=5, lr=2e-5, batch_size=8,  eval_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5784554481506348"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(exp_types_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train with features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_172125-3vgvylis</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/3vgvylis\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00f3839499e46cda1c29335502b495d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325aa7fdbd7545dda462c7d878f5e740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39be8de72c14863922479b682c6fbbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: input_texts, exp_act_label, topic. If input_texts, exp_act_label, topic are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.339000</td>\n",
       "      <td>2.359891</td>\n",
       "      <td>1.536194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.764900</td>\n",
       "      <td>1.548875</td>\n",
       "      <td>1.244538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.128900</td>\n",
       "      <td>1.620993</td>\n",
       "      <td>1.273182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>1.287212</td>\n",
       "      <td>1.134554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.612300</td>\n",
       "      <td>1.324992</td>\n",
       "      <td>1.151083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, exp_act_label, topic. If __index_level_0__, input_texts, exp_act_label, topic are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, exp_act_label, topic. If __index_level_0__, input_texts, exp_act_label, topic are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, exp_act_label, topic. If __index_level_0__, input_texts, exp_act_label, topic are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, exp_act_label, topic. If __index_level_0__, input_texts, exp_act_label, topic are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, exp_act_label, topic. If __index_level_0__, input_texts, exp_act_label, topic are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, exp_act_label, topic. If __index_level_0__, input_texts, exp_act_label, topic are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de9e0f6c695420086391d4419e8711c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▃▁▁▅</td></tr><tr><td>eval/rmse</td><td>█▃▃▁▁▅</td></tr><tr><td>eval/runtime</td><td>▁▁█▁▁▄</td></tr><tr><td>eval/samples_per_second</td><td>██▁██▅</td></tr><tr><td>eval/steps_per_second</td><td>██▁██▄</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.86868</td></tr><tr><td>eval/rmse</td><td>1.367</td></tr><tr><td>eval/runtime</td><td>0.7247</td></tr><tr><td>eval/samples_per_second</td><td>103.494</td></tr><tr><td>eval/steps_per_second</td><td>13.799</td></tr><tr><td>eval_loss</td><td>1.86868</td></tr><tr><td>eval_rmse</td><td>1.367</td></tr><tr><td>eval_runtime</td><td>0.7247</td></tr><tr><td>eval_samples_per_second</td><td>103.494</td></tr><tr><td>eval_steps_per_second</td><td>13.799</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6123</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.30108</td></tr><tr><td>train/train_runtime</td><td>76.9555</td></tr><tr><td>train/train_samples_per_second</td><td>26.639</td></tr><tr><td>train/train_steps_per_second</td><td>3.379</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/3vgvylis\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/3vgvylis</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_172125-3vgvylis/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_scores = train_and_evaluate_hat_model(model_name_or_path, '../data/quality_models/hat-models/', \n",
    "                                         eli5_annotation_df[['topic', 'input_texts', 'exp_act_label', 'labels']], 'hat-model-test-with-exp-moves-encoder',\n",
    "                                         extra_encoder_configs=[{'num_tokens':11, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3}],\n",
    "                                         num_train_epochs=5, lr=2e-5, batch_size=8,  eval_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.366997480392456"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_172303-1b9izw9n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1b9izw9n\" target=\"_blank\">hat-model-test-with-dlg-act-encoder-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639ec883ec3541b7b4903287f685f072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dlg_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329d9311f124412d9cc22a1ed159260e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dlg_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acab4de39e048d1995c04c347d3fa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dlg_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: input_texts, topic, dlg_act_label. If input_texts, topic, dlg_act_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.316800</td>\n",
       "      <td>2.244183</td>\n",
       "      <td>1.498060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.746800</td>\n",
       "      <td>1.597429</td>\n",
       "      <td>1.263894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.013200</td>\n",
       "      <td>1.474707</td>\n",
       "      <td>1.214375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.765300</td>\n",
       "      <td>1.546335</td>\n",
       "      <td>1.243517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.530800</td>\n",
       "      <td>1.470122</td>\n",
       "      <td>1.212486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, dlg_act_label. If __index_level_0__, input_texts, topic, dlg_act_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, dlg_act_label. If __index_level_0__, input_texts, topic, dlg_act_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, dlg_act_label. If __index_level_0__, input_texts, topic, dlg_act_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, dlg_act_label. If __index_level_0__, input_texts, topic, dlg_act_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, dlg_act_label. If __index_level_0__, input_texts, topic, dlg_act_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, dlg_act_label. If __index_level_0__, input_texts, topic, dlg_act_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-dlg-act-encoder/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-dlg-act-encoder/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f327ae7d28bb46d1b93d3d9872b60024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▁▂▁▅</td></tr><tr><td>eval/rmse</td><td>█▂▁▂▁▆</td></tr><tr><td>eval/runtime</td><td>▃▅▁▃▄█</td></tr><tr><td>eval/samples_per_second</td><td>▃▁▅▃▂█</td></tr><tr><td>eval/steps_per_second</td><td>▆▄█▆▅▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.95688</td></tr><tr><td>eval/rmse</td><td>1.39889</td></tr><tr><td>eval/runtime</td><td>0.5836</td></tr><tr><td>eval/samples_per_second</td><td>128.522</td></tr><tr><td>eval/steps_per_second</td><td>17.136</td></tr><tr><td>eval_loss</td><td>1.95688</td></tr><tr><td>eval_rmse</td><td>1.39889</td></tr><tr><td>eval_runtime</td><td>0.5836</td></tr><tr><td>eval_samples_per_second</td><td>128.522</td></tr><tr><td>eval_steps_per_second</td><td>17.136</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5308</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.24525</td></tr><tr><td>train/train_runtime</td><td>76.8822</td></tr><tr><td>train/train_samples_per_second</td><td>26.664</td></tr><tr><td>train/train_steps_per_second</td><td>3.382</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-dlg-act-encoder-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1b9izw9n\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1b9izw9n</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_172303-1b9izw9n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_scores = train_and_evaluate_hat_model(model_name_or_path, '../data/quality_models/hat-models/', \n",
    "                                         eli5_annotation_df[['topic', 'input_texts', 'dlg_act_label', 'labels']], 'hat-model-test-with-dlg-act-encoder',\n",
    "                                         extra_encoder_configs=[{'num_tokens':11, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3}],\n",
    "                                         num_train_epochs=5, lr=2e-5, batch_size=8,  eval_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3988869190216064"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_172440-1vynbbaf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1vynbbaf\" target=\"_blank\">hat-model-test-with-topic-dist-encoder-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4502c1c385a4496bbf8569d6b7dcc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding topic_func_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a0c9e343bb414fa91ad25840e0c22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding topic_func_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc5dc245c9f4f0786737683cda57ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding topic_func_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 5, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: input_texts, topic, topic_func_label. If input_texts, topic, topic_func_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.603000</td>\n",
       "      <td>2.392323</td>\n",
       "      <td>1.546713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.924200</td>\n",
       "      <td>2.100353</td>\n",
       "      <td>1.449260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.490600</td>\n",
       "      <td>1.736596</td>\n",
       "      <td>1.317800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.165100</td>\n",
       "      <td>1.548130</td>\n",
       "      <td>1.244239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.886100</td>\n",
       "      <td>1.490147</td>\n",
       "      <td>1.220716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, topic_func_label. If __index_level_0__, input_texts, topic, topic_func_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, topic_func_label. If __index_level_0__, input_texts, topic, topic_func_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, topic_func_label. If __index_level_0__, input_texts, topic, topic_func_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, topic_func_label. If __index_level_0__, input_texts, topic, topic_func_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, topic_func_label. If __index_level_0__, input_texts, topic, topic_func_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, input_texts, topic, topic_func_label. If __index_level_0__, input_texts, topic, topic_func_label are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-topic-dist-encoder/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-topic-dist-encoder/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89abc4ec5cac4ce2b44af2a78f958967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▆▃▁▁▇</td></tr><tr><td>eval/rmse</td><td>█▆▃▂▁▇</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▇███▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇███▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.27802</td></tr><tr><td>eval/rmse</td><td>1.50931</td></tr><tr><td>eval/runtime</td><td>1.2177</td></tr><tr><td>eval/samples_per_second</td><td>61.593</td></tr><tr><td>eval/steps_per_second</td><td>8.212</td></tr><tr><td>eval_loss</td><td>2.27802</td></tr><tr><td>eval_rmse</td><td>1.50931</td></tr><tr><td>eval_runtime</td><td>1.2177</td></tr><tr><td>eval_samples_per_second</td><td>61.593</td></tr><tr><td>eval_steps_per_second</td><td>8.212</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8861</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.57358</td></tr><tr><td>train/train_runtime</td><td>83.4819</td></tr><tr><td>train/train_samples_per_second</td><td>24.556</td></tr><tr><td>train/train_steps_per_second</td><td>3.114</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-topic-dist-encoder-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1vynbbaf\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1vynbbaf</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_172440-1vynbbaf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_scores = train_and_evaluate_hat_model(model_name_or_path, '../data/quality_models/hat-models/', \n",
    "                                         eli5_annotation_df[['topic', 'input_texts', 'topic_func_label', 'labels']], 'hat-model-test-with-topic-dist-encoder',\n",
    "                                         extra_encoder_configs=[{'num_tokens':5, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3}],\n",
    "                                         num_train_epochs=5, lr=2e-5, batch_size=8,  eval_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.509312391281128\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_172625-10sm940h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/10sm940h\" target=\"_blank\">hat-model-test-all-encoder-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693ddcaefa3f4428acc7a1ff539329c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "adding dlg_act_label to the flows\n",
      "adding topic_func_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5e57074e384e6dad47204400608009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "adding dlg_act_label to the flows\n",
      "adding topic_func_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f19e32ddd1c49c487c384f815823c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "adding dlg_act_label to the flows\n",
      "adding topic_func_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}, {'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}, {'num_tokens': 5, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['pooler.dense.bias', 'classifier.weight', 'pooler.dense.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, dlg_act_label, topic_func_label, exp_act_label, input_texts. If topic, dlg_act_label, topic_func_label, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.659600</td>\n",
       "      <td>2.267148</td>\n",
       "      <td>1.505705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.945900</td>\n",
       "      <td>1.951925</td>\n",
       "      <td>1.397113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.555300</td>\n",
       "      <td>1.803087</td>\n",
       "      <td>1.342791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.141600</td>\n",
       "      <td>1.401359</td>\n",
       "      <td>1.183790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.920200</td>\n",
       "      <td>1.475539</td>\n",
       "      <td>1.214718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts. If __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts. If __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts. If __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts. If __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts. If __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts. If __index_level_0__, topic, dlg_act_label, topic_func_label, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-all-encoder/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-all-encoder/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a2f330345a4c838ab8ecaee9b6c18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▅▄▁▂▆</td></tr><tr><td>eval/rmse</td><td>█▆▄▁▂▆</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▄▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.97364</td></tr><tr><td>eval/rmse</td><td>1.40486</td></tr><tr><td>eval/runtime</td><td>1.439</td></tr><tr><td>eval/samples_per_second</td><td>52.118</td></tr><tr><td>eval/steps_per_second</td><td>6.949</td></tr><tr><td>eval_loss</td><td>1.97364</td></tr><tr><td>eval_rmse</td><td>1.40486</td></tr><tr><td>eval_runtime</td><td>1.439</td></tr><tr><td>eval_samples_per_second</td><td>52.118</td></tr><tr><td>eval_steps_per_second</td><td>6.949</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.9202</td></tr><tr><td>train/total_flos</td><td>2682234060604416.0</td></tr><tr><td>train/train_loss</td><td>1.61142</td></tr><tr><td>train/train_runtime</td><td>89.7439</td></tr><tr><td>train/train_samples_per_second</td><td>22.843</td></tr><tr><td>train/train_steps_per_second</td><td>2.897</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-all-encoder-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/10sm940h\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/10sm940h</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_172625-10sm940h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_scores = train_and_evaluate_hat_model(model_name_or_path, '../data/quality_models/hat-models/', \n",
    "                                         eli5_annotation_df[['topic', 'input_texts', 'exp_act_label', 'dlg_act_label' , 'topic_func_label', 'labels']], 'hat-model-test-all-encoder',\n",
    "                                         extra_encoder_configs=[\n",
    "                                             {'num_tokens':11, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3},\n",
    "                                             {'num_tokens':11, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3},\n",
    "                                             {'num_tokens':5, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3}],\n",
    "                                         num_train_epochs=5, lr=2e-5, batch_size=8,  eval_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4048638343811035\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(rmse_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fine-tuning different parameters of the encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_011726-xho481ow</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/xho481ow\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-64-1-3-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b3ad52bf8642e2b4598e71ab5e97aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2304b06e56b448491ea7c66afb4b045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90a3b5bceb846f0a1853d1230395f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 64, 'nhead': 1, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.389100</td>\n",
       "      <td>2.214026</td>\n",
       "      <td>1.487960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.722700</td>\n",
       "      <td>1.988444</td>\n",
       "      <td>1.410122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.132800</td>\n",
       "      <td>1.474364</td>\n",
       "      <td>1.214234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.775100</td>\n",
       "      <td>1.535385</td>\n",
       "      <td>1.239107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.601800</td>\n",
       "      <td>1.551808</td>\n",
       "      <td>1.245716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-1-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-1-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2db6a475bb643398cbaa03bdd6f4e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▆▁▂▂▇</td></tr><tr><td>eval/rmse</td><td>█▆▁▂▂▇</td></tr><tr><td>eval/runtime</td><td>▂▃▁▄▁█</td></tr><tr><td>eval/samples_per_second</td><td>▇▆▇▅█▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▆▇▅█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.144</td></tr><tr><td>eval/rmse</td><td>1.46424</td></tr><tr><td>eval/runtime</td><td>0.676</td></tr><tr><td>eval/samples_per_second</td><td>110.943</td></tr><tr><td>eval/steps_per_second</td><td>14.792</td></tr><tr><td>eval_loss</td><td>2.144</td></tr><tr><td>eval_rmse</td><td>1.46424</td></tr><tr><td>eval_runtime</td><td>0.676</td></tr><tr><td>eval_samples_per_second</td><td>110.943</td></tr><tr><td>eval_steps_per_second</td><td>14.792</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6018</td></tr><tr><td>train/total_flos</td><td>2682217496577024.0</td></tr><tr><td>train/train_loss</td><td>1.29184</td></tr><tr><td>train/train_runtime</td><td>74.7121</td></tr><tr><td>train/train_samples_per_second</td><td>27.439</td></tr><tr><td>train/train_steps_per_second</td><td>3.48</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-64-1-3-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/xho481ow\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/xho481ow</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_011726-xho481ow/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_011858-11oxqhbp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/11oxqhbp\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-64-1-6-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada022f6fb974b19a126c4a891e4f4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc513190f1b4a7da3828d01c06811ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36c22dca59040d682b2341ef5102e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 64, 'nhead': 1, 'nlayers': 6}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.377400</td>\n",
       "      <td>2.273475</td>\n",
       "      <td>1.507805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.827500</td>\n",
       "      <td>1.685358</td>\n",
       "      <td>1.298213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.336100</td>\n",
       "      <td>1.571285</td>\n",
       "      <td>1.253509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.957400</td>\n",
       "      <td>1.562912</td>\n",
       "      <td>1.250165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.764400</td>\n",
       "      <td>1.546049</td>\n",
       "      <td>1.243402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-1-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-1-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3bb024949f4dca8885a6525c20e3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▇</td></tr><tr><td>eval/rmse</td><td>█▂▁▁▁▇</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.13926</td></tr><tr><td>eval/rmse</td><td>1.46262</td></tr><tr><td>eval/runtime</td><td>0.8173</td></tr><tr><td>eval/samples_per_second</td><td>91.77</td></tr><tr><td>eval/steps_per_second</td><td>12.236</td></tr><tr><td>eval_loss</td><td>2.13926</td></tr><tr><td>eval_rmse</td><td>1.46262</td></tr><tr><td>eval_runtime</td><td>0.8173</td></tr><tr><td>eval_samples_per_second</td><td>91.77</td></tr><tr><td>eval_steps_per_second</td><td>12.236</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7644</td></tr><tr><td>train/total_flos</td><td>2682217496577024.0</td></tr><tr><td>train/train_loss</td><td>1.41822</td></tr><tr><td>train/train_runtime</td><td>77.6158</td></tr><tr><td>train/train_samples_per_second</td><td>26.412</td></tr><tr><td>train/train_steps_per_second</td><td>3.35</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-64-1-6-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/11oxqhbp\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/11oxqhbp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_011858-11oxqhbp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_012033-2utp04fs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/2utp04fs\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-64-1-12-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5ad851c6fc4af2b35accc3d4ce73ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa940f1d795a46049cc918222e9ba931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233ee33ff1fa4c169f88174f6aae399a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 64, 'nhead': 1, 'nlayers': 12}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.346000</td>\n",
       "      <td>2.219710</td>\n",
       "      <td>1.489869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.848700</td>\n",
       "      <td>1.945488</td>\n",
       "      <td>1.394808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.349600</td>\n",
       "      <td>1.314800</td>\n",
       "      <td>1.146647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.041500</td>\n",
       "      <td>1.367727</td>\n",
       "      <td>1.169499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.734800</td>\n",
       "      <td>1.227403</td>\n",
       "      <td>1.107882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-1-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-1-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c83e940dc809480fb16b0052be48d0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▆▂▂▁▅</td></tr><tr><td>eval/rmse</td><td>█▆▂▂▁▆</td></tr><tr><td>eval/runtime</td><td>▂▂▄▂▁█</td></tr><tr><td>eval/samples_per_second</td><td>▇▆▄▇█▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▆▅▇█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▄▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.85643</td></tr><tr><td>eval/rmse</td><td>1.36251</td></tr><tr><td>eval/runtime</td><td>0.7574</td></tr><tr><td>eval/samples_per_second</td><td>99.028</td></tr><tr><td>eval/steps_per_second</td><td>13.204</td></tr><tr><td>eval_loss</td><td>1.85643</td></tr><tr><td>eval_rmse</td><td>1.36251</td></tr><tr><td>eval_runtime</td><td>0.7574</td></tr><tr><td>eval_samples_per_second</td><td>99.028</td></tr><tr><td>eval_steps_per_second</td><td>13.204</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7348</td></tr><tr><td>train/total_flos</td><td>2682217496577024.0</td></tr><tr><td>train/train_loss</td><td>1.43052</td></tr><tr><td>train/train_runtime</td><td>79.3957</td></tr><tr><td>train/train_samples_per_second</td><td>25.82</td></tr><tr><td>train/train_steps_per_second</td><td>3.275</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-64-1-12-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/2utp04fs\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/2utp04fs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_012033-2utp04fs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_012209-h12iztyl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/h12iztyl\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-64-4-3-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f80e2ac0884b339dbda2bd6f157ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cba24dbf76f4f369a016354589dad8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ac0a65bd8744b2bf3d4f84b766f56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.367700</td>\n",
       "      <td>2.276155</td>\n",
       "      <td>1.508693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.710800</td>\n",
       "      <td>1.628733</td>\n",
       "      <td>1.276218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.127900</td>\n",
       "      <td>1.390385</td>\n",
       "      <td>1.179146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.389496</td>\n",
       "      <td>1.178769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.592700</td>\n",
       "      <td>1.369824</td>\n",
       "      <td>1.170395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-4-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-4-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c874af4729d04d87a191d511f704788f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▁▁▁▆</td></tr><tr><td>eval/rmse</td><td>█▃▁▁▁▆</td></tr><tr><td>eval/runtime</td><td>▁▁▁▃▂█</td></tr><tr><td>eval/samples_per_second</td><td>███▆▇▁</td></tr><tr><td>eval/steps_per_second</td><td>███▆▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.05199</td></tr><tr><td>eval/rmse</td><td>1.43248</td></tr><tr><td>eval/runtime</td><td>0.7327</td></tr><tr><td>eval/samples_per_second</td><td>102.361</td></tr><tr><td>eval/steps_per_second</td><td>13.648</td></tr><tr><td>eval_loss</td><td>2.05199</td></tr><tr><td>eval_rmse</td><td>1.43248</td></tr><tr><td>eval_runtime</td><td>0.7327</td></tr><tr><td>eval_samples_per_second</td><td>102.361</td></tr><tr><td>eval_steps_per_second</td><td>13.648</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5927</td></tr><tr><td>train/total_flos</td><td>2682217496577024.0</td></tr><tr><td>train/train_loss</td><td>1.29053</td></tr><tr><td>train/train_runtime</td><td>74.4635</td></tr><tr><td>train/train_samples_per_second</td><td>27.53</td></tr><tr><td>train/train_steps_per_second</td><td>3.492</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-64-4-3-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/h12iztyl\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/h12iztyl</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_012209-h12iztyl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_012340-2i26yb0e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/2i26yb0e\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-64-4-6-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4572b82baf404d7dad1f139017b11e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec79b5693c54064adbaa9ee316a440e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72441378515940ad910d4e6d62df6b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 6}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.382500</td>\n",
       "      <td>2.195257</td>\n",
       "      <td>1.481640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.806000</td>\n",
       "      <td>1.751876</td>\n",
       "      <td>1.323584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.308000</td>\n",
       "      <td>1.523934</td>\n",
       "      <td>1.234477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.896400</td>\n",
       "      <td>1.582275</td>\n",
       "      <td>1.257885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.761700</td>\n",
       "      <td>1.569348</td>\n",
       "      <td>1.252736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-4-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-4-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2467561c370349f8bae30a0af525d724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▁▂▁▇</td></tr><tr><td>eval/rmse</td><td>█▄▁▂▂▇</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁█▅</td></tr><tr><td>eval/samples_per_second</td><td>████▁▄</td></tr><tr><td>eval/steps_per_second</td><td>████▁▃</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.06384</td></tr><tr><td>eval/rmse</td><td>1.43661</td></tr><tr><td>eval/runtime</td><td>0.6904</td></tr><tr><td>eval/samples_per_second</td><td>108.638</td></tr><tr><td>eval/steps_per_second</td><td>14.485</td></tr><tr><td>eval_loss</td><td>2.06384</td></tr><tr><td>eval_rmse</td><td>1.43661</td></tr><tr><td>eval_runtime</td><td>0.6904</td></tr><tr><td>eval_samples_per_second</td><td>108.638</td></tr><tr><td>eval_steps_per_second</td><td>14.485</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7617</td></tr><tr><td>train/total_flos</td><td>2682217496577024.0</td></tr><tr><td>train/train_loss</td><td>1.39728</td></tr><tr><td>train/train_runtime</td><td>77.8827</td></tr><tr><td>train/train_samples_per_second</td><td>26.322</td></tr><tr><td>train/train_steps_per_second</td><td>3.338</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-64-4-6-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/2i26yb0e\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/2i26yb0e</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_012340-2i26yb0e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_012515-3c4cuq81</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/3c4cuq81\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-64-4-12-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05aa9d0b40db4442954ef1fa2c0ef0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c4b556a792447e943a5b9928694fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61e419fb36e4fd39e986758abc4d22a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 12}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.340100</td>\n",
       "      <td>2.147536</td>\n",
       "      <td>1.465447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.762600</td>\n",
       "      <td>1.606858</td>\n",
       "      <td>1.267619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.206700</td>\n",
       "      <td>1.538208</td>\n",
       "      <td>1.240245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.000600</td>\n",
       "      <td>1.342540</td>\n",
       "      <td>1.158680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.724200</td>\n",
       "      <td>1.638707</td>\n",
       "      <td>1.280120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-4-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-4-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11dd6dc1516494aad9885e8cb8f4f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▃▁▄▇</td></tr><tr><td>eval/rmse</td><td>█▃▃▁▄▇</td></tr><tr><td>eval/runtime</td><td>▂▅▁█▆▆</td></tr><tr><td>eval/samples_per_second</td><td>▆▃▇▁▃█</td></tr><tr><td>eval/steps_per_second</td><td>▇▄█▁▃▃</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.98725</td></tr><tr><td>eval/rmse</td><td>1.4097</td></tr><tr><td>eval/runtime</td><td>0.6349</td></tr><tr><td>eval/samples_per_second</td><td>118.131</td></tr><tr><td>eval/steps_per_second</td><td>15.751</td></tr><tr><td>eval_loss</td><td>1.98725</td></tr><tr><td>eval_rmse</td><td>1.4097</td></tr><tr><td>eval_runtime</td><td>0.6349</td></tr><tr><td>eval_samples_per_second</td><td>118.131</td></tr><tr><td>eval_steps_per_second</td><td>15.751</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7242</td></tr><tr><td>train/total_flos</td><td>2682217496577024.0</td></tr><tr><td>train/train_loss</td><td>1.37345</td></tr><tr><td>train/train_runtime</td><td>82.6321</td></tr><tr><td>train/train_samples_per_second</td><td>24.809</td></tr><tr><td>train/train_steps_per_second</td><td>3.146</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-64-4-12-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/3c4cuq81\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/3c4cuq81</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_012515-3c4cuq81/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_012655-26v8ojuo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/26v8ojuo\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-64-8-3-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71aa9c701eef46bbaa565446f4bb2a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6514dd167d42c8b94b01addb556f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9414a0e5d614782858b726c8bc7f59a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 64, 'nhead': 8, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.381200</td>\n",
       "      <td>2.198632</td>\n",
       "      <td>1.482779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.850200</td>\n",
       "      <td>1.555997</td>\n",
       "      <td>1.247396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>1.471223</td>\n",
       "      <td>1.212940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.985200</td>\n",
       "      <td>1.206376</td>\n",
       "      <td>1.098351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.730100</td>\n",
       "      <td>1.267595</td>\n",
       "      <td>1.125875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-8-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-8-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d7f3d81abe4d0ebe6336c9fbb776db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▃▁▁▆</td></tr><tr><td>eval/rmse</td><td>█▄▃▁▂▆</td></tr><tr><td>eval/runtime</td><td>▂▂▁▂▁█</td></tr><tr><td>eval/samples_per_second</td><td>▆▇▇▆█▁</td></tr><tr><td>eval/steps_per_second</td><td>▆▇█▆█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.90273</td></tr><tr><td>eval/rmse</td><td>1.37939</td></tr><tr><td>eval/runtime</td><td>0.8296</td></tr><tr><td>eval/samples_per_second</td><td>90.409</td></tr><tr><td>eval/steps_per_second</td><td>12.055</td></tr><tr><td>eval_loss</td><td>1.90273</td></tr><tr><td>eval_rmse</td><td>1.37939</td></tr><tr><td>eval_runtime</td><td>0.8296</td></tr><tr><td>eval_samples_per_second</td><td>90.409</td></tr><tr><td>eval_steps_per_second</td><td>12.055</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7301</td></tr><tr><td>train/total_flos</td><td>2682217496577024.0</td></tr><tr><td>train/train_loss</td><td>1.41061</td></tr><tr><td>train/train_runtime</td><td>78.4682</td></tr><tr><td>train/train_samples_per_second</td><td>26.125</td></tr><tr><td>train/train_steps_per_second</td><td>3.313</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-64-8-3-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/26v8ojuo\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/26v8ojuo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_012655-26v8ojuo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_012831-32xb6z39</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/32xb6z39\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-64-8-6-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac77d944357a448d83b2b98e196ed8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bad569590054d3d97e4ab99d8535692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e56bb9acb14437965a91f9b9f36b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 64, 'nhead': 8, 'nlayers': 6}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.365000</td>\n",
       "      <td>2.195008</td>\n",
       "      <td>1.481556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.748100</td>\n",
       "      <td>1.721843</td>\n",
       "      <td>1.312190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.144600</td>\n",
       "      <td>1.747434</td>\n",
       "      <td>1.321906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.828400</td>\n",
       "      <td>1.769024</td>\n",
       "      <td>1.330046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.671100</td>\n",
       "      <td>1.791451</td>\n",
       "      <td>1.338451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-8-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-8-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17eb0b26bc343c080fb851ef98122b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▁▁▂▂▇</td></tr><tr><td>eval/rmse</td><td>█▁▁▂▂▇</td></tr><tr><td>eval/runtime</td><td>▁▂▃▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▇▆▇█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇▆██▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.13274</td></tr><tr><td>eval/rmse</td><td>1.46039</td></tr><tr><td>eval/runtime</td><td>0.7656</td></tr><tr><td>eval/samples_per_second</td><td>97.967</td></tr><tr><td>eval/steps_per_second</td><td>13.062</td></tr><tr><td>eval_loss</td><td>2.13274</td></tr><tr><td>eval_rmse</td><td>1.46039</td></tr><tr><td>eval_runtime</td><td>0.7656</td></tr><tr><td>eval_samples_per_second</td><td>97.967</td></tr><tr><td>eval_steps_per_second</td><td>13.062</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6711</td></tr><tr><td>train/total_flos</td><td>2682217496577024.0</td></tr><tr><td>train/train_loss</td><td>1.31816</td></tr><tr><td>train/train_runtime</td><td>76.7921</td></tr><tr><td>train/train_samples_per_second</td><td>26.695</td></tr><tr><td>train/train_steps_per_second</td><td>3.386</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-64-8-6-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/32xb6z39\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/32xb6z39</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_012831-32xb6z39/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_013004-3qt00rks</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/3qt00rks\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-64-8-12-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0161ce2fbe4a168c88e8520d820096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d55671b527743e39f02cf6f946bae17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c839f96ec614cf4bd570c126bb06d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 64, 'nhead': 8, 'nlayers': 12}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.335600</td>\n",
       "      <td>2.203078</td>\n",
       "      <td>1.484277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.798700</td>\n",
       "      <td>1.628574</td>\n",
       "      <td>1.276156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.236200</td>\n",
       "      <td>1.532610</td>\n",
       "      <td>1.237986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.018900</td>\n",
       "      <td>1.298405</td>\n",
       "      <td>1.139476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.737800</td>\n",
       "      <td>1.555903</td>\n",
       "      <td>1.247358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-8-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-64-8-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8efca9941d45e9902b73ebd132a25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▄▃▁▃▆</td></tr><tr><td>eval/rmse</td><td>█▄▃▁▃▆</td></tr><tr><td>eval/runtime</td><td>▁▄▁▂▂█</td></tr><tr><td>eval/samples_per_second</td><td>█▄█▆▇▁</td></tr><tr><td>eval/steps_per_second</td><td>█▅█▆▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.88444</td></tr><tr><td>eval/rmse</td><td>1.37275</td></tr><tr><td>eval/runtime</td><td>0.7265</td></tr><tr><td>eval/samples_per_second</td><td>103.236</td></tr><tr><td>eval/steps_per_second</td><td>13.765</td></tr><tr><td>eval_loss</td><td>1.88444</td></tr><tr><td>eval_rmse</td><td>1.37275</td></tr><tr><td>eval_runtime</td><td>0.7265</td></tr><tr><td>eval_samples_per_second</td><td>103.236</td></tr><tr><td>eval_steps_per_second</td><td>13.765</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7378</td></tr><tr><td>train/total_flos</td><td>2682217496577024.0</td></tr><tr><td>train/train_loss</td><td>1.39162</td></tr><tr><td>train/train_runtime</td><td>82.4288</td></tr><tr><td>train/train_samples_per_second</td><td>24.87</td></tr><tr><td>train/train_steps_per_second</td><td>3.154</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-64-8-12-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/3qt00rks\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/3qt00rks</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_013004-3qt00rks/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_013144-2kmft26z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/2kmft26z\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-128-1-3-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019c58d2ed944b1e9dafa4e40a863e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1f8a7d365b49ebb925164c4a4261f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b864b8d78dc48adba8ed3605d117a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.443400</td>\n",
       "      <td>2.349677</td>\n",
       "      <td>1.532866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.969000</td>\n",
       "      <td>1.921097</td>\n",
       "      <td>1.386036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.437200</td>\n",
       "      <td>2.231913</td>\n",
       "      <td>1.493959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.048900</td>\n",
       "      <td>2.025670</td>\n",
       "      <td>1.423260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.782700</td>\n",
       "      <td>2.218914</td>\n",
       "      <td>1.489602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-1-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-1-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25b4796c6ec94bcc9282766fd462a141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>▆▁▅▂▅█</td></tr><tr><td>eval/rmse</td><td>▆▁▅▂▅█</td></tr><tr><td>eval/runtime</td><td>▁▃▁▄▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▆█▄█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▆█▅█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▄▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.48573</td></tr><tr><td>eval/rmse</td><td>1.57662</td></tr><tr><td>eval/runtime</td><td>0.652</td></tr><tr><td>eval/samples_per_second</td><td>115.023</td></tr><tr><td>eval/steps_per_second</td><td>15.336</td></tr><tr><td>eval_loss</td><td>2.48573</td></tr><tr><td>eval_rmse</td><td>1.57662</td></tr><tr><td>eval_runtime</td><td>0.652</td></tr><tr><td>eval_samples_per_second</td><td>115.023</td></tr><tr><td>eval_steps_per_second</td><td>15.336</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7827</td></tr><tr><td>train/total_flos</td><td>2682219002397696.0</td></tr><tr><td>train/train_loss</td><td>1.49785</td></tr><tr><td>train/train_runtime</td><td>75.9695</td></tr><tr><td>train/train_samples_per_second</td><td>26.985</td></tr><tr><td>train/train_steps_per_second</td><td>3.422</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-128-1-3-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/2kmft26z\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/2kmft26z</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_013144-2kmft26z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_013317-1s4vm1ax</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1s4vm1ax\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-128-1-6-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6fe16f37c1e43d7814e43b258488b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7bbcbd117c64991aa37d664db2478ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df896f3f44644118b05910b9f4471c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 6}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.448100</td>\n",
       "      <td>2.129215</td>\n",
       "      <td>1.459183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.703800</td>\n",
       "      <td>1.671762</td>\n",
       "      <td>1.292966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.148900</td>\n",
       "      <td>1.891852</td>\n",
       "      <td>1.375446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.894800</td>\n",
       "      <td>1.570634</td>\n",
       "      <td>1.253250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>1.642680</td>\n",
       "      <td>1.281671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-1-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-1-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3b36929b64411b98656334847ea366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▅▁▂█</td></tr><tr><td>eval/rmse</td><td>█▂▅▁▂█</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.14342</td></tr><tr><td>eval/rmse</td><td>1.46404</td></tr><tr><td>eval/runtime</td><td>0.8763</td></tr><tr><td>eval/samples_per_second</td><td>85.585</td></tr><tr><td>eval/steps_per_second</td><td>11.411</td></tr><tr><td>eval_loss</td><td>2.14342</td></tr><tr><td>eval_rmse</td><td>1.46404</td></tr><tr><td>eval_runtime</td><td>0.8763</td></tr><tr><td>eval_samples_per_second</td><td>85.585</td></tr><tr><td>eval_steps_per_second</td><td>11.411</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6525</td></tr><tr><td>train/total_flos</td><td>2682219002397696.0</td></tr><tr><td>train/train_loss</td><td>1.33584</td></tr><tr><td>train/train_runtime</td><td>78.7323</td></tr><tr><td>train/train_samples_per_second</td><td>26.038</td></tr><tr><td>train/train_steps_per_second</td><td>3.302</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-128-1-6-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1s4vm1ax\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1s4vm1ax</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_013317-1s4vm1ax/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_013454-1y99pvxa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1y99pvxa\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-128-1-12-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b1b1f267e2492aaab6dabe27c928ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f56c3cb3614befabff240d90e51037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf601343f6d4273a1610375a47f784e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 12}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.466400</td>\n",
       "      <td>2.444999</td>\n",
       "      <td>1.563649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.807700</td>\n",
       "      <td>1.879641</td>\n",
       "      <td>1.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.253800</td>\n",
       "      <td>1.747314</td>\n",
       "      <td>1.321860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.943700</td>\n",
       "      <td>1.620650</td>\n",
       "      <td>1.273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.710200</td>\n",
       "      <td>1.802497</td>\n",
       "      <td>1.342571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-1-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-1-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1448c33d9db84c579ea422dfa2e0222f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▂▁▃▇</td></tr><tr><td>eval/rmse</td><td>█▃▂▁▃▇</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▇███▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.33789</td></tr><tr><td>eval/rmse</td><td>1.52902</td></tr><tr><td>eval/runtime</td><td>0.8928</td></tr><tr><td>eval/samples_per_second</td><td>84.004</td></tr><tr><td>eval/steps_per_second</td><td>11.201</td></tr><tr><td>eval_loss</td><td>2.33789</td></tr><tr><td>eval_rmse</td><td>1.52902</td></tr><tr><td>eval_runtime</td><td>0.8928</td></tr><tr><td>eval_samples_per_second</td><td>84.004</td></tr><tr><td>eval_steps_per_second</td><td>11.201</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7102</td></tr><tr><td>train/total_flos</td><td>2682219002397696.0</td></tr><tr><td>train/train_loss</td><td>1.40446</td></tr><tr><td>train/train_runtime</td><td>81.3414</td></tr><tr><td>train/train_samples_per_second</td><td>25.202</td></tr><tr><td>train/train_steps_per_second</td><td>3.196</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-128-1-12-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1y99pvxa\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1y99pvxa</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_013454-1y99pvxa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_013632-3tt1mk8b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/3tt1mk8b\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-128-4-3-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58669eeea0e455398e5ceee3a4fa421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bfdf6b2ef445539e613e12b3cb1bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75dcc4ad905243dda04c55640214a18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 128, 'nhead': 4, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.450100</td>\n",
       "      <td>2.494182</td>\n",
       "      <td>1.579298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.894200</td>\n",
       "      <td>1.759973</td>\n",
       "      <td>1.326640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.311600</td>\n",
       "      <td>1.666712</td>\n",
       "      <td>1.291012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.949000</td>\n",
       "      <td>1.755647</td>\n",
       "      <td>1.325008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.719700</td>\n",
       "      <td>1.659581</td>\n",
       "      <td>1.288247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-4-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-4-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e683b4611af48708058e7dab66a0448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▁▂▁▆</td></tr><tr><td>eval/rmse</td><td>█▂▁▂▁▆</td></tr><tr><td>eval/runtime</td><td>▁▁▃▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>██▅██▁</td></tr><tr><td>eval/steps_per_second</td><td>██▆██▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.22427</td></tr><tr><td>eval/rmse</td><td>1.4914</td></tr><tr><td>eval/runtime</td><td>0.7787</td></tr><tr><td>eval/samples_per_second</td><td>96.314</td></tr><tr><td>eval/steps_per_second</td><td>12.842</td></tr><tr><td>eval_loss</td><td>2.22427</td></tr><tr><td>eval_rmse</td><td>1.4914</td></tr><tr><td>eval_runtime</td><td>0.7787</td></tr><tr><td>eval_samples_per_second</td><td>96.314</td></tr><tr><td>eval_steps_per_second</td><td>12.842</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7197</td></tr><tr><td>train/total_flos</td><td>2682219002397696.0</td></tr><tr><td>train/train_loss</td><td>1.42698</td></tr><tr><td>train/train_runtime</td><td>77.2844</td></tr><tr><td>train/train_samples_per_second</td><td>26.525</td></tr><tr><td>train/train_steps_per_second</td><td>3.364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-128-4-3-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/3tt1mk8b\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/3tt1mk8b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_013632-3tt1mk8b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_013809-tmeaeq6i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/tmeaeq6i\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-128-4-6-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9756f938b8ba4b00bb2f441c90a19d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4567ead00180488b91e32b9fc92dfbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc809aba5f6244b0b59ac49129fb9f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 128, 'nhead': 4, 'nlayers': 6}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.444900</td>\n",
       "      <td>2.147545</td>\n",
       "      <td>1.465450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.716800</td>\n",
       "      <td>1.523731</td>\n",
       "      <td>1.234395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.103300</td>\n",
       "      <td>2.100999</td>\n",
       "      <td>1.449482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.798100</td>\n",
       "      <td>1.480618</td>\n",
       "      <td>1.216807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.583800</td>\n",
       "      <td>1.566014</td>\n",
       "      <td>1.251405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-4-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-4-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf3e7af6702c43c0aa7593175bb54bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>▇▁▇▁▂█</td></tr><tr><td>eval/rmse</td><td>▇▁▇▁▂█</td></tr><tr><td>eval/runtime</td><td>▁▂▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▇█▇█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇█▇█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.23367</td></tr><tr><td>eval/rmse</td><td>1.49455</td></tr><tr><td>eval/runtime</td><td>0.7828</td></tr><tr><td>eval/samples_per_second</td><td>95.809</td></tr><tr><td>eval/steps_per_second</td><td>12.775</td></tr><tr><td>eval_loss</td><td>2.23367</td></tr><tr><td>eval_rmse</td><td>1.49455</td></tr><tr><td>eval_runtime</td><td>0.7828</td></tr><tr><td>eval_samples_per_second</td><td>95.809</td></tr><tr><td>eval_steps_per_second</td><td>12.775</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5838</td></tr><tr><td>train/total_flos</td><td>2682219002397696.0</td></tr><tr><td>train/train_loss</td><td>1.2961</td></tr><tr><td>train/train_runtime</td><td>77.5742</td></tr><tr><td>train/train_samples_per_second</td><td>26.426</td></tr><tr><td>train/train_steps_per_second</td><td>3.352</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-128-4-6-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/tmeaeq6i\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/tmeaeq6i</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_013809-tmeaeq6i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_013944-3ccaq48i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/3ccaq48i\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-128-4-12-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68294ce7ed3f4e0bbacd23ce40ea691b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a2389ef0024886a2407c5f548bd2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dba394eac8d4f2f95ab2a56f344b5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 128, 'nhead': 4, 'nlayers': 12}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.489300</td>\n",
       "      <td>2.294903</td>\n",
       "      <td>1.514894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.832300</td>\n",
       "      <td>2.015156</td>\n",
       "      <td>1.419562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.280600</td>\n",
       "      <td>1.934239</td>\n",
       "      <td>1.390769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.911100</td>\n",
       "      <td>1.494149</td>\n",
       "      <td>1.222354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>1.663433</td>\n",
       "      <td>1.289742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-4-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-4-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8277e9dc89a94839a807c60ae3cb7e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▆▅▁▂▇</td></tr><tr><td>eval/rmse</td><td>█▆▅▁▃▇</td></tr><tr><td>eval/runtime</td><td>▃▄▃▃▁█</td></tr><tr><td>eval/samples_per_second</td><td>▅▃▅▆█▁</td></tr><tr><td>eval/steps_per_second</td><td>▆▄▆▆█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.20904</td></tr><tr><td>eval/rmse</td><td>1.48629</td></tr><tr><td>eval/runtime</td><td>0.6987</td></tr><tr><td>eval/samples_per_second</td><td>107.343</td></tr><tr><td>eval/steps_per_second</td><td>14.312</td></tr><tr><td>eval_loss</td><td>2.20904</td></tr><tr><td>eval_rmse</td><td>1.48629</td></tr><tr><td>eval_runtime</td><td>0.6987</td></tr><tr><td>eval_samples_per_second</td><td>107.343</td></tr><tr><td>eval_steps_per_second</td><td>14.312</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6764</td></tr><tr><td>train/total_flos</td><td>2682219002397696.0</td></tr><tr><td>train/train_loss</td><td>1.40278</td></tr><tr><td>train/train_runtime</td><td>84.0745</td></tr><tr><td>train/train_samples_per_second</td><td>24.383</td></tr><tr><td>train/train_steps_per_second</td><td>3.092</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-128-4-12-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/3ccaq48i\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/3ccaq48i</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_013944-3ccaq48i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_014126-usc1l60r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/usc1l60r\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-128-8-3-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f41de37b524c97901b0e6f9bedadc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521ad87535d9406f8c603fad5e20b4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd0a0e9a01b4ac2a58b913dceac678a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 128, 'nhead': 8, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.415800</td>\n",
       "      <td>2.293600</td>\n",
       "      <td>1.514464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.932000</td>\n",
       "      <td>1.723438</td>\n",
       "      <td>1.312798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.371800</td>\n",
       "      <td>1.393462</td>\n",
       "      <td>1.180450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.047400</td>\n",
       "      <td>1.277548</td>\n",
       "      <td>1.130287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.813000</td>\n",
       "      <td>1.521669</td>\n",
       "      <td>1.233560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-8-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-8-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544daaac53df4b62b04b636a27434898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▄▂▁▃▇</td></tr><tr><td>eval/rmse</td><td>█▄▂▁▃▇</td></tr><tr><td>eval/runtime</td><td>▁▁▁▂▁█</td></tr><tr><td>eval/samples_per_second</td><td>███▇█▁</td></tr><tr><td>eval/steps_per_second</td><td>███▇█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.0876</td></tr><tr><td>eval/rmse</td><td>1.44485</td></tr><tr><td>eval/runtime</td><td>0.8319</td></tr><tr><td>eval/samples_per_second</td><td>90.153</td></tr><tr><td>eval/steps_per_second</td><td>12.02</td></tr><tr><td>eval_loss</td><td>2.0876</td></tr><tr><td>eval_rmse</td><td>1.44485</td></tr><tr><td>eval_runtime</td><td>0.8319</td></tr><tr><td>eval_samples_per_second</td><td>90.153</td></tr><tr><td>eval_steps_per_second</td><td>12.02</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.813</td></tr><tr><td>train/total_flos</td><td>2682219002397696.0</td></tr><tr><td>train/train_loss</td><td>1.47808</td></tr><tr><td>train/train_runtime</td><td>78.2831</td></tr><tr><td>train/train_samples_per_second</td><td>26.187</td></tr><tr><td>train/train_steps_per_second</td><td>3.321</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-128-8-3-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/usc1l60r\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/usc1l60r</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_014126-usc1l60r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_014302-1f23335i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1f23335i\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-128-8-6-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53043f7cc60c432985ed241cff064fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4c9a07bbfb41729de90496a21cc85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ee9344c6d245db8dd0e12f019b2615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 128, 'nhead': 8, 'nlayers': 6}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.448000</td>\n",
       "      <td>2.334451</td>\n",
       "      <td>1.527891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.804500</td>\n",
       "      <td>1.896000</td>\n",
       "      <td>1.376953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.156100</td>\n",
       "      <td>1.849156</td>\n",
       "      <td>1.359837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.863900</td>\n",
       "      <td>1.914012</td>\n",
       "      <td>1.383478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.632900</td>\n",
       "      <td>2.003218</td>\n",
       "      <td>1.415351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-8-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-8-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a64ca4647d49c0b9d6bba4fe3f77de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▁▂▃█</td></tr><tr><td>eval/rmse</td><td>█▂▁▂▃█</td></tr><tr><td>eval/runtime</td><td>▁▂▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▇██▇▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇██▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.31632</td></tr><tr><td>eval/rmse</td><td>1.52195</td></tr><tr><td>eval/runtime</td><td>0.7207</td></tr><tr><td>eval/samples_per_second</td><td>104.061</td></tr><tr><td>eval/steps_per_second</td><td>13.875</td></tr><tr><td>eval_loss</td><td>2.31632</td></tr><tr><td>eval_rmse</td><td>1.52195</td></tr><tr><td>eval_runtime</td><td>0.7207</td></tr><tr><td>eval_samples_per_second</td><td>104.061</td></tr><tr><td>eval_steps_per_second</td><td>13.875</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6329</td></tr><tr><td>train/total_flos</td><td>2682219002397696.0</td></tr><tr><td>train/train_loss</td><td>1.34708</td></tr><tr><td>train/train_runtime</td><td>80.393</td></tr><tr><td>train/train_samples_per_second</td><td>25.5</td></tr><tr><td>train/train_steps_per_second</td><td>3.234</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-128-8-6-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1f23335i\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1f23335i</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_014302-1f23335i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_014440-342gc112</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/342gc112\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-128-8-12-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ed4cb4344ef4195aa70a7c89693c2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3250419671cd48388ef3ab6e5ab9a451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c53b7c2b054c9bbf01ebe74e732ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 128, 'nhead': 8, 'nlayers': 12}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.447000</td>\n",
       "      <td>2.331230</td>\n",
       "      <td>1.526837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.917000</td>\n",
       "      <td>2.179561</td>\n",
       "      <td>1.476334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.435300</td>\n",
       "      <td>1.448263</td>\n",
       "      <td>1.203438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.970200</td>\n",
       "      <td>1.474862</td>\n",
       "      <td>1.214439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.760600</td>\n",
       "      <td>1.478864</td>\n",
       "      <td>1.216086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-8-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-128-8-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852b7457819e4db88ac1cbfb900b0fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▇▁▁▁▆</td></tr><tr><td>eval/rmse</td><td>█▇▁▁▁▆</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▇███▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇███▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▄▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.05039</td></tr><tr><td>eval/rmse</td><td>1.43192</td></tr><tr><td>eval/runtime</td><td>1.1933</td></tr><tr><td>eval/samples_per_second</td><td>62.853</td></tr><tr><td>eval/steps_per_second</td><td>8.38</td></tr><tr><td>eval_loss</td><td>2.05039</td></tr><tr><td>eval_rmse</td><td>1.43192</td></tr><tr><td>eval_runtime</td><td>1.1933</td></tr><tr><td>eval_samples_per_second</td><td>62.853</td></tr><tr><td>eval_steps_per_second</td><td>8.38</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7606</td></tr><tr><td>train/total_flos</td><td>2682219002397696.0</td></tr><tr><td>train/train_loss</td><td>1.47274</td></tr><tr><td>train/train_runtime</td><td>83.9956</td></tr><tr><td>train/train_samples_per_second</td><td>24.406</td></tr><tr><td>train/train_steps_per_second</td><td>3.095</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-128-8-12-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/342gc112\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/342gc112</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_014440-342gc112/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_014622-77qjq65s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/77qjq65s\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-256-1-3-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21a9748062544d3b6f3bba05a3b313b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a550e69ace4647a1780ee6018fc74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d46dbce2874a0299ab2c86f1042e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.339000</td>\n",
       "      <td>2.359891</td>\n",
       "      <td>1.536194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.764900</td>\n",
       "      <td>1.548875</td>\n",
       "      <td>1.244538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.128900</td>\n",
       "      <td>1.620993</td>\n",
       "      <td>1.273182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>1.287212</td>\n",
       "      <td>1.134554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.612300</td>\n",
       "      <td>1.324992</td>\n",
       "      <td>1.151083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-1-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-1-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f01d0e152a44818a2ee804f4b161083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▃▁▁▅</td></tr><tr><td>eval/rmse</td><td>█▃▃▁▁▅</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▂█</td></tr><tr><td>eval/samples_per_second</td><td>████▆▁</td></tr><tr><td>eval/steps_per_second</td><td>████▆▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.86868</td></tr><tr><td>eval/rmse</td><td>1.367</td></tr><tr><td>eval/runtime</td><td>0.7825</td></tr><tr><td>eval/samples_per_second</td><td>95.85</td></tr><tr><td>eval/steps_per_second</td><td>12.78</td></tr><tr><td>eval_loss</td><td>1.86868</td></tr><tr><td>eval_rmse</td><td>1.367</td></tr><tr><td>eval_runtime</td><td>0.7825</td></tr><tr><td>eval_samples_per_second</td><td>95.85</td></tr><tr><td>eval_steps_per_second</td><td>12.78</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6123</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.30108</td></tr><tr><td>train/train_runtime</td><td>78.9461</td></tr><tr><td>train/train_samples_per_second</td><td>25.967</td></tr><tr><td>train/train_steps_per_second</td><td>3.293</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-256-1-3-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/77qjq65s\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/77qjq65s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_014622-77qjq65s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_014800-17bjrcbn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/17bjrcbn\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-256-1-6-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632d5eaa4de34382bace2c76e4806fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e21fa905444637bac59f13f96e535e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2faf59947ffd415aacb19fb262e9507a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 6}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.253000</td>\n",
       "      <td>2.358667</td>\n",
       "      <td>1.535795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.765000</td>\n",
       "      <td>1.865664</td>\n",
       "      <td>1.365893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.100500</td>\n",
       "      <td>1.638523</td>\n",
       "      <td>1.280048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.829100</td>\n",
       "      <td>2.051975</td>\n",
       "      <td>1.432472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.583800</td>\n",
       "      <td>2.167622</td>\n",
       "      <td>1.472284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-1-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-1-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e18a5f387548cab80f4f999a2acdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>▇▃▁▄▅█</td></tr><tr><td>eval/rmse</td><td>▇▃▁▅▅█</td></tr><tr><td>eval/runtime</td><td>▂▄▂▃▁█</td></tr><tr><td>eval/samples_per_second</td><td>▆▃▇▄█▁</td></tr><tr><td>eval/steps_per_second</td><td>▇▅▇▆█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.49524</td></tr><tr><td>eval/rmse</td><td>1.57963</td></tr><tr><td>eval/runtime</td><td>0.6281</td></tr><tr><td>eval/samples_per_second</td><td>119.417</td></tr><tr><td>eval/steps_per_second</td><td>15.922</td></tr><tr><td>eval_loss</td><td>2.49524</td></tr><tr><td>eval_rmse</td><td>1.57963</td></tr><tr><td>eval_runtime</td><td>0.6281</td></tr><tr><td>eval_samples_per_second</td><td>119.417</td></tr><tr><td>eval_steps_per_second</td><td>15.922</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5838</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.27135</td></tr><tr><td>train/train_runtime</td><td>79.1814</td></tr><tr><td>train/train_samples_per_second</td><td>25.89</td></tr><tr><td>train/train_steps_per_second</td><td>3.284</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-256-1-6-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/17bjrcbn\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/17bjrcbn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_014800-17bjrcbn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_014936-1ok7w7i6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1ok7w7i6\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-256-1-12-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18fabc2f33347e48a621df7d3aac0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c5ee10f6364bf694257119087b17c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a0231230cd4074a7eb3eaaaa264b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 12}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.275900</td>\n",
       "      <td>2.417058</td>\n",
       "      <td>1.554689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.788400</td>\n",
       "      <td>1.752229</td>\n",
       "      <td>1.323718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.071200</td>\n",
       "      <td>1.956375</td>\n",
       "      <td>1.398705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.831700</td>\n",
       "      <td>1.653987</td>\n",
       "      <td>1.286074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>1.658602</td>\n",
       "      <td>1.287867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-1-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-1-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde46085a74f490397193c7cc342fef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▄▁▁▄</td></tr><tr><td>eval/rmse</td><td>█▂▄▁▁▄</td></tr><tr><td>eval/runtime</td><td>▁▃▁▂▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▅█▆█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▆█▇█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.97083</td></tr><tr><td>eval/rmse</td><td>1.40386</td></tr><tr><td>eval/runtime</td><td>0.7218</td></tr><tr><td>eval/samples_per_second</td><td>103.905</td></tr><tr><td>eval/steps_per_second</td><td>13.854</td></tr><tr><td>eval_loss</td><td>1.97083</td></tr><tr><td>eval_rmse</td><td>1.40386</td></tr><tr><td>eval_runtime</td><td>0.7218</td></tr><tr><td>eval_samples_per_second</td><td>103.905</td></tr><tr><td>eval_steps_per_second</td><td>13.854</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5891</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.27748</td></tr><tr><td>train/train_runtime</td><td>84.3489</td></tr><tr><td>train/train_samples_per_second</td><td>24.304</td></tr><tr><td>train/train_steps_per_second</td><td>3.082</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-256-1-12-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1ok7w7i6\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1ok7w7i6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_014936-1ok7w7i6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_015117-1z9zdr5b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1z9zdr5b\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-256-4-3-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612bd49f987d4c66821fdf3c50c92548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7532340f90cb43318abb7900894b6533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb6430a96c4451faa22ac75f286a0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 4, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.323700</td>\n",
       "      <td>2.228625</td>\n",
       "      <td>1.492858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.697800</td>\n",
       "      <td>2.095130</td>\n",
       "      <td>1.447456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.216500</td>\n",
       "      <td>1.501891</td>\n",
       "      <td>1.225517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.786100</td>\n",
       "      <td>1.619728</td>\n",
       "      <td>1.272686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.582600</td>\n",
       "      <td>1.653575</td>\n",
       "      <td>1.285914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-4-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-4-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739040718d4144e396b18909fe05bb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>▇▆▁▂▂█</td></tr><tr><td>eval/rmse</td><td>▇▆▁▂▂█</td></tr><tr><td>eval/runtime</td><td>▁▂▂▂▂█</td></tr><tr><td>eval/samples_per_second</td><td>█▇▇▆▇▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇▇▆▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▅▄▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.31446</td></tr><tr><td>eval/rmse</td><td>1.52133</td></tr><tr><td>eval/runtime</td><td>0.8152</td></tr><tr><td>eval/samples_per_second</td><td>92.003</td></tr><tr><td>eval/steps_per_second</td><td>12.267</td></tr><tr><td>eval_loss</td><td>2.31446</td></tr><tr><td>eval_rmse</td><td>1.52133</td></tr><tr><td>eval_runtime</td><td>0.8152</td></tr><tr><td>eval_samples_per_second</td><td>92.003</td></tr><tr><td>eval_steps_per_second</td><td>12.267</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5826</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.28924</td></tr><tr><td>train/train_runtime</td><td>78.6474</td></tr><tr><td>train/train_samples_per_second</td><td>26.066</td></tr><tr><td>train/train_steps_per_second</td><td>3.306</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-256-4-3-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1z9zdr5b\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1z9zdr5b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_015117-1z9zdr5b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_015254-u8zjz944</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/u8zjz944\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-256-4-6-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0386651cb5b43969a83bdb432bf0884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c150a22802ea4f3eb07943fbc2fae96b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6c62957e0a4ace8dc55d7d4eb8e391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 4, 'nlayers': 6}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.292100</td>\n",
       "      <td>2.448871</td>\n",
       "      <td>1.564887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.894700</td>\n",
       "      <td>2.080962</td>\n",
       "      <td>1.442554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.353600</td>\n",
       "      <td>1.777391</td>\n",
       "      <td>1.333188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.001400</td>\n",
       "      <td>2.013337</td>\n",
       "      <td>1.418921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.761000</td>\n",
       "      <td>1.594576</td>\n",
       "      <td>1.262765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-4-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-4-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d5a4ba915e4bcf8ed5e1866eb1fafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▅▂▄▁▅</td></tr><tr><td>eval/rmse</td><td>█▅▃▅▁▅</td></tr><tr><td>eval/runtime</td><td>▁▂▃▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▇▅██▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇▆██▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▄▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.11933</td></tr><tr><td>eval/rmse</td><td>1.45579</td></tr><tr><td>eval/runtime</td><td>0.7576</td></tr><tr><td>eval/samples_per_second</td><td>98.994</td></tr><tr><td>eval/steps_per_second</td><td>13.199</td></tr><tr><td>eval_loss</td><td>2.11933</td></tr><tr><td>eval_rmse</td><td>1.45579</td></tr><tr><td>eval_runtime</td><td>0.7576</td></tr><tr><td>eval_samples_per_second</td><td>98.994</td></tr><tr><td>eval_steps_per_second</td><td>13.199</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.761</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.42406</td></tr><tr><td>train/train_runtime</td><td>76.2945</td></tr><tr><td>train/train_samples_per_second</td><td>26.87</td></tr><tr><td>train/train_steps_per_second</td><td>3.408</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-256-4-6-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/u8zjz944\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/u8zjz944</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_015254-u8zjz944/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_015427-1y5dyyl1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1y5dyyl1\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-256-4-12-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6ae0e8f5df4e12b37536227dd038e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d3981390b7144f1a9e00caee4aafc8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02618716dc0843bfa12373c96742a878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 4, 'nlayers': 12}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.277000</td>\n",
       "      <td>2.240227</td>\n",
       "      <td>1.496739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.687400</td>\n",
       "      <td>1.563847</td>\n",
       "      <td>1.250538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.040500</td>\n",
       "      <td>1.739307</td>\n",
       "      <td>1.318828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.806400</td>\n",
       "      <td>1.717411</td>\n",
       "      <td>1.310500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.556100</td>\n",
       "      <td>1.648017</td>\n",
       "      <td>1.283751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-4-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-4-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df81aabe26449b5aca852eb1b3c31b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▁▃▃▂▄</td></tr><tr><td>eval/rmse</td><td>█▁▃▃▂▄</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.80899</td></tr><tr><td>eval/rmse</td><td>1.34499</td></tr><tr><td>eval/runtime</td><td>0.8232</td></tr><tr><td>eval/samples_per_second</td><td>91.105</td></tr><tr><td>eval/steps_per_second</td><td>12.147</td></tr><tr><td>eval_loss</td><td>1.80899</td></tr><tr><td>eval_rmse</td><td>1.34499</td></tr><tr><td>eval_runtime</td><td>0.8232</td></tr><tr><td>eval_samples_per_second</td><td>91.105</td></tr><tr><td>eval_steps_per_second</td><td>12.147</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5561</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.24232</td></tr><tr><td>train/train_runtime</td><td>82.4863</td></tr><tr><td>train/train_samples_per_second</td><td>24.853</td></tr><tr><td>train/train_steps_per_second</td><td>3.152</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-256-4-12-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1y5dyyl1\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1y5dyyl1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_015427-1y5dyyl1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_015608-32fgxtsa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/32fgxtsa\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-256-8-3-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5d8f82cbe94dfca2571ded3d1de807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a8a2e73a764ee4ae418c34335138ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56cd56b8589143fbb7c4259f61e84e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 8, 'nlayers': 3}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.287400</td>\n",
       "      <td>2.240188</td>\n",
       "      <td>1.496726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.714400</td>\n",
       "      <td>2.252680</td>\n",
       "      <td>1.500893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.080000</td>\n",
       "      <td>1.383740</td>\n",
       "      <td>1.176325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.813300</td>\n",
       "      <td>1.618611</td>\n",
       "      <td>1.272246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.617600</td>\n",
       "      <td>1.498013</td>\n",
       "      <td>1.223933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-8-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-8-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73e6f2e397f84ec692947da4177bec0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>██▁▃▂▇</td></tr><tr><td>eval/rmse</td><td>██▁▃▂▇</td></tr><tr><td>eval/runtime</td><td>▁▃▁█▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▅▄▅▁▅█</td></tr><tr><td>eval/steps_per_second</td><td>█▆█▁▇█</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.09869</td></tr><tr><td>eval/rmse</td><td>1.44869</td></tr><tr><td>eval/runtime</td><td>0.5699</td></tr><tr><td>eval/samples_per_second</td><td>131.609</td></tr><tr><td>eval/steps_per_second</td><td>17.548</td></tr><tr><td>eval_loss</td><td>2.09869</td></tr><tr><td>eval_rmse</td><td>1.44869</td></tr><tr><td>eval_runtime</td><td>0.5699</td></tr><tr><td>eval_samples_per_second</td><td>131.609</td></tr><tr><td>eval_steps_per_second</td><td>17.548</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6176</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.27255</td></tr><tr><td>train/train_runtime</td><td>76.3786</td></tr><tr><td>train/train_samples_per_second</td><td>26.84</td></tr><tr><td>train/train_steps_per_second</td><td>3.404</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-256-8-3-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/32fgxtsa\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/32fgxtsa</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_015608-32fgxtsa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_015741-6r906xe5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/6r906xe5\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-256-8-6-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9869c004ec094018b750f088345fce25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdcab383db0400e98ec109e9ece2ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d56c404e1b040b5af8aa830dda34cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 8, 'nlayers': 6}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.339000</td>\n",
       "      <td>2.395637</td>\n",
       "      <td>1.547785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.836500</td>\n",
       "      <td>2.109116</td>\n",
       "      <td>1.452280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.325800</td>\n",
       "      <td>1.689125</td>\n",
       "      <td>1.299663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.041100</td>\n",
       "      <td>1.701929</td>\n",
       "      <td>1.304580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.825800</td>\n",
       "      <td>1.815729</td>\n",
       "      <td>1.347490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-8-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-8-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a85bffafd8844aaac5117baf8adeb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▅▁▁▂█</td></tr><tr><td>eval/rmse</td><td>█▅▁▁▂█</td></tr><tr><td>eval/runtime</td><td>▁▂▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▇▇███▁</td></tr><tr><td>eval/steps_per_second</td><td>█▇███▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.3712</td></tr><tr><td>eval/rmse</td><td>1.53987</td></tr><tr><td>eval/runtime</td><td>0.8522</td></tr><tr><td>eval/samples_per_second</td><td>88.009</td></tr><tr><td>eval/steps_per_second</td><td>11.735</td></tr><tr><td>eval_loss</td><td>2.3712</td></tr><tr><td>eval_rmse</td><td>1.53987</td></tr><tr><td>eval_runtime</td><td>0.8522</td></tr><tr><td>eval_samples_per_second</td><td>88.009</td></tr><tr><td>eval_steps_per_second</td><td>11.735</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.8258</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.44041</td></tr><tr><td>train/train_runtime</td><td>80.6393</td></tr><tr><td>train/train_samples_per_second</td><td>25.422</td></tr><tr><td>train/train_steps_per_second</td><td>3.224</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-256-8-6-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/6r906xe5\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/6r906xe5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_015741-6r906xe5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"document-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/b43ba3b1768a9480d7c985b0c22a3b10c15f0afd581f05347a1beb7a7f145eb1.bfdcc444ff249bca1a95ca170ec350b442f81804d7df3a95a2252217574121d7\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7177ee98ea6eb708be40ec3560f4807b7bf196fdf8f110dc4c249053bb47bef5.f5b91da9e34259b8f4d88dbc97c740667a0e8430b96314460cdb04e86d4fc435\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/special_tokens_map.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/d87e91220b4f8fe445492c0ca87879d99261d9ace150b1cd71c913c14ae66872.a11ebb04664c067c8fe5ef8f8068b0f721263414a26058692f7b2e4ba2a1b342\n",
      "loading file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/tokenizer_config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/7e7e7119ad1bc49907efe0f7f053bc0d2faf4ac6ebce153e4f7576436bf97df1.829f8fd1fa96172393d7b8208d8ed93ee137f1042e291df240a0a8e7f1699142\n",
      "loading configuration file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/67fff7e4e0a33106e11c355770df4420b2385850d788d1b7b549eb8d64b4f3d1.ef5baf2314e8ee19e0e25bc7741c47229b1ac5c08ae795cbc2d27f5f2c19535c\n",
      "Model config HATConfig {\n",
      "  \"_name_or_path\": \"kiddothe2b/hierarchical-transformer-base-4096\",\n",
      "  \"architectures\": [\n",
      "    \"HATForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_hat.HATConfig\",\n",
      "    \"AutoModel\": \"modelling_hat.HATModel\",\n",
      "    \"AutoModelForMaskedLM\": \"modelling_hat.HATForMaskedLM\",\n",
      "    \"AutoModelForMultipleChoice\": \"modelling_hat.HATForMultipleChoice\",\n",
      "    \"AutoModelForQuestionAnswering\": \"modelling_hat.HATForQuestionAnswering\",\n",
      "    \"AutoModelForSequenceClassification\": \"modelling_hat.HATForSequenceClassification\",\n",
      "    \"AutoModelForTokenClassification\": \"modelling_hat.HATForTokenClassification\",\n",
      "    \"AutoTokenizer\": \"tokenization_hat.HATTokenizer\"\n",
      "  },\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"encoder_layout\": {\n",
      "    \"0\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"1\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"10\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"11\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"2\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"3\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"4\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"5\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"6\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"7\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"8\": {\n",
      "      \"document_encoder\": true,\n",
      "      \"sentence_encoder\": true\n",
      "    },\n",
      "    \"9\": {\n",
      "      \"document_encoder\": false,\n",
      "      \"sentence_encoder\": true\n",
      "    }\n",
      "  },\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"max_sentence_length\": 128,\n",
      "  \"max_sentence_size\": 128,\n",
      "  \"max_sentences\": 32,\n",
      "  \"model_max_length\": 4096,\n",
      "  \"model_type\": \"hierarchical-transformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"parameters\": 136350720,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230217_015921-28ry48ib</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/28ry48ib\" target=\"_blank\">hat-model-test-with-exp-moves-encoder-256-8-12-hat-former</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f589914fd6744dda8a16fc3859db70a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3fdd75c17b4f558700b7b14453d3b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d862d0c1525347fb9874268ca1da30c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/kiddothe2b/hierarchical-transformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/3e6b4d161afa24393cd7a5363c4581beaea6fcad5e0aa6e1efd3733999473b92.b9741b26fc86ac9ac410a55dc25f6ed6b2dff47efeefb6a7058e3e63117e545a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  [{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 8, 'nlayers': 12}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 were not used when initializing MyHATForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyHATForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyHATForSequenceClassification were not initialized from the model checkpoint at kiddothe2b/hierarchical-transformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.weight', 'pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: topic, exp_act_label, input_texts. If topic, exp_act_label, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='260' max='260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [260/260 01:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.266400</td>\n",
       "      <td>2.197345</td>\n",
       "      <td>1.482345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.728700</td>\n",
       "      <td>1.702009</td>\n",
       "      <td>1.304611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.954200</td>\n",
       "      <td>1.798303</td>\n",
       "      <td>1.341008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.721800</td>\n",
       "      <td>1.758994</td>\n",
       "      <td>1.326271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>1.764732</td>\n",
       "      <td>1.328432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `MyHATForSequenceClassification.forward` and have been ignored: exp_act_label, topic, __index_level_0__, input_texts. If exp_act_label, topic, __index_level_0__, input_texts are not expected by `MyHATForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-8-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/hat-models//hat-model-test-with-exp-moves-encoder-256-8-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dc55580746403b81f275183b7297a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▁▂▂▂▃</td></tr><tr><td>eval/rmse</td><td>█▁▂▂▂▃</td></tr><tr><td>eval/runtime</td><td>▁▄▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█▅█▇█▁</td></tr><tr><td>eval/steps_per_second</td><td>█▅█▇█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▃▃▄▄▆▆████</td></tr><tr><td>train/global_step</td><td>▁▁▃▃▄▄▆▆█████</td></tr><tr><td>train/learning_rate</td><td>█▆▄▃▁</td></tr><tr><td>train/loss</td><td>█▆▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.85486</td></tr><tr><td>eval/rmse</td><td>1.36193</td></tr><tr><td>eval/runtime</td><td>0.8447</td></tr><tr><td>eval/samples_per_second</td><td>88.793</td></tr><tr><td>eval/steps_per_second</td><td>11.839</td></tr><tr><td>eval_loss</td><td>1.85486</td></tr><tr><td>eval_rmse</td><td>1.36193</td></tr><tr><td>eval_runtime</td><td>0.8447</td></tr><tr><td>eval_samples_per_second</td><td>88.793</td></tr><tr><td>eval_steps_per_second</td><td>11.839</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4974</td></tr><tr><td>train/total_flos</td><td>2682222014039040.0</td></tr><tr><td>train/train_loss</td><td>1.20246</td></tr><tr><td>train/train_runtime</td><td>96.6915</td></tr><tr><td>train/train_samples_per_second</td><td>21.201</td></tr><tr><td>train/train_steps_per_second</td><td>2.689</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">hat-model-test-with-exp-moves-encoder-256-8-12-hat-former</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/28ry48ib\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/28ry48ib</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230217_015921-28ry48ib/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for flow_model_hidden_size in [64, 128, 256]:\n",
    "    for nhead in [1, 4, 8]:\n",
    "        for nlayers in [3, 6, 12]:\n",
    "            hat_rmse_scores = train_and_evaluate_hat_model(model_name_or_path, '../data/quality_models/hat-models/', \n",
    "                                         eli5_annotation_df[['topic', 'input_texts', 'exp_act_label', 'labels']], \n",
    "                                                           'hat-model-test-with-exp-moves-encoder-{}-{}-{}'.format(flow_model_hidden_size, nhead, nlayers),\n",
    "                                         extra_encoder_configs=[{'num_tokens':11, 'flow_model_hidden_size': flow_model_hidden_size, 'nhead': nhead, 'nlayers':nlayers}],\n",
    "                                         num_train_epochs=5, lr=2e-5, batch_size=8,  eval_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for flow_model_hidden_size in [64, 128, 256]:\n",
    "#     for nhead in [1, 4, 8]:\n",
    "#         for nlayers in [3, 6, 12]:\n",
    "#             print('{}-{}-{}'.format(flow_model_hidden_size, nhead, nlayers), ':' , load_results('../data/quality_models/hat-model-exp-moves-encoder-{}-{}-{}/0-fold'.format(flow_model_hidden_size, nhead, nlayers))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Testing kfolds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 163, and Test 41\n",
      "Training 553, and Test 99\n",
      "------\n",
      "Training 163, and Test 41\n",
      "Training 532, and Test 120\n",
      "------\n",
      "Training 163, and Test 41\n",
      "Training 485, and Test 167\n",
      "------\n",
      "Training 163, and Test 41\n",
      "Training 481, and Test 171\n",
      "------\n",
      "Training 164, and Test 40\n",
      "Training 557, and Test 95\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "#split the two corpora\n",
    "topics  = eli5_annotation_df.topic.unique()\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "#kfold  = StratifiedKFold(n_splits=n_folds)\n",
    "fold_idx = 0\n",
    "rmse_scores = []\n",
    "for fold in kfold.split(topics):\n",
    "    train_topics = topics[fold[0]]\n",
    "    test_topics = topics[fold[1]]\n",
    "    \n",
    "    test_df  = eli5_annotation_df[eli5_annotation_df.topic.isin(test_topics)]\n",
    "    train_df = eli5_annotation_df[eli5_annotation_df.topic.isin(train_topics)]\n",
    "    \n",
    "    print('Training {}, and Test {}'.format(len(train_topics), len(test_topics)))\n",
    "    print('Training {}, and Test {}'.format(len(train_df), len(test_df)))\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Experimenting with LongFromer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5_training_df= load_and_prepare_df('../../data/eli5_ds/annotation-results/MACE-measure/final_mace_predictions_training.pkl', '../../data/eli5_ds/annotation-results/MACE-measure/final_mace_rating_predictions.csv')\n",
    "eli5_testing_df = load_and_prepare_df('../../data/eli5_ds/annotation-results/MACE-measure/final_mace_predictions_testing.pkl', '../../data/eli5_ds/annotation-results/MACE-measure/final_mace_rating_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_longformer_model(output_dir, df, wandb_run_name, input_clm='input_texts', num_train_epochs=5, eval_steps=500, lr=2e-6, batch_size=4, \n",
    "                                 max_seq_length=256, max_num_sequences=40, extra_encoder_configs=[]):\n",
    "\n",
    "\n",
    "    tokenizer = LongformerTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "    config = LongformerConfig.from_pretrained(\"allenai/longformer-base-4096\")\n",
    "    config.num_labels = 1\n",
    "\n",
    "    wandb.init(settings=wandb.Settings(start_method=\"fork\"), project=\"test-project\", entity=\"milad-it\", name='{}-longformer'.format(wandb_run_name))\n",
    "\n",
    "    rmse_scores = []\n",
    "\n",
    "    #split by topic\n",
    "    topics  = df.topic.unique()\n",
    "    train_topics, test_topics  = train_test_split(topics, test_size=0.2, shuffle=True, random_state=123)\n",
    "    train_topics, valid_topics = train_test_split(train_topics, test_size=0.2, shuffle=True, random_state=123)\n",
    "    \n",
    "    train_df = df[df.topic.isin(train_topics)]\n",
    "    valid_df = df[df.topic.isin(valid_topics)]\n",
    "    test_df  = df[df.topic.isin(test_topics)]\n",
    "    \n",
    "    #balance the data\n",
    "    train_df, y = ros.fit_resample(train_df, train_df['labels'])\n",
    "    train_df['labels'] = y\n",
    "    print(train_df.labels.value_counts())\n",
    "\n",
    "    \n",
    "    training_ds = Dataset.from_dict(preprocess_function(tokenizer, train_df, input_clm=input_clm))\n",
    "    valid_ds = Dataset.from_dict(preprocess_function(tokenizer, valid_df, input_clm=input_clm))\n",
    "    test_ds = Dataset.from_dict(preprocess_function(tokenizer, test_df, input_clm=input_clm))\n",
    "\n",
    "    print('Training {}, Valid {}, and Test {}'.format(len(train_topics), len(valid_topics), len(test_topics)))\n",
    "    print('Training {}, Valid {}, and Test {}'.format(len(training_ds), len(valid_ds), len(test_ds)))\n",
    "\n",
    "\n",
    "    model = LongformerForSequenceClassification.from_pretrained(\"allenai/longformer-base-4096\", config=config, extra_encoders_configs=extra_encoder_configs).to(device)\n",
    "\n",
    "    args = TrainingArguments(\n",
    "            output_dir= '{}/longformer-{}-fold'.format(output_dir, 0),\n",
    "            overwrite_output_dir=True,\n",
    "            evaluation_strategy = \"steps\",\n",
    "            save_strategy = \"steps\",\n",
    "            logging_strategy=\"steps\",\n",
    "            save_total_limit=5,\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            weight_decay=0.01,\n",
    "            eval_steps=eval_steps,\n",
    "            logging_steps=eval_steps,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model='rmse'\n",
    "        )\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=training_ds,\n",
    "        eval_dataset=valid_ds,\n",
    "        compute_metrics=lambda x: compute_metrics(x),\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    eval_results = trainer.evaluate(test_ds)\n",
    "    wandb.log(eval_results)\n",
    "    rmse_scores.append(eval_results['eval_rmse'])\n",
    "    model.save_pretrained('{}/{}/{}-fold'.format(output_dir, wandb_run_name, 0))\n",
    "    test_ds.to_json('{}/{}/{}-fold/test_set.json'.format(output_dir, wandb_run_name, 0))\n",
    "    json.dump(eval_results, open('{}/{}/{}-fold/eval_results.json'.format(output_dir, wandb_run_name, 0), 'w'))\n",
    "\n",
    "    wandb.finish()\n",
    "        \n",
    "    return rmse_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fine-tuning LongFormer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmiladalsh-it\u001b[0m (\u001b[33mmilad-it\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_140942-2fd1x3k0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/2fd1x3k0\" target=\"_blank\">longformer-model-test-baseline-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "Using input_clm=input_texts\n",
      "Using input_clm=input_texts\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n",
      "Extra encoders:  ModuleList()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:09, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.223200</td>\n",
       "      <td>2.496426</td>\n",
       "      <td>1.580008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.824200</td>\n",
       "      <td>1.635609</td>\n",
       "      <td>1.278909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.613400</td>\n",
       "      <td>1.912244</td>\n",
       "      <td>1.382839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.650600</td>\n",
       "      <td>1.826673</td>\n",
       "      <td>1.351544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.017400</td>\n",
       "      <td>1.300700</td>\n",
       "      <td>1.140483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.244900</td>\n",
       "      <td>1.299960</td>\n",
       "      <td>1.140158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.845100</td>\n",
       "      <td>1.442755</td>\n",
       "      <td>1.201147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.724500</td>\n",
       "      <td>1.427345</td>\n",
       "      <td>1.194715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.515600</td>\n",
       "      <td>1.283194</td>\n",
       "      <td>1.132782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>1.276497</td>\n",
       "      <td>1.129822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-baseline}/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-baseline}/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-baseline}/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-baseline}/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-baseline}/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-baseline}/longformer-0-fold/checkpoint-500 (score: 1.12982177734375).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-baseline}/longformer-model-test-baseline/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-baseline}/longformer-model-test-baseline/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6419660f71b14929a8931763a5018f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▅▄▁▁▂▂▁▁▅</td></tr><tr><td>eval/rmse</td><td>█▃▅▄▁▁▂▂▁▁▅</td></tr><tr><td>eval/runtime</td><td>▂▁▁▂▂▂▁▁▃▂█</td></tr><tr><td>eval/samples_per_second</td><td>▃▆▇▅▆▆█▆▁▃▂</td></tr><tr><td>eval/steps_per_second</td><td>▇██▇▇▇██▆▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▂▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.93806</td></tr><tr><td>eval/rmse</td><td>1.39214</td></tr><tr><td>eval/runtime</td><td>4.6377</td></tr><tr><td>eval/samples_per_second</td><td>16.172</td></tr><tr><td>eval/steps_per_second</td><td>4.097</td></tr><tr><td>eval_loss</td><td>1.93806</td></tr><tr><td>eval_rmse</td><td>1.39214</td></tr><tr><td>eval_runtime</td><td>4.6377</td></tr><tr><td>eval_samples_per_second</td><td>16.172</td></tr><tr><td>eval_steps_per_second</td><td>4.097</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4198</td></tr><tr><td>train/total_flos</td><td>5415898970112000.0</td></tr><tr><td>train/train_loss</td><td>1.28293</td></tr><tr><td>train/train_runtime</td><td>611.031</td></tr><tr><td>train/train_samples_per_second</td><td>3.355</td></tr><tr><td>train/train_steps_per_second</td><td>0.843</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-baseline-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/2fd1x3k0\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/2fd1x3k0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_140942-2fd1x3k0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hat_rmse_scores = train_and_evaluate_longformer_model('../data/quality_models/longformer-models/longformer-model-test-baseline}', \n",
    "                                         eli5_annotation_df[['topic', 'input_texts', 'labels']], 'longformer-model-test-baseline',\n",
    "                                         extra_encoder_configs=[], lr=2e-5, eval_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3921436071395874]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_142355-3ib0pojx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/3ib0pojx\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-64-1-3-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 64)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.embedding.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.915800</td>\n",
       "      <td>2.316873</td>\n",
       "      <td>1.522128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.996700</td>\n",
       "      <td>2.501929</td>\n",
       "      <td>1.581749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.135200</td>\n",
       "      <td>2.059739</td>\n",
       "      <td>1.435179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>1.660197</td>\n",
       "      <td>1.288486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.459400</td>\n",
       "      <td>1.352867</td>\n",
       "      <td>1.163128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.498700</td>\n",
       "      <td>1.277015</td>\n",
       "      <td>1.130051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.055200</td>\n",
       "      <td>1.434408</td>\n",
       "      <td>1.197668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.891700</td>\n",
       "      <td>1.254322</td>\n",
       "      <td>1.119965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.698800</td>\n",
       "      <td>1.255607</td>\n",
       "      <td>1.120539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.566200</td>\n",
       "      <td>1.222642</td>\n",
       "      <td>1.105731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-3/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-3/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-3/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-3/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-3/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-3/longformer-0-fold/checkpoint-500 (score: 1.1057313680648804).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-3/longformer-model-test-with-exp-moves-encoder-64-1-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-3/longformer-model-test-with-exp-moves-encoder-64-1-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010b1d70230a413a862cfe6f0136ded0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>▇█▆▃▂▁▂▁▁▁▅</td></tr><tr><td>eval/rmse</td><td>▇█▆▄▂▁▂▁▁▁▅</td></tr><tr><td>eval/runtime</td><td>▁▂▁█▂▄▁▆▁▁▂</td></tr><tr><td>eval/samples_per_second</td><td>█▇█▁▇▅█▃███</td></tr><tr><td>eval/steps_per_second</td><td>█▇█▁▇▅█▃██▆</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▆▅▄▄▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.87336</td></tr><tr><td>eval/rmse</td><td>1.36871</td></tr><tr><td>eval/runtime</td><td>4.6909</td></tr><tr><td>eval/samples_per_second</td><td>15.988</td></tr><tr><td>eval/steps_per_second</td><td>4.05</td></tr><tr><td>eval_loss</td><td>1.87336</td></tr><tr><td>eval_rmse</td><td>1.36871</td></tr><tr><td>eval_runtime</td><td>4.6909</td></tr><tr><td>eval_samples_per_second</td><td>15.988</td></tr><tr><td>eval_steps_per_second</td><td>4.05</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5662</td></tr><tr><td>train/total_flos</td><td>5425085203660800.0</td></tr><tr><td>train/train_loss</td><td>1.48287</td></tr><tr><td>train/train_runtime</td><td>631.3188</td></tr><tr><td>train/train_samples_per_second</td><td>3.247</td></tr><tr><td>train/train_steps_per_second</td><td>0.816</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-64-1-3-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/3ib0pojx\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/3ib0pojx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_142355-3ib0pojx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_143454-q7kjsk1o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/q7kjsk1o\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-64-1-6-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 64)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.963400</td>\n",
       "      <td>2.401869</td>\n",
       "      <td>1.549796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.035300</td>\n",
       "      <td>2.491433</td>\n",
       "      <td>1.578428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.043300</td>\n",
       "      <td>1.941279</td>\n",
       "      <td>1.393298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.895000</td>\n",
       "      <td>2.005525</td>\n",
       "      <td>1.416166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.566700</td>\n",
       "      <td>1.770076</td>\n",
       "      <td>1.330442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.504600</td>\n",
       "      <td>1.795562</td>\n",
       "      <td>1.339986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.202400</td>\n",
       "      <td>1.217056</td>\n",
       "      <td>1.103203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.921000</td>\n",
       "      <td>1.376329</td>\n",
       "      <td>1.173171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.878600</td>\n",
       "      <td>1.145513</td>\n",
       "      <td>1.070287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.731500</td>\n",
       "      <td>1.185611</td>\n",
       "      <td>1.088858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-6/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-6/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-6/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-6/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-6/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-6/longformer-0-fold/checkpoint-500 (score: 1.0888575315475464).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-6/longformer-model-test-with-exp-moves-encoder-64-1-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-6/longformer-model-test-with-exp-moves-encoder-64-1-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257252553c814ff9a07576e13e67846b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>██▅▅▄▄▁▂▁▁▄</td></tr><tr><td>eval/rmse</td><td>██▅▆▅▅▁▂▁▁▄</td></tr><tr><td>eval/runtime</td><td>▂▄▂▃▂▅▁▂▂▃█</td></tr><tr><td>eval/samples_per_second</td><td>▅▃▅▅▆▁▇▅▅▅█</td></tr><tr><td>eval/steps_per_second</td><td>▇▅▇▆▇▄█▇▇▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▅▅▄▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.74869</td></tr><tr><td>eval/rmse</td><td>1.32238</td></tr><tr><td>eval/runtime</td><td>4.6875</td></tr><tr><td>eval/samples_per_second</td><td>16.0</td></tr><tr><td>eval/steps_per_second</td><td>4.053</td></tr><tr><td>eval_loss</td><td>1.74869</td></tr><tr><td>eval_rmse</td><td>1.32238</td></tr><tr><td>eval_runtime</td><td>4.6875</td></tr><tr><td>eval_samples_per_second</td><td>16.0</td></tr><tr><td>eval_steps_per_second</td><td>4.053</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7315</td></tr><tr><td>train/total_flos</td><td>5428896410419200.0</td></tr><tr><td>train/train_loss</td><td>1.54655</td></tr><tr><td>train/train_runtime</td><td>633.9757</td></tr><tr><td>train/train_samples_per_second</td><td>3.234</td></tr><tr><td>train/train_steps_per_second</td><td>0.812</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-64-1-6-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/q7kjsk1o\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/q7kjsk1o</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_143454-q7kjsk1o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_144556-1lv7ja8a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1lv7ja8a\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-64-1-12-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 64)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.10.linear1.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.7.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.9.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.6.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.10.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.10.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.7.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.bias', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear2.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.linear2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.957100</td>\n",
       "      <td>2.675383</td>\n",
       "      <td>1.635660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.953300</td>\n",
       "      <td>2.052755</td>\n",
       "      <td>1.432744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.835900</td>\n",
       "      <td>1.535079</td>\n",
       "      <td>1.238983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.926100</td>\n",
       "      <td>2.509422</td>\n",
       "      <td>1.584116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.838700</td>\n",
       "      <td>1.845091</td>\n",
       "      <td>1.358341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.879900</td>\n",
       "      <td>1.591057</td>\n",
       "      <td>1.261371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.258400</td>\n",
       "      <td>1.457806</td>\n",
       "      <td>1.207397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.200700</td>\n",
       "      <td>1.387217</td>\n",
       "      <td>1.177802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.067900</td>\n",
       "      <td>1.337021</td>\n",
       "      <td>1.156296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.756400</td>\n",
       "      <td>1.357897</td>\n",
       "      <td>1.165288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-12/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-12/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-12/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-12/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-12/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-12/longformer-0-fold/checkpoint-500 (score: 1.1652882099151611).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-12/longformer-model-test-with-exp-moves-encoder-64-1-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-1-12/longformer-model-test-with-exp-moves-encoder-64-1-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3045852347734493b1de31c3fe84d11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▅▂▇▄▂▂▁▁▁▅</td></tr><tr><td>eval/rmse</td><td>█▅▂▇▄▃▂▁▁▁▅</td></tr><tr><td>eval/runtime</td><td>▁▁█▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/samples_per_second</td><td>██▁████████</td></tr><tr><td>eval/steps_per_second</td><td>██▁████████</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▅▄▅▃▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>2.06303</td></tr><tr><td>eval/rmse</td><td>1.43632</td></tr><tr><td>eval/runtime</td><td>4.8077</td></tr><tr><td>eval/samples_per_second</td><td>15.6</td></tr><tr><td>eval/steps_per_second</td><td>3.952</td></tr><tr><td>eval_loss</td><td>2.06303</td></tr><tr><td>eval_rmse</td><td>1.43632</td></tr><tr><td>eval_runtime</td><td>4.8077</td></tr><tr><td>eval_samples_per_second</td><td>15.6</td></tr><tr><td>eval_steps_per_second</td><td>3.952</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7564</td></tr><tr><td>train/total_flos</td><td>5436518823936000.0</td></tr><tr><td>train/train_loss</td><td>1.64167</td></tr><tr><td>train/train_runtime</td><td>661.1855</td></tr><tr><td>train/train_samples_per_second</td><td>3.1</td></tr><tr><td>train/train_steps_per_second</td><td>0.779</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-64-1-12-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1lv7ja8a\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1lv7ja8a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_144556-1lv7ja8a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_145728-1gh2qm59</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1gh2qm59\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-64-4-3-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 64)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.embedding.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.859800</td>\n",
       "      <td>2.373556</td>\n",
       "      <td>1.540635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.044200</td>\n",
       "      <td>2.408084</td>\n",
       "      <td>1.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.159300</td>\n",
       "      <td>2.248860</td>\n",
       "      <td>1.499620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.008400</td>\n",
       "      <td>1.967276</td>\n",
       "      <td>1.402596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.483700</td>\n",
       "      <td>1.279546</td>\n",
       "      <td>1.131170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.504900</td>\n",
       "      <td>1.346921</td>\n",
       "      <td>1.160569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.121000</td>\n",
       "      <td>1.401954</td>\n",
       "      <td>1.184041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.957200</td>\n",
       "      <td>1.383193</td>\n",
       "      <td>1.176093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.710400</td>\n",
       "      <td>1.400962</td>\n",
       "      <td>1.183622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.608100</td>\n",
       "      <td>1.441902</td>\n",
       "      <td>1.200792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-3/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-3/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-3/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-3/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-3/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-3/longformer-0-fold/checkpoint-500 (score: 1.2007923126220703).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-3/longformer-model-test-with-exp-moves-encoder-64-4-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-3/longformer-model-test-with-exp-moves-encoder-64-4-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1351ba7c264526a8e7a89d8261642d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>██▇▅▁▁▂▂▂▂▄</td></tr><tr><td>eval/rmse</td><td>██▇▆▁▁▂▂▂▂▄</td></tr><tr><td>eval/runtime</td><td>▃▅▂▂▂▁▂▄▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▄▁▆▆▆█▇▃▇██</td></tr><tr><td>eval/steps_per_second</td><td>▆▄▇▇▇█▇▅██▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▆▅▄▄▃▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.7202</td></tr><tr><td>eval/rmse</td><td>1.31157</td></tr><tr><td>eval/runtime</td><td>4.6682</td></tr><tr><td>eval/samples_per_second</td><td>16.066</td></tr><tr><td>eval/steps_per_second</td><td>4.07</td></tr><tr><td>eval_loss</td><td>1.7202</td></tr><tr><td>eval_rmse</td><td>1.31157</td></tr><tr><td>eval_runtime</td><td>4.6682</td></tr><tr><td>eval_samples_per_second</td><td>16.066</td></tr><tr><td>eval_steps_per_second</td><td>4.07</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6081</td></tr><tr><td>train/total_flos</td><td>5425085203660800.0</td></tr><tr><td>train/train_loss</td><td>1.51846</td></tr><tr><td>train/train_runtime</td><td>634.2826</td></tr><tr><td>train/train_samples_per_second</td><td>3.232</td></tr><tr><td>train/train_steps_per_second</td><td>0.812</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-64-4-3-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1gh2qm59\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1gh2qm59</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_145728-1gh2qm59/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_150836-gbrgrskz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/gbrgrskz\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-64-4-6-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 64)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>2.451358</td>\n",
       "      <td>1.565681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.105800</td>\n",
       "      <td>2.547534</td>\n",
       "      <td>1.596099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.124300</td>\n",
       "      <td>2.331852</td>\n",
       "      <td>1.527040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.909200</td>\n",
       "      <td>2.064193</td>\n",
       "      <td>1.436730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.467100</td>\n",
       "      <td>2.247305</td>\n",
       "      <td>1.499102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.750900</td>\n",
       "      <td>1.265471</td>\n",
       "      <td>1.124931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.266200</td>\n",
       "      <td>1.184908</td>\n",
       "      <td>1.088535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.037800</td>\n",
       "      <td>1.190463</td>\n",
       "      <td>1.091083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.875800</td>\n",
       "      <td>1.098137</td>\n",
       "      <td>1.047921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.683900</td>\n",
       "      <td>1.071439</td>\n",
       "      <td>1.035103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-6/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-6/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-6/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-6/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-6/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-6/longformer-0-fold/checkpoint-500 (score: 1.0351033210754395).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-6/longformer-model-test-with-exp-moves-encoder-64-4-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-6/longformer-model-test-with-exp-moves-encoder-64-4-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19aaf0996d734adcbd6d6e58c7dec38b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>██▇▆▇▂▂▂▁▁▅</td></tr><tr><td>eval/rmse</td><td>██▇▆▇▂▂▂▁▁▅</td></tr><tr><td>eval/runtime</td><td>▁▁█▂▁▁▁▁▁▂▅</td></tr><tr><td>eval/samples_per_second</td><td>▇▇▁▇▇▇███▇█</td></tr><tr><td>eval/steps_per_second</td><td>██▁▇█████▇▄</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▅▅▃▄▃▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.87855</td></tr><tr><td>eval/rmse</td><td>1.3706</td></tr><tr><td>eval/runtime</td><td>4.6876</td></tr><tr><td>eval/samples_per_second</td><td>16.0</td></tr><tr><td>eval/steps_per_second</td><td>4.053</td></tr><tr><td>eval_loss</td><td>1.87855</td></tr><tr><td>eval_rmse</td><td>1.3706</td></tr><tr><td>eval_runtime</td><td>4.6876</td></tr><tr><td>eval_samples_per_second</td><td>16.0</td></tr><tr><td>eval_steps_per_second</td><td>4.053</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6839</td></tr><tr><td>train/total_flos</td><td>5428896410419200.0</td></tr><tr><td>train/train_loss</td><td>1.59044</td></tr><tr><td>train/train_runtime</td><td>636.0001</td></tr><tr><td>train/train_samples_per_second</td><td>3.223</td></tr><tr><td>train/train_steps_per_second</td><td>0.81</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-64-4-6-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/gbrgrskz\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/gbrgrskz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_150836-gbrgrskz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_151945-2derchqn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/2derchqn\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-64-4-12-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 64)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.10.linear1.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.7.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.9.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.6.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.10.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.10.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.7.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.bias', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear2.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.linear2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.950400</td>\n",
       "      <td>2.738398</td>\n",
       "      <td>1.654810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.990100</td>\n",
       "      <td>2.115010</td>\n",
       "      <td>1.454307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.869500</td>\n",
       "      <td>1.562728</td>\n",
       "      <td>1.250091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.897900</td>\n",
       "      <td>1.644623</td>\n",
       "      <td>1.282429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.316000</td>\n",
       "      <td>1.162155</td>\n",
       "      <td>1.078033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.351700</td>\n",
       "      <td>1.088134</td>\n",
       "      <td>1.043137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>1.102393</td>\n",
       "      <td>1.049949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.954500</td>\n",
       "      <td>1.000424</td>\n",
       "      <td>1.000212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.808800</td>\n",
       "      <td>0.935016</td>\n",
       "      <td>0.966963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.624900</td>\n",
       "      <td>0.963919</td>\n",
       "      <td>0.981794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-12/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-12/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-12/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-12/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-12/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-12/longformer-0-fold/checkpoint-500 (score: 0.9817939400672913).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-12/longformer-model-test-with-exp-moves-encoder-64-4-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-4-12/longformer-model-test-with-exp-moves-encoder-64-4-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c16a5e7324a413ab6cafc6b56a04755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▆▃▄▂▂▂▁▁▁▄</td></tr><tr><td>eval/rmse</td><td>█▆▄▄▂▂▂▁▁▁▄</td></tr><tr><td>eval/runtime</td><td>▁█▁▇▁▄▁▂▁▂▂</td></tr><tr><td>eval/samples_per_second</td><td>█▁█▂█▅█▇█▇█</td></tr><tr><td>eval/steps_per_second</td><td>█▁█▂█▅█▇█▇▇</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▅▅▃▃▂▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.63627</td></tr><tr><td>eval/rmse</td><td>1.27917</td></tr><tr><td>eval/runtime</td><td>4.7527</td></tr><tr><td>eval/samples_per_second</td><td>15.78</td></tr><tr><td>eval/steps_per_second</td><td>3.998</td></tr><tr><td>eval_loss</td><td>1.63627</td></tr><tr><td>eval_rmse</td><td>1.27917</td></tr><tr><td>eval_runtime</td><td>4.7527</td></tr><tr><td>eval_samples_per_second</td><td>15.78</td></tr><tr><td>eval_steps_per_second</td><td>3.998</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6249</td></tr><tr><td>train/total_flos</td><td>5436518823936000.0</td></tr><tr><td>train/train_loss</td><td>1.44965</td></tr><tr><td>train/train_runtime</td><td>645.5364</td></tr><tr><td>train/train_samples_per_second</td><td>3.176</td></tr><tr><td>train/train_steps_per_second</td><td>0.798</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-64-4-12-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/2derchqn\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/2derchqn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_151945-2derchqn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_153100-38vk342j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/38vk342j\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-64-8-3-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 64)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.embedding.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.890500</td>\n",
       "      <td>2.299375</td>\n",
       "      <td>1.516369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.027500</td>\n",
       "      <td>2.456084</td>\n",
       "      <td>1.567190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.144600</td>\n",
       "      <td>2.262610</td>\n",
       "      <td>1.504197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.890700</td>\n",
       "      <td>1.778748</td>\n",
       "      <td>1.333697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.422300</td>\n",
       "      <td>1.548005</td>\n",
       "      <td>1.244189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.495200</td>\n",
       "      <td>1.344011</td>\n",
       "      <td>1.159315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.061200</td>\n",
       "      <td>1.450045</td>\n",
       "      <td>1.204178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.928000</td>\n",
       "      <td>1.286836</td>\n",
       "      <td>1.134388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.750800</td>\n",
       "      <td>1.236443</td>\n",
       "      <td>1.111954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.624500</td>\n",
       "      <td>1.238668</td>\n",
       "      <td>1.112954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-3/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-3/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-3/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-3/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-3/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-3/longformer-0-fold/checkpoint-500 (score: 1.1129544973373413).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-3/longformer-model-test-with-exp-moves-encoder-64-8-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-3/longformer-model-test-with-exp-moves-encoder-64-8-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eea6d3099d84e43b0b10994ea73f678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>▇█▇▄▃▂▂▁▁▁▅</td></tr><tr><td>eval/rmse</td><td>▇█▇▄▃▂▂▁▁▁▅</td></tr><tr><td>eval/runtime</td><td>▂▁▁▁▁▁▁▃▁▂█</td></tr><tr><td>eval/samples_per_second</td><td>▃▇▇██▇▇▁█▅▅</td></tr><tr><td>eval/steps_per_second</td><td>▇██████▆█▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▆▅▃▄▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.95847</td></tr><tr><td>eval/rmse</td><td>1.39945</td></tr><tr><td>eval/runtime</td><td>4.6938</td></tr><tr><td>eval/samples_per_second</td><td>15.979</td></tr><tr><td>eval/steps_per_second</td><td>4.048</td></tr><tr><td>eval_loss</td><td>1.95847</td></tr><tr><td>eval_rmse</td><td>1.39945</td></tr><tr><td>eval_runtime</td><td>4.6938</td></tr><tr><td>eval_samples_per_second</td><td>15.979</td></tr><tr><td>eval_steps_per_second</td><td>4.048</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6245</td></tr><tr><td>train/total_flos</td><td>5425085203660800.0</td></tr><tr><td>train/train_loss</td><td>1.49752</td></tr><tr><td>train/train_runtime</td><td>619.9371</td></tr><tr><td>train/train_samples_per_second</td><td>3.307</td></tr><tr><td>train/train_steps_per_second</td><td>0.831</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-64-8-3-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/38vk342j\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/38vk342j</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_153100-38vk342j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_154146-n4eqdg2y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/n4eqdg2y\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-64-8-6-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 64)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.971200</td>\n",
       "      <td>2.426296</td>\n",
       "      <td>1.557657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.071500</td>\n",
       "      <td>2.518315</td>\n",
       "      <td>1.586920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.111700</td>\n",
       "      <td>2.057681</td>\n",
       "      <td>1.434462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.781600</td>\n",
       "      <td>1.820879</td>\n",
       "      <td>1.349400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.342400</td>\n",
       "      <td>1.325941</td>\n",
       "      <td>1.151495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.490300</td>\n",
       "      <td>1.331877</td>\n",
       "      <td>1.154070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.144200</td>\n",
       "      <td>1.435157</td>\n",
       "      <td>1.197980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.960500</td>\n",
       "      <td>1.337400</td>\n",
       "      <td>1.156460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.840300</td>\n",
       "      <td>1.189999</td>\n",
       "      <td>1.090871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.665600</td>\n",
       "      <td>1.258473</td>\n",
       "      <td>1.121817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-6/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-6/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-6/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-6/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-6/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-6/longformer-0-fold/checkpoint-500 (score: 1.121816873550415).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-6/longformer-model-test-with-exp-moves-encoder-64-8-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-6/longformer-model-test-with-exp-moves-encoder-64-8-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c122dda2e5b416db39459fc8f26e36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>██▆▄▂▂▂▂▁▁▅</td></tr><tr><td>eval/rmse</td><td>██▆▅▂▂▃▂▁▁▅</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▂▁▁█▁▂</td></tr><tr><td>eval/samples_per_second</td><td>█████▇██▁██</td></tr><tr><td>eval/steps_per_second</td><td>█████▇██▁█▇</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▅▄▃▄▂▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.96903</td></tr><tr><td>eval/rmse</td><td>1.40322</td></tr><tr><td>eval/runtime</td><td>4.698</td></tr><tr><td>eval/samples_per_second</td><td>15.964</td></tr><tr><td>eval/steps_per_second</td><td>4.044</td></tr><tr><td>eval_loss</td><td>1.96903</td></tr><tr><td>eval_rmse</td><td>1.40322</td></tr><tr><td>eval_runtime</td><td>4.698</td></tr><tr><td>eval_samples_per_second</td><td>15.964</td></tr><tr><td>eval_steps_per_second</td><td>4.044</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6656</td></tr><tr><td>train/total_flos</td><td>5428896410419200.0</td></tr><tr><td>train/train_loss</td><td>1.51365</td></tr><tr><td>train/train_runtime</td><td>635.4773</td></tr><tr><td>train/train_samples_per_second</td><td>3.226</td></tr><tr><td>train/train_steps_per_second</td><td>0.81</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-64-8-6-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/n4eqdg2y\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/n4eqdg2y</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_154146-n4eqdg2y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_155252-1nf71li3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1nf71li3\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-64-8-12-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 64)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.10.linear1.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.7.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.9.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.6.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.10.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.10.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.7.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.bias', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear2.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.linear2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:37, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.952300</td>\n",
       "      <td>3.027869</td>\n",
       "      <td>1.740077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.036100</td>\n",
       "      <td>2.082303</td>\n",
       "      <td>1.443019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.925700</td>\n",
       "      <td>1.613737</td>\n",
       "      <td>1.270329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.845900</td>\n",
       "      <td>1.671374</td>\n",
       "      <td>1.292816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.305300</td>\n",
       "      <td>1.139758</td>\n",
       "      <td>1.067595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.386800</td>\n",
       "      <td>1.204270</td>\n",
       "      <td>1.097393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.979900</td>\n",
       "      <td>1.220801</td>\n",
       "      <td>1.104899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.940518</td>\n",
       "      <td>0.969803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.794900</td>\n",
       "      <td>0.894603</td>\n",
       "      <td>0.945834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.605900</td>\n",
       "      <td>0.947805</td>\n",
       "      <td>0.973553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-12/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-12/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-12/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-12/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-12/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-12/longformer-0-fold/checkpoint-500 (score: 0.9735528826713562).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-12/longformer-model-test-with-exp-moves-encoder-64-8-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-64-8-12/longformer-model-test-with-exp-moves-encoder-64-8-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6bd80c184e48868ec986dae49a8a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▅▃▄▂▂▂▁▁▁▄</td></tr><tr><td>eval/rmse</td><td>█▅▄▄▂▂▂▁▁▁▄</td></tr><tr><td>eval/runtime</td><td>▁█▁▄▁▁▁▁▁▂▄</td></tr><tr><td>eval/samples_per_second</td><td>█▁█▅█████▆▆</td></tr><tr><td>eval/steps_per_second</td><td>█▁█▅█████▆▅</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▅▅▃▃▂▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.66652</td></tr><tr><td>eval/rmse</td><td>1.29094</td></tr><tr><td>eval/runtime</td><td>4.9722</td></tr><tr><td>eval/samples_per_second</td><td>15.084</td></tr><tr><td>eval/steps_per_second</td><td>3.821</td></tr><tr><td>eval_loss</td><td>1.66652</td></tr><tr><td>eval_rmse</td><td>1.29094</td></tr><tr><td>eval_runtime</td><td>4.9722</td></tr><tr><td>eval_samples_per_second</td><td>15.084</td></tr><tr><td>eval_steps_per_second</td><td>3.821</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6059</td></tr><tr><td>train/total_flos</td><td>5436518823936000.0</td></tr><tr><td>train/train_loss</td><td>1.43804</td></tr><tr><td>train/train_runtime</td><td>639.2607</td></tr><tr><td>train/train_samples_per_second</td><td>3.207</td></tr><tr><td>train/train_steps_per_second</td><td>0.806</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-64-8-12-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1nf71li3\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1nf71li3</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_155252-1nf71li3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_160358-uwzxw88l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/uwzxw88l\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-128-1-3-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.embedding.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.864100</td>\n",
       "      <td>2.185182</td>\n",
       "      <td>1.478236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.725200</td>\n",
       "      <td>1.446832</td>\n",
       "      <td>1.202843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.393100</td>\n",
       "      <td>1.422126</td>\n",
       "      <td>1.192529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.578800</td>\n",
       "      <td>1.569786</td>\n",
       "      <td>1.252911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.863700</td>\n",
       "      <td>1.369437</td>\n",
       "      <td>1.170229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.081700</td>\n",
       "      <td>1.393509</td>\n",
       "      <td>1.180470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.759800</td>\n",
       "      <td>1.004144</td>\n",
       "      <td>1.002070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.615300</td>\n",
       "      <td>1.010973</td>\n",
       "      <td>1.005472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>1.094244</td>\n",
       "      <td>1.046061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>1.046562</td>\n",
       "      <td>1.023016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-3/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-3/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-3/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-3/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-3/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-3/longformer-0-fold/checkpoint-500 (score: 1.023016095161438).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-3/longformer-model-test-with-exp-moves-encoder-128-1-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-3/longformer-model-test-with-exp-moves-encoder-128-1-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c829ed954aa745319faea1603852ca6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▄▃▄▃▃▁▁▂▁▄</td></tr><tr><td>eval/rmse</td><td>█▄▄▅▃▄▁▁▂▁▄</td></tr><tr><td>eval/runtime</td><td>▁▁▁▂▂▃▂▃▁▅█</td></tr><tr><td>eval/samples_per_second</td><td>▇▇▆▅▆▄▆▃▇▁█</td></tr><tr><td>eval/steps_per_second</td><td>███▇▇▆▇▆█▄▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▂▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.4309</td></tr><tr><td>eval/rmse</td><td>1.1962</td></tr><tr><td>eval/runtime</td><td>4.6724</td></tr><tr><td>eval/samples_per_second</td><td>16.052</td></tr><tr><td>eval/steps_per_second</td><td>4.066</td></tr><tr><td>eval_loss</td><td>1.4309</td></tr><tr><td>eval_rmse</td><td>1.1962</td></tr><tr><td>eval_runtime</td><td>4.6724</td></tr><tr><td>eval_samples_per_second</td><td>16.052</td></tr><tr><td>eval_steps_per_second</td><td>4.066</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.36</td></tr><tr><td>train/total_flos</td><td>5442525827481600.0</td></tr><tr><td>train/train_loss</td><td>1.14698</td></tr><tr><td>train/train_runtime</td><td>623.8305</td></tr><tr><td>train/train_samples_per_second</td><td>3.286</td></tr><tr><td>train/train_steps_per_second</td><td>0.826</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-128-1-3-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/uwzxw88l\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/uwzxw88l</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_160358-uwzxw88l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_161449-2sz30okk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/2sz30okk\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-128-1-6-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.071700</td>\n",
       "      <td>2.352088</td>\n",
       "      <td>1.533652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.827300</td>\n",
       "      <td>1.622253</td>\n",
       "      <td>1.273677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.441824</td>\n",
       "      <td>1.200760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.540200</td>\n",
       "      <td>1.797707</td>\n",
       "      <td>1.340786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.040100</td>\n",
       "      <td>1.344079</td>\n",
       "      <td>1.159344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>1.352468</td>\n",
       "      <td>1.162957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.859300</td>\n",
       "      <td>1.211240</td>\n",
       "      <td>1.100563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.714500</td>\n",
       "      <td>1.105690</td>\n",
       "      <td>1.051518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.553900</td>\n",
       "      <td>1.085402</td>\n",
       "      <td>1.041826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>1.091338</td>\n",
       "      <td>1.044671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-6/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-6/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-6/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-6/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-6/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-6/longformer-0-fold/checkpoint-500 (score: 1.0446711778640747).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-6/longformer-model-test-with-exp-moves-encoder-128-1-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-6/longformer-model-test-with-exp-moves-encoder-128-1-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "800aa33edb544cbbabb11c23ecf9d3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▄▃▅▂▂▂▁▁▁▃</td></tr><tr><td>eval/rmse</td><td>█▄▃▅▃▃▂▁▁▁▃</td></tr><tr><td>eval/runtime</td><td>▁▂▁▁█▁▁▁▁▁▃</td></tr><tr><td>eval/samples_per_second</td><td>█▆▇▇▁███▇██</td></tr><tr><td>eval/steps_per_second</td><td>█▇██▁█████▆</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▃▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.42988</td></tr><tr><td>eval/rmse</td><td>1.19578</td></tr><tr><td>eval/runtime</td><td>4.6974</td></tr><tr><td>eval/samples_per_second</td><td>15.966</td></tr><tr><td>eval/steps_per_second</td><td>4.045</td></tr><tr><td>eval_loss</td><td>1.42988</td></tr><tr><td>eval_rmse</td><td>1.19578</td></tr><tr><td>eval_runtime</td><td>4.6974</td></tr><tr><td>eval_samples_per_second</td><td>15.966</td></tr><tr><td>eval_steps_per_second</td><td>4.045</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4516</td></tr><tr><td>train/total_flos</td><td>5457577192243200.0</td></tr><tr><td>train/train_loss</td><td>1.24084</td></tr><tr><td>train/train_runtime</td><td>625.1169</td></tr><tr><td>train/train_samples_per_second</td><td>3.279</td></tr><tr><td>train/train_steps_per_second</td><td>0.824</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-128-1-6-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/2sz30okk\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/2sz30okk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_161449-2sz30okk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_162537-211juclr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/211juclr\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-128-1-12-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.10.linear1.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.7.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.9.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.6.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.10.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.10.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.7.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.bias', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear2.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.linear2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.996700</td>\n",
       "      <td>2.298898</td>\n",
       "      <td>1.516212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.856900</td>\n",
       "      <td>1.528867</td>\n",
       "      <td>1.236473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.435400</td>\n",
       "      <td>1.168882</td>\n",
       "      <td>1.081149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.304100</td>\n",
       "      <td>1.547312</td>\n",
       "      <td>1.243910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.750500</td>\n",
       "      <td>1.312079</td>\n",
       "      <td>1.145460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.006200</td>\n",
       "      <td>1.632515</td>\n",
       "      <td>1.277699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.701300</td>\n",
       "      <td>1.117197</td>\n",
       "      <td>1.056975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.442700</td>\n",
       "      <td>1.188829</td>\n",
       "      <td>1.090334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.368500</td>\n",
       "      <td>1.182820</td>\n",
       "      <td>1.087575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.327800</td>\n",
       "      <td>1.145971</td>\n",
       "      <td>1.070500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-12/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-12/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-12/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-12/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-12/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-12/longformer-0-fold/checkpoint-500 (score: 1.0705002546310425).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-12/longformer-model-test-with-exp-moves-encoder-128-1-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-1-12/longformer-model-test-with-exp-moves-encoder-128-1-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36c59284e654afeb36ce600baf6a8f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▁▄▂▄▁▁▁▁▄</td></tr><tr><td>eval/rmse</td><td>█▄▁▄▂▄▁▂▁▁▄</td></tr><tr><td>eval/runtime</td><td>▂▄▁▁▁▁▁▂▁▂█</td></tr><tr><td>eval/samples_per_second</td><td>▆▁▇██▇█▄█▅▆</td></tr><tr><td>eval/steps_per_second</td><td>▇▅█████▆█▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▂▃▂▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.63493</td></tr><tr><td>eval/rmse</td><td>1.27864</td></tr><tr><td>eval/runtime</td><td>4.7722</td></tr><tr><td>eval/samples_per_second</td><td>15.716</td></tr><tr><td>eval/steps_per_second</td><td>3.981</td></tr><tr><td>eval_loss</td><td>1.63493</td></tr><tr><td>eval_rmse</td><td>1.27864</td></tr><tr><td>eval_runtime</td><td>4.7722</td></tr><tr><td>eval_samples_per_second</td><td>15.716</td></tr><tr><td>eval_steps_per_second</td><td>3.981</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3278</td></tr><tr><td>train/total_flos</td><td>5487679921766400.0</td></tr><tr><td>train/train_loss</td><td>1.09877</td></tr><tr><td>train/train_runtime</td><td>634.4611</td></tr><tr><td>train/train_samples_per_second</td><td>3.231</td></tr><tr><td>train/train_steps_per_second</td><td>0.812</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-128-1-12-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/211juclr\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/211juclr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_162537-211juclr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_163634-7psai49e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/7psai49e\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-128-4-3-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.embedding.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.865200</td>\n",
       "      <td>2.199707</td>\n",
       "      <td>1.483141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.636500</td>\n",
       "      <td>1.424186</td>\n",
       "      <td>1.193393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.570500</td>\n",
       "      <td>1.526094</td>\n",
       "      <td>1.235352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.715400</td>\n",
       "      <td>1.731022</td>\n",
       "      <td>1.315683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.984500</td>\n",
       "      <td>2.001344</td>\n",
       "      <td>1.414689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.075700</td>\n",
       "      <td>1.137526</td>\n",
       "      <td>1.066549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.861100</td>\n",
       "      <td>1.099987</td>\n",
       "      <td>1.048803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.581300</td>\n",
       "      <td>1.154772</td>\n",
       "      <td>1.074603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>1.151911</td>\n",
       "      <td>1.073271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.329400</td>\n",
       "      <td>1.109527</td>\n",
       "      <td>1.053341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-3/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-3/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-3/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-3/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-3/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-3/longformer-0-fold/checkpoint-500 (score: 1.0533406734466553).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-3/longformer-model-test-with-exp-moves-encoder-128-4-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-3/longformer-model-test-with-exp-moves-encoder-128-4-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937cc8813c2f4d85a22e15906f2f33e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▄▅▇▁▁▁▁▁▄</td></tr><tr><td>eval/rmse</td><td>█▃▄▅▇▁▁▁▁▁▄</td></tr><tr><td>eval/runtime</td><td>▂▃▁▂▂█▂▃▁▁▅</td></tr><tr><td>eval/samples_per_second</td><td>▇▅█▇▇▁▇▆█▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▇▅█▇▇▁▇▆█▇▄</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▅▃▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.51697</td></tr><tr><td>eval/rmse</td><td>1.23165</td></tr><tr><td>eval/runtime</td><td>4.704</td></tr><tr><td>eval/samples_per_second</td><td>15.944</td></tr><tr><td>eval/steps_per_second</td><td>4.039</td></tr><tr><td>eval_loss</td><td>1.51697</td></tr><tr><td>eval_rmse</td><td>1.23165</td></tr><tr><td>eval_runtime</td><td>4.704</td></tr><tr><td>eval_samples_per_second</td><td>15.944</td></tr><tr><td>eval_steps_per_second</td><td>4.039</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3294</td></tr><tr><td>train/total_flos</td><td>5442525827481600.0</td></tr><tr><td>train/train_loss</td><td>1.18677</td></tr><tr><td>train/train_runtime</td><td>619.5179</td></tr><tr><td>train/train_samples_per_second</td><td>3.309</td></tr><tr><td>train/train_steps_per_second</td><td>0.831</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-128-4-3-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/7psai49e\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/7psai49e</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_163634-7psai49e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_164717-3pvcg1ek</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/3pvcg1ek\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-128-4-6-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.039900</td>\n",
       "      <td>2.419046</td>\n",
       "      <td>1.555328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.880200</td>\n",
       "      <td>1.507460</td>\n",
       "      <td>1.227787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.460300</td>\n",
       "      <td>1.186160</td>\n",
       "      <td>1.089110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.460100</td>\n",
       "      <td>1.486295</td>\n",
       "      <td>1.219137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.790900</td>\n",
       "      <td>1.174272</td>\n",
       "      <td>1.083638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.027600</td>\n",
       "      <td>1.158121</td>\n",
       "      <td>1.076160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.685400</td>\n",
       "      <td>1.221454</td>\n",
       "      <td>1.105194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>1.067447</td>\n",
       "      <td>1.033173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.366500</td>\n",
       "      <td>1.041635</td>\n",
       "      <td>1.020605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>1.151513</td>\n",
       "      <td>1.073086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-6/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-6/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-6/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-6/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-6/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-6/longformer-0-fold/checkpoint-500 (score: 1.0730856657028198).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-6/longformer-model-test-with-exp-moves-encoder-128-4-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-6/longformer-model-test-with-exp-moves-encoder-128-4-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2a416cbfa34fcda6507c45155eb0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▂▃▂▂▂▁▁▂▂</td></tr><tr><td>eval/rmse</td><td>█▄▂▄▂▂▂▁▁▂▃</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▂▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>██████▇███▁</td></tr><tr><td>eval/steps_per_second</td><td>██████▇███▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▂▃▂▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.30582</td></tr><tr><td>eval/rmse</td><td>1.14273</td></tr><tr><td>eval/runtime</td><td>5.3664</td></tr><tr><td>eval/samples_per_second</td><td>13.976</td></tr><tr><td>eval/steps_per_second</td><td>3.541</td></tr><tr><td>eval_loss</td><td>1.30582</td></tr><tr><td>eval_rmse</td><td>1.14273</td></tr><tr><td>eval_runtime</td><td>5.3664</td></tr><tr><td>eval_samples_per_second</td><td>13.976</td></tr><tr><td>eval_steps_per_second</td><td>3.541</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3228</td></tr><tr><td>train/total_flos</td><td>5457577192243200.0</td></tr><tr><td>train/train_loss</td><td>1.12411</td></tr><tr><td>train/train_runtime</td><td>643.8519</td></tr><tr><td>train/train_samples_per_second</td><td>3.184</td></tr><tr><td>train/train_steps_per_second</td><td>0.8</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-128-4-6-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/3pvcg1ek\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/3pvcg1ek</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_164717-3pvcg1ek/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_165826-120ewt6p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/120ewt6p\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-128-4-12-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.10.linear1.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.7.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.9.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.6.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.10.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.10.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.7.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.bias', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear2.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.linear2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.967800</td>\n",
       "      <td>2.334856</td>\n",
       "      <td>1.528024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.746100</td>\n",
       "      <td>1.385068</td>\n",
       "      <td>1.176889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.346600</td>\n",
       "      <td>1.842300</td>\n",
       "      <td>1.357314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.676000</td>\n",
       "      <td>1.621493</td>\n",
       "      <td>1.273379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.918000</td>\n",
       "      <td>1.345934</td>\n",
       "      <td>1.160144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.054700</td>\n",
       "      <td>1.250565</td>\n",
       "      <td>1.118287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.737100</td>\n",
       "      <td>1.183011</td>\n",
       "      <td>1.087663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>1.247080</td>\n",
       "      <td>1.116727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.531500</td>\n",
       "      <td>1.237110</td>\n",
       "      <td>1.112254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.386700</td>\n",
       "      <td>1.201586</td>\n",
       "      <td>1.096169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-12/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-12/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-12/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-12/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-12/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-12/longformer-0-fold/checkpoint-500 (score: 1.0961687564849854).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-12/longformer-model-test-with-exp-moves-encoder-128-4-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-4-12/longformer-model-test-with-exp-moves-encoder-128-4-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f94c11d7b247fca8de1fe58a102744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▅▄▂▁▁▁▁▁▃</td></tr><tr><td>eval/rmse</td><td>█▂▅▄▂▁▁▁▁▁▃</td></tr><tr><td>eval/runtime</td><td>▂▂▁▁▁▃▃▁▁▂█</td></tr><tr><td>eval/samples_per_second</td><td>▃▅▇▇█▂▁▇▆▄▅</td></tr><tr><td>eval/steps_per_second</td><td>▇▇███▆▆██▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▂▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.54722</td></tr><tr><td>eval/rmse</td><td>1.24387</td></tr><tr><td>eval/runtime</td><td>4.7727</td></tr><tr><td>eval/samples_per_second</td><td>15.715</td></tr><tr><td>eval/steps_per_second</td><td>3.981</td></tr><tr><td>eval_loss</td><td>1.54722</td></tr><tr><td>eval_rmse</td><td>1.24387</td></tr><tr><td>eval_runtime</td><td>4.7727</td></tr><tr><td>eval_samples_per_second</td><td>15.715</td></tr><tr><td>eval_steps_per_second</td><td>3.981</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3867</td></tr><tr><td>train/total_flos</td><td>5487679921766400.0</td></tr><tr><td>train/train_loss</td><td>1.18111</td></tr><tr><td>train/train_runtime</td><td>637.7493</td></tr><tr><td>train/train_samples_per_second</td><td>3.214</td></tr><tr><td>train/train_steps_per_second</td><td>0.808</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-128-4-12-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/120ewt6p\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/120ewt6p</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_165826-120ewt6p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_170928-2eyrh13t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/2eyrh13t\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-128-8-3-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.embedding.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.871700</td>\n",
       "      <td>2.266132</td>\n",
       "      <td>1.505368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.772700</td>\n",
       "      <td>1.278119</td>\n",
       "      <td>1.130539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.427400</td>\n",
       "      <td>1.242535</td>\n",
       "      <td>1.114691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.447500</td>\n",
       "      <td>1.380662</td>\n",
       "      <td>1.175016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.884600</td>\n",
       "      <td>1.002101</td>\n",
       "      <td>1.001050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.078200</td>\n",
       "      <td>1.053041</td>\n",
       "      <td>1.026178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.837100</td>\n",
       "      <td>1.022192</td>\n",
       "      <td>1.011035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>1.022153</td>\n",
       "      <td>1.011016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>1.019335</td>\n",
       "      <td>1.009621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.392300</td>\n",
       "      <td>0.994140</td>\n",
       "      <td>0.997066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-3/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-3/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-3/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-3/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-3/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-3/longformer-0-fold/checkpoint-500 (score: 0.9970656633377075).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-3/longformer-model-test-with-exp-moves-encoder-128-8-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-3/longformer-model-test-with-exp-moves-encoder-128-8-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46de4a8c83014109bfb2a77c51567f66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▃▂▃▁▁▁▁▁▁▃</td></tr><tr><td>eval/rmse</td><td>█▃▃▃▁▁▁▁▁▁▄</td></tr><tr><td>eval/runtime</td><td>▃▆▁█▂▂▁▁▂▃█</td></tr><tr><td>eval/samples_per_second</td><td>▆▃█▁▇▇██▇▆█</td></tr><tr><td>eval/steps_per_second</td><td>▆▃█▁▇▇██▇▆▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▂▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.40262</td></tr><tr><td>eval/rmse</td><td>1.18432</td></tr><tr><td>eval/runtime</td><td>4.6646</td></tr><tr><td>eval/samples_per_second</td><td>16.078</td></tr><tr><td>eval/steps_per_second</td><td>4.073</td></tr><tr><td>eval_loss</td><td>1.40262</td></tr><tr><td>eval_rmse</td><td>1.18432</td></tr><tr><td>eval_runtime</td><td>4.6646</td></tr><tr><td>eval_samples_per_second</td><td>16.078</td></tr><tr><td>eval_steps_per_second</td><td>4.073</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3923</td></tr><tr><td>train/total_flos</td><td>5442525827481600.0</td></tr><tr><td>train/train_loss</td><td>1.15079</td></tr><tr><td>train/train_runtime</td><td>614.3707</td></tr><tr><td>train/train_samples_per_second</td><td>3.337</td></tr><tr><td>train/train_steps_per_second</td><td>0.838</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-128-8-3-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/2eyrh13t\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/2eyrh13t</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_170928-2eyrh13t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_172001-241ifhyk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/241ifhyk\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-128-8-6-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.036200</td>\n",
       "      <td>2.427985</td>\n",
       "      <td>1.558199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.888500</td>\n",
       "      <td>1.672677</td>\n",
       "      <td>1.293320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.530700</td>\n",
       "      <td>1.408171</td>\n",
       "      <td>1.186664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.888600</td>\n",
       "      <td>1.907667</td>\n",
       "      <td>1.381183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.891600</td>\n",
       "      <td>1.275053</td>\n",
       "      <td>1.129183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.092500</td>\n",
       "      <td>1.286419</td>\n",
       "      <td>1.134204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.808400</td>\n",
       "      <td>1.092835</td>\n",
       "      <td>1.045388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.680800</td>\n",
       "      <td>1.188337</td>\n",
       "      <td>1.090109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.489100</td>\n",
       "      <td>1.235098</td>\n",
       "      <td>1.111350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>1.218594</td>\n",
       "      <td>1.103899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-6/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-6/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-6/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-6/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-6/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-6/longformer-0-fold/checkpoint-500 (score: 1.1038994789123535).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-6/longformer-model-test-with-exp-moves-encoder-128-8-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-6/longformer-model-test-with-exp-moves-encoder-128-8-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df89dc9b6eb4ad18b05a75fe3597130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▄▃▅▂▂▁▂▂▂▃</td></tr><tr><td>eval/rmse</td><td>█▄▃▆▂▂▁▂▂▂▃</td></tr><tr><td>eval/runtime</td><td>▃▇▆▂▁▁▁▅▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▅▁▂▆▇██▄█▇█</td></tr><tr><td>eval/steps_per_second</td><td>▆▂▃▇███▄██▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▅▂▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.38173</td></tr><tr><td>eval/rmse</td><td>1.17547</td></tr><tr><td>eval/runtime</td><td>4.7001</td></tr><tr><td>eval/samples_per_second</td><td>15.957</td></tr><tr><td>eval/steps_per_second</td><td>4.043</td></tr><tr><td>eval_loss</td><td>1.38173</td></tr><tr><td>eval_rmse</td><td>1.17547</td></tr><tr><td>eval_runtime</td><td>4.7001</td></tr><tr><td>eval_samples_per_second</td><td>15.957</td></tr><tr><td>eval_steps_per_second</td><td>4.043</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3922</td></tr><tr><td>train/total_flos</td><td>5457577192243200.0</td></tr><tr><td>train/train_loss</td><td>1.24413</td></tr><tr><td>train/train_runtime</td><td>623.2941</td></tr><tr><td>train/train_samples_per_second</td><td>3.289</td></tr><tr><td>train/train_steps_per_second</td><td>0.826</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-128-8-6-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/241ifhyk\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/241ifhyk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_172001-241ifhyk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_173047-1knuxk6b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1knuxk6b\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-128-8-12-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.10.linear1.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.7.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.9.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.6.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.10.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.10.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.7.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.bias', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear2.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.linear2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.005900</td>\n",
       "      <td>2.305271</td>\n",
       "      <td>1.518312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.772700</td>\n",
       "      <td>1.391132</td>\n",
       "      <td>1.179463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.581600</td>\n",
       "      <td>2.086727</td>\n",
       "      <td>1.444551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.721900</td>\n",
       "      <td>1.670373</td>\n",
       "      <td>1.292429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.889900</td>\n",
       "      <td>1.182289</td>\n",
       "      <td>1.087331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.171700</td>\n",
       "      <td>1.191584</td>\n",
       "      <td>1.091597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.864600</td>\n",
       "      <td>1.615912</td>\n",
       "      <td>1.271185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.710800</td>\n",
       "      <td>1.183337</td>\n",
       "      <td>1.087813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.496100</td>\n",
       "      <td>1.355035</td>\n",
       "      <td>1.164060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>1.252407</td>\n",
       "      <td>1.119110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-12/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-12/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-12/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-12/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-12/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-12/longformer-0-fold/checkpoint-500 (score: 1.1191099882125854).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-12/longformer-model-test-with-exp-moves-encoder-128-8-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-128-8-12/longformer-model-test-with-exp-moves-encoder-128-8-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659daf7acbca4f189a1d086fdd336649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▂▇▄▁▁▄▁▂▁▆</td></tr><tr><td>eval/rmse</td><td>█▂▇▄▁▁▄▁▂▂▆</td></tr><tr><td>eval/runtime</td><td>▂▅▂▇▂▁▂▄▂▄█</td></tr><tr><td>eval/samples_per_second</td><td>▇▄▇▁▇█▆▅▆▅█</td></tr><tr><td>eval/steps_per_second</td><td>▇▄▇▂▇█▇▅▇▅▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▄▅▂▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.91092</td></tr><tr><td>eval/rmse</td><td>1.38236</td></tr><tr><td>eval/runtime</td><td>4.7674</td></tr><tr><td>eval/samples_per_second</td><td>15.732</td></tr><tr><td>eval/steps_per_second</td><td>3.985</td></tr><tr><td>eval_loss</td><td>1.91092</td></tr><tr><td>eval_rmse</td><td>1.38236</td></tr><tr><td>eval_runtime</td><td>4.7674</td></tr><tr><td>eval_samples_per_second</td><td>15.732</td></tr><tr><td>eval_steps_per_second</td><td>3.985</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4171</td></tr><tr><td>train/total_flos</td><td>5487679921766400.0</td></tr><tr><td>train/train_loss</td><td>1.24135</td></tr><tr><td>train/train_runtime</td><td>639.2738</td></tr><tr><td>train/train_samples_per_second</td><td>3.207</td></tr><tr><td>train/train_steps_per_second</td><td>0.806</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-128-8-12-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1knuxk6b\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1knuxk6b</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_173047-1knuxk6b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_174150-2za96u2c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/2za96u2c\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-256-1-3-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 256)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.embedding.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.729600</td>\n",
       "      <td>2.424771</td>\n",
       "      <td>1.557168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.963500</td>\n",
       "      <td>2.216672</td>\n",
       "      <td>1.488849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.815000</td>\n",
       "      <td>1.626765</td>\n",
       "      <td>1.275447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.846700</td>\n",
       "      <td>2.144692</td>\n",
       "      <td>1.464477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.147700</td>\n",
       "      <td>1.344276</td>\n",
       "      <td>1.159429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.197400</td>\n",
       "      <td>1.240154</td>\n",
       "      <td>1.113622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.959200</td>\n",
       "      <td>1.202457</td>\n",
       "      <td>1.096566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.806700</td>\n",
       "      <td>1.312971</td>\n",
       "      <td>1.145849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.778000</td>\n",
       "      <td>1.270348</td>\n",
       "      <td>1.127097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.500800</td>\n",
       "      <td>1.232003</td>\n",
       "      <td>1.109956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-3/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-3/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-3/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-3/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-3/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-3/longformer-0-fold/checkpoint-500 (score: 1.1099562644958496).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-3/longformer-model-test-with-exp-moves-encoder-256-1-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-3/longformer-model-test-with-exp-moves-encoder-256-1-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323885a4b6414f6cb8710302132ba0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▇▃▆▂▁▁▂▁▁▄</td></tr><tr><td>eval/rmse</td><td>█▇▄▇▂▁▁▂▁▁▅</td></tr><tr><td>eval/runtime</td><td>█▂▁▁▁▁▁▁▁▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▁▆█▇▇█▇████</td></tr><tr><td>eval/steps_per_second</td><td>▁▇████████▇</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▅▅▃▃▂▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.76168</td></tr><tr><td>eval/rmse</td><td>1.32728</td></tr><tr><td>eval/runtime</td><td>4.6611</td></tr><tr><td>eval/samples_per_second</td><td>16.091</td></tr><tr><td>eval/steps_per_second</td><td>4.076</td></tr><tr><td>eval_loss</td><td>1.76168</td></tr><tr><td>eval_rmse</td><td>1.32728</td></tr><tr><td>eval_runtime</td><td>4.6611</td></tr><tr><td>eval_samples_per_second</td><td>16.091</td></tr><tr><td>eval_steps_per_second</td><td>4.076</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5008</td></tr><tr><td>train/total_flos</td><td>5502170245939200.0</td></tr><tr><td>train/train_loss</td><td>1.34845</td></tr><tr><td>train/train_runtime</td><td>620.0607</td></tr><tr><td>train/train_samples_per_second</td><td>3.306</td></tr><tr><td>train/train_steps_per_second</td><td>0.831</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-256-1-3-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/2za96u2c\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/2za96u2c</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_174150-2za96u2c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_175236-nbzcm6gz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/nbzcm6gz\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-256-1-6-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 256)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.751700</td>\n",
       "      <td>2.351331</td>\n",
       "      <td>1.533405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.008000</td>\n",
       "      <td>2.222899</td>\n",
       "      <td>1.490939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.904100</td>\n",
       "      <td>2.188459</td>\n",
       "      <td>1.479344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.464200</td>\n",
       "      <td>2.355453</td>\n",
       "      <td>1.534749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.310300</td>\n",
       "      <td>1.611370</td>\n",
       "      <td>1.269397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.425500</td>\n",
       "      <td>1.566741</td>\n",
       "      <td>1.251695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.089100</td>\n",
       "      <td>1.330805</td>\n",
       "      <td>1.153605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.031900</td>\n",
       "      <td>1.730555</td>\n",
       "      <td>1.315505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.762200</td>\n",
       "      <td>1.602362</td>\n",
       "      <td>1.265845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.635500</td>\n",
       "      <td>1.354138</td>\n",
       "      <td>1.163674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-6/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-6/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-6/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-6/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-6/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-6/longformer-0-fold/checkpoint-500 (score: 1.1636744737625122).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-6/longformer-model-test-with-exp-moves-encoder-256-1-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-6/longformer-model-test-with-exp-moves-encoder-256-1-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3a0e5005eb460484b0dc6bcd0868fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▇▇█▃▃▁▄▃▁▄</td></tr><tr><td>eval/rmse</td><td>█▇▇█▃▃▁▄▃▁▄</td></tr><tr><td>eval/runtime</td><td>▁▃▁▁▁▁▃▂▂▃█</td></tr><tr><td>eval/samples_per_second</td><td>▇▁▇▇▇▇▁▃▅▂█</td></tr><tr><td>eval/steps_per_second</td><td>█▆████▆▇▇▆▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▃▄▃▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.71884</td></tr><tr><td>eval/rmse</td><td>1.31104</td></tr><tr><td>eval/runtime</td><td>4.7083</td></tr><tr><td>eval/samples_per_second</td><td>15.929</td></tr><tr><td>eval/steps_per_second</td><td>4.035</td></tr><tr><td>eval_loss</td><td>1.71884</td></tr><tr><td>eval_rmse</td><td>1.31104</td></tr><tr><td>eval_runtime</td><td>4.7083</td></tr><tr><td>eval_samples_per_second</td><td>15.929</td></tr><tr><td>eval_steps_per_second</td><td>4.035</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6355</td></tr><tr><td>train/total_flos</td><td>5561988780441600.0</td></tr><tr><td>train/train_loss</td><td>1.41334</td></tr><tr><td>train/train_runtime</td><td>626.7537</td></tr><tr><td>train/train_samples_per_second</td><td>3.271</td></tr><tr><td>train/train_steps_per_second</td><td>0.822</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-256-1-6-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/nbzcm6gz\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/nbzcm6gz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_175236-nbzcm6gz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_180328-1w9zl1zn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1w9zl1zn\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-256-1-12-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 256)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.10.linear1.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.7.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.9.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.6.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.10.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.10.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.7.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.bias', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear2.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.linear2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:46, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.595000</td>\n",
       "      <td>2.261674</td>\n",
       "      <td>1.503886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.862400</td>\n",
       "      <td>1.967556</td>\n",
       "      <td>1.402696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.685800</td>\n",
       "      <td>2.163851</td>\n",
       "      <td>1.471004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.750700</td>\n",
       "      <td>2.047805</td>\n",
       "      <td>1.431015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.089700</td>\n",
       "      <td>1.754518</td>\n",
       "      <td>1.324582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.135100</td>\n",
       "      <td>1.208495</td>\n",
       "      <td>1.099316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.925300</td>\n",
       "      <td>1.197314</td>\n",
       "      <td>1.094218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.728900</td>\n",
       "      <td>1.265639</td>\n",
       "      <td>1.125006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.511800</td>\n",
       "      <td>1.245818</td>\n",
       "      <td>1.116162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.500600</td>\n",
       "      <td>1.236838</td>\n",
       "      <td>1.112132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-12/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-12/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-12/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-12/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-12/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-12/longformer-0-fold/checkpoint-500 (score: 1.1121323108673096).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-12/longformer-model-test-with-exp-moves-encoder-256-1-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-1-12/longformer-model-test-with-exp-moves-encoder-256-1-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9482362ddab148fb8375395b9e7499fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▆▇▇▅▁▁▁▁▁▄</td></tr><tr><td>eval/rmse</td><td>█▆▇▇▅▁▁▂▁▁▄</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>██████████▁</td></tr><tr><td>eval/steps_per_second</td><td>██████████▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▅▅▃▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.6587</td></tr><tr><td>eval/rmse</td><td>1.28791</td></tr><tr><td>eval/runtime</td><td>5.8196</td></tr><tr><td>eval/samples_per_second</td><td>12.888</td></tr><tr><td>eval/steps_per_second</td><td>3.265</td></tr><tr><td>eval_loss</td><td>1.6587</td></tr><tr><td>eval_rmse</td><td>1.28791</td></tr><tr><td>eval_runtime</td><td>5.8196</td></tr><tr><td>eval_samples_per_second</td><td>12.888</td></tr><tr><td>eval_steps_per_second</td><td>3.265</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5006</td></tr><tr><td>train/total_flos</td><td>5681625849446400.0</td></tr><tr><td>train/train_loss</td><td>1.25755</td></tr><tr><td>train/train_runtime</td><td>647.355</td></tr><tr><td>train/train_samples_per_second</td><td>3.167</td></tr><tr><td>train/train_steps_per_second</td><td>0.796</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-256-1-12-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1w9zl1zn\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1w9zl1zn</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_180328-1w9zl1zn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_181440-1ypz50lq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1ypz50lq\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-256-4-3-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 256)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.embedding.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.760600</td>\n",
       "      <td>2.464017</td>\n",
       "      <td>1.569719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.008300</td>\n",
       "      <td>2.401592</td>\n",
       "      <td>1.549707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.203400</td>\n",
       "      <td>2.403884</td>\n",
       "      <td>1.550447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.992600</td>\n",
       "      <td>2.219277</td>\n",
       "      <td>1.489724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.638600</td>\n",
       "      <td>1.701424</td>\n",
       "      <td>1.304387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.718100</td>\n",
       "      <td>1.593877</td>\n",
       "      <td>1.262488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.295000</td>\n",
       "      <td>1.563073</td>\n",
       "      <td>1.250229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.160400</td>\n",
       "      <td>1.602645</td>\n",
       "      <td>1.265956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.891900</td>\n",
       "      <td>1.463363</td>\n",
       "      <td>1.209696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.710800</td>\n",
       "      <td>1.506096</td>\n",
       "      <td>1.227231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-3/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-3/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-3/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-3/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-3/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-3/longformer-0-fold/checkpoint-500 (score: 1.2272310256958008).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-3/longformer-model-test-with-exp-moves-encoder-256-4-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-3/longformer-model-test-with-exp-moves-encoder-256-4-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e398a876f2b40d6bebe830df9f109c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>███▆▃▂▂▂▁▁▄</td></tr><tr><td>eval/rmse</td><td>███▆▃▂▂▂▁▁▄</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁▁▂▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>██████▆███▁</td></tr><tr><td>eval/steps_per_second</td><td>██████▇███▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▆▅▄▄▃▃▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.92474</td></tr><tr><td>eval/rmse</td><td>1.38735</td></tr><tr><td>eval/runtime</td><td>5.4414</td></tr><tr><td>eval/samples_per_second</td><td>13.783</td></tr><tr><td>eval/steps_per_second</td><td>3.492</td></tr><tr><td>eval_loss</td><td>1.92474</td></tr><tr><td>eval_rmse</td><td>1.38735</td></tr><tr><td>eval_runtime</td><td>5.4414</td></tr><tr><td>eval_samples_per_second</td><td>13.783</td></tr><tr><td>eval_steps_per_second</td><td>3.492</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.7108</td></tr><tr><td>train/total_flos</td><td>5502170245939200.0</td></tr><tr><td>train/train_loss</td><td>1.61062</td></tr><tr><td>train/train_runtime</td><td>629.6052</td></tr><tr><td>train/train_samples_per_second</td><td>3.256</td></tr><tr><td>train/train_steps_per_second</td><td>0.818</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-256-4-3-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1ypz50lq\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1ypz50lq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_181440-1ypz50lq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_182535-2g6bduox</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/2g6bduox\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-256-4-6-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 256)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.814700</td>\n",
       "      <td>2.568529</td>\n",
       "      <td>1.602663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.969800</td>\n",
       "      <td>2.098477</td>\n",
       "      <td>1.448612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.737300</td>\n",
       "      <td>1.330897</td>\n",
       "      <td>1.153645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.461000</td>\n",
       "      <td>1.958036</td>\n",
       "      <td>1.399299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.121000</td>\n",
       "      <td>1.568074</td>\n",
       "      <td>1.252228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.297000</td>\n",
       "      <td>1.477018</td>\n",
       "      <td>1.215326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.994400</td>\n",
       "      <td>1.201678</td>\n",
       "      <td>1.096211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>1.170793</td>\n",
       "      <td>1.082032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.693700</td>\n",
       "      <td>1.117719</td>\n",
       "      <td>1.057222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.625400</td>\n",
       "      <td>1.191575</td>\n",
       "      <td>1.091593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-6/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-6/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-6/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-6/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-6/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-6/longformer-0-fold/checkpoint-500 (score: 1.091592788696289).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-6/longformer-model-test-with-exp-moves-encoder-256-4-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-6/longformer-model-test-with-exp-moves-encoder-256-4-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefb4940d28848688d537998e4bc6adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▆▂▅▃▃▁▁▁▁▃</td></tr><tr><td>eval/rmse</td><td>█▆▂▅▄▃▂▁▁▁▄</td></tr><tr><td>eval/runtime</td><td>▁▂▂▆▂▂▂▃▃▄█</td></tr><tr><td>eval/samples_per_second</td><td>█▆▆▁▇▇▆▅▅▄█</td></tr><tr><td>eval/steps_per_second</td><td>█▇▇▃▇▇▇▆▆▅▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▅▄▃▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.58324</td></tr><tr><td>eval/rmse</td><td>1.25827</td></tr><tr><td>eval/runtime</td><td>4.7047</td></tr><tr><td>eval/samples_per_second</td><td>15.942</td></tr><tr><td>eval/steps_per_second</td><td>4.039</td></tr><tr><td>eval_loss</td><td>1.58324</td></tr><tr><td>eval_rmse</td><td>1.25827</td></tr><tr><td>eval_runtime</td><td>4.7047</td></tr><tr><td>eval_samples_per_second</td><td>15.942</td></tr><tr><td>eval_steps_per_second</td><td>4.039</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.6254</td></tr><tr><td>train/total_flos</td><td>5561988780441600.0</td></tr><tr><td>train/train_loss</td><td>1.32851</td></tr><tr><td>train/train_runtime</td><td>637.6737</td></tr><tr><td>train/train_samples_per_second</td><td>3.215</td></tr><tr><td>train/train_steps_per_second</td><td>0.808</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-256-4-6-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/2g6bduox\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/2g6bduox</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_182535-2g6bduox/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_183636-195s88dz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/195s88dz\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-256-4-12-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 256)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.10.linear1.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.7.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.9.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.6.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.10.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.10.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.7.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.bias', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear2.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.linear2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.593200</td>\n",
       "      <td>2.240413</td>\n",
       "      <td>1.496801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.820700</td>\n",
       "      <td>1.607251</td>\n",
       "      <td>1.267774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.586200</td>\n",
       "      <td>1.410006</td>\n",
       "      <td>1.187437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.663700</td>\n",
       "      <td>1.982813</td>\n",
       "      <td>1.408124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.990600</td>\n",
       "      <td>1.745870</td>\n",
       "      <td>1.321314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.091500</td>\n",
       "      <td>1.287420</td>\n",
       "      <td>1.134645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.880400</td>\n",
       "      <td>1.145844</td>\n",
       "      <td>1.070441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.815100</td>\n",
       "      <td>1.222427</td>\n",
       "      <td>1.105634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.569200</td>\n",
       "      <td>1.517450</td>\n",
       "      <td>1.231848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>1.280620</td>\n",
       "      <td>1.131645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-12/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-12/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-12/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-12/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-12/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-12/longformer-0-fold/checkpoint-500 (score: 1.13164484500885).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-12/longformer-model-test-with-exp-moves-encoder-256-4-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-4-12/longformer-model-test-with-exp-moves-encoder-256-4-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1753f1483534f3993d56b895111a1b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▄▃▆▅▂▁▁▃▂▃</td></tr><tr><td>eval/rmse</td><td>█▄▃▇▅▂▁▂▄▂▄</td></tr><tr><td>eval/runtime</td><td>▂▃▂▂▁▁▁▁▁▂█</td></tr><tr><td>eval/samples_per_second</td><td>▄▁▄▃▆▆▅▆▅▃█</td></tr><tr><td>eval/steps_per_second</td><td>▇▆▇▇█████▇▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▅▅▃▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.51645</td></tr><tr><td>eval/rmse</td><td>1.23144</td></tr><tr><td>eval/runtime</td><td>4.7634</td></tr><tr><td>eval/samples_per_second</td><td>15.745</td></tr><tr><td>eval/steps_per_second</td><td>3.989</td></tr><tr><td>eval_loss</td><td>1.51645</td></tr><tr><td>eval_rmse</td><td>1.23144</td></tr><tr><td>eval_runtime</td><td>4.7634</td></tr><tr><td>eval_samples_per_second</td><td>15.745</td></tr><tr><td>eval_steps_per_second</td><td>3.989</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.495</td></tr><tr><td>train/total_flos</td><td>5681625849446400.0</td></tr><tr><td>train/train_loss</td><td>1.22467</td></tr><tr><td>train/train_runtime</td><td>637.143</td></tr><tr><td>train/train_samples_per_second</td><td>3.217</td></tr><tr><td>train/train_steps_per_second</td><td>0.808</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-256-4-12-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/195s88dz\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/195s88dz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_183636-195s88dz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_184738-1ouqxvh0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1ouqxvh0\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-256-8-3-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 256)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.embedding.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.743200</td>\n",
       "      <td>2.455917</td>\n",
       "      <td>1.567137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.969700</td>\n",
       "      <td>2.461856</td>\n",
       "      <td>1.569030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.079600</td>\n",
       "      <td>2.096950</td>\n",
       "      <td>1.448085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.799100</td>\n",
       "      <td>2.024900</td>\n",
       "      <td>1.422990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.209400</td>\n",
       "      <td>1.452886</td>\n",
       "      <td>1.205357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.418300</td>\n",
       "      <td>1.399671</td>\n",
       "      <td>1.183077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.043400</td>\n",
       "      <td>1.418870</td>\n",
       "      <td>1.191164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.831700</td>\n",
       "      <td>1.472350</td>\n",
       "      <td>1.213404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.713300</td>\n",
       "      <td>1.434551</td>\n",
       "      <td>1.197728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.526500</td>\n",
       "      <td>1.436421</td>\n",
       "      <td>1.198508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-3/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-3/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-3/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-3/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-3/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-3/longformer-0-fold/checkpoint-500 (score: 1.1985076665878296).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-3/longformer-model-test-with-exp-moves-encoder-256-8-3/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-3/longformer-model-test-with-exp-moves-encoder-256-8-3/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce1ce7cca684a45a099de46a092ee77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>██▆▅▁▁▁▁▁▁▃</td></tr><tr><td>eval/rmse</td><td>██▆▅▁▁▁▂▁▁▃</td></tr><tr><td>eval/runtime</td><td>▃▂▁▂▁▁▂▂▂▁█</td></tr><tr><td>eval/samples_per_second</td><td>▁▃▇▆▆█▂▂▅█▂</td></tr><tr><td>eval/steps_per_second</td><td>▆▇█▇██▇▇▇█▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▆▅▃▄▃▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.6979</td></tr><tr><td>eval/rmse</td><td>1.30304</td></tr><tr><td>eval/runtime</td><td>4.6998</td></tr><tr><td>eval/samples_per_second</td><td>15.958</td></tr><tr><td>eval/steps_per_second</td><td>4.043</td></tr><tr><td>eval_loss</td><td>1.6979</td></tr><tr><td>eval_rmse</td><td>1.30304</td></tr><tr><td>eval_runtime</td><td>4.6998</td></tr><tr><td>eval_samples_per_second</td><td>15.958</td></tr><tr><td>eval_steps_per_second</td><td>4.043</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5265</td></tr><tr><td>train/total_flos</td><td>5502170245939200.0</td></tr><tr><td>train/train_loss</td><td>1.41042</td></tr><tr><td>train/train_runtime</td><td>618.9805</td></tr><tr><td>train/train_samples_per_second</td><td>3.312</td></tr><tr><td>train/train_steps_per_second</td><td>0.832</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-256-8-3-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1ouqxvh0\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1ouqxvh0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_184738-1ouqxvh0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_185819-2h05vxeu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/2h05vxeu\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-256-8-6-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 256)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.801500</td>\n",
       "      <td>2.575087</td>\n",
       "      <td>1.604708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.994800</td>\n",
       "      <td>2.175745</td>\n",
       "      <td>1.475041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.679200</td>\n",
       "      <td>1.353756</td>\n",
       "      <td>1.163510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.504400</td>\n",
       "      <td>2.013966</td>\n",
       "      <td>1.419143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.104700</td>\n",
       "      <td>1.603478</td>\n",
       "      <td>1.266285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.117900</td>\n",
       "      <td>1.346870</td>\n",
       "      <td>1.160547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.936200</td>\n",
       "      <td>1.182034</td>\n",
       "      <td>1.087214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.830500</td>\n",
       "      <td>1.335761</td>\n",
       "      <td>1.155751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.578700</td>\n",
       "      <td>1.236668</td>\n",
       "      <td>1.112056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.547200</td>\n",
       "      <td>1.227242</td>\n",
       "      <td>1.107810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-6/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-6/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-6/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-6/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-6/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-6/longformer-0-fold/checkpoint-500 (score: 1.1078095436096191).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-6/longformer-model-test-with-exp-moves-encoder-256-8-6/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-6/longformer-model-test-with-exp-moves-encoder-256-8-6/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f62e1ae39c4beb8bad5cb0af24c576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>█▆▂▅▃▂▁▂▁▁▃</td></tr><tr><td>eval/rmse</td><td>█▆▂▅▃▂▁▂▁▁▃</td></tr><tr><td>eval/runtime</td><td>▁▂▂▂▁▂▄▂▂▃█</td></tr><tr><td>eval/samples_per_second</td><td>█▆▆▅█▅▁▅▇▃█</td></tr><tr><td>eval/steps_per_second</td><td>█▇▇▇█▇▅▇▇▆▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▅▅▄▃▃▂▂▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.55582</td></tr><tr><td>eval/rmse</td><td>1.24733</td></tr><tr><td>eval/runtime</td><td>4.7066</td></tr><tr><td>eval/samples_per_second</td><td>15.935</td></tr><tr><td>eval/steps_per_second</td><td>4.037</td></tr><tr><td>eval_loss</td><td>1.55582</td></tr><tr><td>eval_rmse</td><td>1.24733</td></tr><tr><td>eval_runtime</td><td>4.7066</td></tr><tr><td>eval_samples_per_second</td><td>15.935</td></tr><tr><td>eval_steps_per_second</td><td>4.037</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.5472</td></tr><tr><td>train/total_flos</td><td>5561988780441600.0</td></tr><tr><td>train/train_loss</td><td>1.28306</td></tr><tr><td>train/train_runtime</td><td>627.2241</td></tr><tr><td>train/train_samples_per_second</td><td>3.268</td></tr><tr><td>train/train_steps_per_second</td><td>0.821</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-256-8-6-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/2h05vxeu\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/2h05vxeu</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_185819-2h05vxeu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/vocab.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/859f4633944e1b7e7fa301e72161388cd5903e36385d0ef2917256506bff64c3.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/merges.txt from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/af6fcabe2bf8cab6f77b20d94ba46a3dbf441ca0549e1f3c852c437b612f5224.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/allenai/longformer-base-4096/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"_name_or_path\": \"allenai/longformer-base-4096\",\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/allenai/longformer-base-4096/resolve/main/config.json from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/0690955d8f70934f95adf0fb108d5f7322d02f8d7dd938b7b133cb7421e120e6.b25f41ff6acdcb7ab47c505c70e351b3fc01957b3798197e5ac6e8efc547ac99\n",
      "Model config LongformerConfig {\n",
      "  \"attention_mode\": \"longformer\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"attention_window\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"ignore_attention_mask\": false,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 4098,\n",
      "  \"model_type\": \"longformer\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"sep_token_id\": 2,\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.14.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.20"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/wandb/run-20230317_190910-1m2i2vr0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/milad-it/test-project/runs/1m2i2vr0\" target=\"_blank\">longformer-model-test-with-exp-moves-encoder-256-8-12-longformer</a></strong> to <a href=\"https://wandb.ai/milad-it/test-project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    82\n",
      "3    82\n",
      "2    82\n",
      "4    82\n",
      "5    82\n",
      "Name: labels, dtype: int64\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "Training 130, Valid 33, and Test 41\n",
      "Training 410, Valid 73, and Test 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/allenai/longformer-base-4096/resolve/main/pytorch_model.bin from cache at /mnt/ceph/storage/data-tmp/current/sile2804/.cache/huggingface/transformers/a7a586602e625bd012d75abdfcc615f5bb1fe133273845f7381332c634273bd9.dc3a4f03d4ab11f972b126d0e6b67f43e5d9003b3aec54f8e549cc7e2d42398d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (6): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (7): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (8): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (9): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (10): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (11): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 256)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerForSequenceClassification: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LongformerForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['extra_encoders.0.transformer_encoder.layers.10.linear1.weight', 'extra_encoders.0.pos_encoder.pe', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.7.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.9.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.9.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.2.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.6.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.10.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.5.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.2.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.in_proj_bias', 'classifier.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.0.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.11.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.bias', 'classifier.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.10.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.6.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.1.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.8.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.out_proj.weight', 'classifier.dense.weight', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.7.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.8.norm2.bias', 'extra_poolers.0.dense.weight', 'extra_encoders.0.transformer_encoder.layers.1.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.8.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.3.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.0.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.7.linear2.weight', 'extra_poolers.0.dense.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.3.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.3.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.7.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.6.linear1.weight', 'classifier.dense.bias', 'extra_encoders.0.transformer_encoder.layers.6.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.9.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.8.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.7.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.6.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.0.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.1.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.4.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.in_proj_weight', 'extra_encoders.0.transformer_encoder.layers.2.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.in_proj_bias', 'extra_encoders.0.embedding.weight', 'extra_encoders.0.transformer_encoder.layers.3.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.1.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.5.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm2.bias', 'extra_encoders.0.transformer_encoder.layers.5.self_attn.in_proj_bias', 'extra_encoders.0.transformer_encoder.layers.9.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.0.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.4.linear1.weight', 'extra_encoders.0.transformer_encoder.layers.0.linear2.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear1.bias', 'extra_encoders.0.transformer_encoder.layers.11.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.5.norm1.bias', 'extra_encoders.0.transformer_encoder.layers.10.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.5.linear2.weight', 'extra_encoders.0.transformer_encoder.layers.3.self_attn.out_proj.weight', 'extra_encoders.0.transformer_encoder.layers.11.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.11.self_attn.out_proj.bias', 'extra_encoders.0.transformer_encoder.layers.2.norm1.weight', 'extra_encoders.0.transformer_encoder.layers.4.norm2.weight', 'extra_encoders.0.transformer_encoder.layers.10.linear2.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 410\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 515\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='515' max='515' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [515/515 10:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.587800</td>\n",
       "      <td>2.260426</td>\n",
       "      <td>1.503471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.844700</td>\n",
       "      <td>1.625872</td>\n",
       "      <td>1.275097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.476400</td>\n",
       "      <td>1.388341</td>\n",
       "      <td>1.178279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.613300</td>\n",
       "      <td>1.829999</td>\n",
       "      <td>1.352775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.037300</td>\n",
       "      <td>2.518991</td>\n",
       "      <td>1.587133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.082000</td>\n",
       "      <td>1.108744</td>\n",
       "      <td>1.052969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.800500</td>\n",
       "      <td>1.276685</td>\n",
       "      <td>1.129905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.716300</td>\n",
       "      <td>1.019434</td>\n",
       "      <td>1.009670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.581300</td>\n",
       "      <td>1.506281</td>\n",
       "      <td>1.227306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>1.221878</td>\n",
       "      <td>1.105386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 73\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-12/longformer-0-fold/checkpoint-500\n",
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-12/longformer-0-fold/checkpoint-500/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-12/longformer-0-fold/checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-12/longformer-0-fold/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-12/longformer-0-fold/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-12/longformer-0-fold/checkpoint-500 (score: 1.105385661125183).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 75\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-12/longformer-model-test-with-exp-moves-encoder-256-8-12/0-fold/config.json\n",
      "Model weights saved in ../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-256-8-12/longformer-model-test-with-exp-moves-encoder-256-8-12/0-fold/pytorch_model.bin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d364a3a2845c492fb1922a302237fc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>eval/loss</td><td>▇▄▃▅█▁▂▁▃▂▃</td></tr><tr><td>eval/rmse</td><td>▇▄▃▅█▂▂▁▄▂▃</td></tr><tr><td>eval/runtime</td><td>▂▃▁▂▂▆▆▃▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▅▅▇▅▅▁▁▄▆▆█</td></tr><tr><td>eval/steps_per_second</td><td>▇▆█▇▇▃▃▆██▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>eval_rmse</td><td>▁</td></tr><tr><td>eval_runtime</td><td>▁</td></tr><tr><td>eval_samples_per_second</td><td>▁</td></tr><tr><td>eval_steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇█████</td></tr><tr><td>train/learning_rate</td><td>█▇▆▆▅▄▃▃▂▁</td></tr><tr><td>train/loss</td><td>█▆▄▅▃▃▂▂▂▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>5.0</td></tr><tr><td>eval/loss</td><td>1.47428</td></tr><tr><td>eval/rmse</td><td>1.2142</td></tr><tr><td>eval/runtime</td><td>4.7652</td></tr><tr><td>eval/samples_per_second</td><td>15.739</td></tr><tr><td>eval/steps_per_second</td><td>3.987</td></tr><tr><td>eval_loss</td><td>1.47428</td></tr><tr><td>eval_rmse</td><td>1.2142</td></tr><tr><td>eval_runtime</td><td>4.7652</td></tr><tr><td>eval_samples_per_second</td><td>15.739</td></tr><tr><td>eval_steps_per_second</td><td>3.987</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>515</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4248</td></tr><tr><td>train/total_flos</td><td>5681625849446400.0</td></tr><tr><td>train/train_loss</td><td>1.19162</td></tr><tr><td>train/train_runtime</td><td>640.423</td></tr><tr><td>train/train_samples_per_second</td><td>3.201</td></tr><tr><td>train/train_steps_per_second</td><td>0.804</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">longformer-model-test-with-exp-moves-encoder-256-8-12-longformer</strong>: <a href=\"https://wandb.ai/milad-it/test-project/runs/1m2i2vr0\" target=\"_blank\">https://wandb.ai/milad-it/test-project/runs/1m2i2vr0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230317_190910-1m2i2vr0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for flow_model_hidden_size in [64, 128, 256]:\n",
    "    for nhead in [1, 4, 8]:\n",
    "        for nlayers in [3, 6, 12]:\n",
    "            hat_rmse_scores = train_and_evaluate_longformer_model('../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-{}-{}-{}'.format(flow_model_hidden_size, nhead, nlayers), \n",
    "                                         eli5_annotation_df[['topic', 'input_texts', 'exp_act_label', 'labels']], \n",
    "                                         'longformer-model-test-with-exp-moves-encoder-{}-{}-{}'.format(flow_model_hidden_size, nhead, nlayers),\n",
    "                                         extra_encoder_configs=[{'num_tokens':11, 'flow_model_hidden_size': flow_model_hidden_size, 'nhead': nhead, 'nlayers':nlayers}], lr=2e-5, eval_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64-1-3 : 1.3687065839767456\n",
      "64-1-6 : 1.3223797082901\n",
      "64-1-12 : 1.4363234043121338\n",
      "64-4-3 : 1.3115657567977905\n",
      "64-4-6 : 1.3706018924713135\n",
      "64-4-12 : 1.2791694402694702\n",
      "64-8-3 : 1.3994545936584473\n",
      "64-8-6 : 1.4032223224639893\n",
      "64-8-12 : 1.2909362316131592\n",
      "128-1-3 : 1.1962027549743652\n",
      "128-1-6 : 1.1957776546478271\n",
      "128-1-12 : 1.2786433696746826\n",
      "128-4-3 : 1.2316513061523438\n",
      "128-4-6 : 1.1427255868911743\n",
      "128-4-12 : 1.2438740730285645\n",
      "128-8-3 : 1.1843225955963135\n",
      "128-8-6 : 1.1754686832427979\n",
      "128-8-12 : 1.3823621273040771\n",
      "256-1-3 : 1.3272812366485596\n",
      "256-1-6 : 1.3110439777374268\n",
      "256-1-12 : 1.2879060506820679\n",
      "256-4-3 : 1.387351393699646\n",
      "256-4-6 : 1.258270263671875\n",
      "256-4-12 : 1.2314435243606567\n",
      "256-8-3 : 1.3030357360839844\n",
      "256-8-6 : 1.2473267316818237\n",
      "256-8-12 : 1.2141982316970825\n"
     ]
    }
   ],
   "source": [
    "for flow_model_hidden_size in [64, 128, 256]:\n",
    "    for nhead in [1, 4, 8]:\n",
    "        for nlayers in [3, 6, 12]:\n",
    "            res = json.load(open('../data/quality_models/longformer-models/longformer-model-test-with-exp-moves-encoder-{}-{}-{}/longformer-model-test-with-exp-moves-encoder-{}-{}-{}/0-fold/eval_results.json'.format(flow_model_hidden_size, nhead, nlayers, flow_model_hidden_size, nhead, nlayers)))\n",
    "            print('{}-{}-{}'.format(flow_model_hidden_size, nhead, nlayers), ':' , res['eval_rmse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluating Trained Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum seq num: 40\n",
      "Maximum seq len: 1099\n",
      "Data size: 345\n",
      "Maximum seq num: 40\n",
      "Maximum seq len: 1303\n",
      "Data size: 122\n"
     ]
    }
   ],
   "source": [
    "eli5_training_df= load_and_prepare_df('../../data/eli5_ds/annotation-results/MACE-measure/final_mace_predictions_training.pkl', \n",
    "                                      '../../data/eli5_ds/annotation-results/MACE-measure/final_mace_rating_predictions.csv')\n",
    "eli5_testing_df = load_and_prepare_df('../../data/eli5_ds/annotation-results/MACE-measure/final_mace_predictions_testing.pkl', \n",
    "                                      '../../data/eli5_ds/annotation-results/MACE-measure/final_mace_rating_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def evaluate_model_on_fold(test_df, model_type, extra_encoder_configs, model_path, max_seq_length=256):\n",
    "    #Load the model\n",
    "    if model_type == 'hatformer':\n",
    "        config, model, tokenizer = get_hatformer_model(None, model_path)\n",
    "    elif model_type == 'longformer':\n",
    "        config, model, tokenizer = get_longformer_model(None, model_path)\n",
    "    else:\n",
    "        print('No model type identified..')\n",
    "        return\n",
    "\n",
    "    model = model.cuda()\n",
    "\n",
    "    if model_type == 'hatformer':\n",
    "        test_ds     = Dataset.from_pandas(test_df)\n",
    "        test_ds = test_ds.map(lambda examples: preprocess_hat_function(tokenizer, examples, max_seq_length, False), \n",
    "                                batched=True, load_from_cache_file=False, remove_columns=['labels'])     \n",
    "    else:\n",
    "        test_ds = Dataset.from_dict(preprocess_function(tokenizer, test_df, input_clm=\"input_texts\"))\n",
    "\n",
    "\n",
    "    if extra_encoder_configs == []:\n",
    "        test_ds = test_ds.remove_columns([col for col in test_ds.column_names if col not in ['input_ids', 'attention_mask']])\n",
    "    else:\n",
    "        test_ds = test_ds.remove_columns([col for col in test_ds.column_names if col not in ['input_ids', 'attention_mask', 'flow_ids']])\n",
    "\n",
    "    eval_dataloader = DataLoader(test_ds, collate_fn=default_data_collator)\n",
    "    all_predictions = []\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        batch = {x[0]: x[1].cuda() for x in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        all_predictions+=[x.item() for x in outputs.logits]\n",
    "\n",
    "    #print(all_predictions)\n",
    "    #print(test_df.labels.tolist())\n",
    "    mse = mean_squared_error(test_df.labels.tolist(), all_predictions, squared=False)\n",
    "    mae = mean_absolute_error(test_df.labels.tolist(), all_predictions)\n",
    "    \n",
    "    return mse, mae, test_df.labels.tolist(), all_predictions\n",
    "\n",
    "def cross_fold_evaluate_model(df, model_path, model_type, extra_encoder_configs):\n",
    "    feats_clms = extra_encoder_configs.keys()\n",
    "    df = df[['topic', 'input_texts', 'labels'] + list(feats_clms)]\n",
    "    \n",
    "    print('----- Evalauting model {} ------'.format(model_path))\n",
    "    topics  = df.topic.unique()\n",
    "    \n",
    "\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "    fold_idx = 0\n",
    "    rmse_scores = []\n",
    "    mae_scores = []\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    for fold in kfold.split(topics):\n",
    "        print('----- testing fold {} ------'.format(fold_idx))\n",
    "        test_topics = topics[fold[1]]\n",
    "        test_df     = df[df.topic.isin(test_topics)]\n",
    "        \n",
    "        mse, mae, labels, predictions = evaluate_model_on_fold(test_df, model_type, extra_encoder_configs.values(), model_path + '/{}-fold/'.format(fold_idx))\n",
    "        rmse_scores.append(mse)\n",
    "        mae_scores.append(mae)\n",
    "        all_labels += labels\n",
    "        all_predictions +=predictions\n",
    "        \n",
    "        fold_idx+=1\n",
    "    print(rmse_scores)\n",
    "    return np.mean(rmse_scores), np.mean(mae_scores), all_labels, all_predictions\n",
    "\n",
    "def evaluate_model(test_df, model_path, model_type, extra_encoder_configs):\n",
    "    feats_clms = extra_encoder_configs.keys()\n",
    "    print(\"feats_clms={}\".format(feats_clms))\n",
    "    test_df = test_df[['topic', 'input_texts', 'labels'] + list(feats_clms)]    \n",
    "    print('----- Evalauting model {} ------'.format(model_path))\n",
    "    mse, mae, all_labels, all_predictions = evaluate_model_on_fold(test_df, model_type, extra_encoder_configs.values(), model_path + '/0-fold/')\n",
    "    return mse, mae, all_labels, all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_models = {\n",
    "    'hat-baseline' : ('../data/quality_models/hat-models/hat-model-baseline', {}),\n",
    "    'hat-enc-dlg-act' : ('../data/quality_models/hat-models/hat-model-dlg-act-encoder/', {'dlg_act_label': {'num_tokens':11, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3}}),\n",
    "    'hat-enc-exp-act' : ('../data/quality_models/hat-models/hat-model-exp-act-encoder/', {'exp_act_label': {'num_tokens':11, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3}}),\n",
    "    'hat-enc-topic-func' : ('../data/quality_models/hat-models/hat-model-topic-func-encoder/', {'topic_func_label':{'num_tokens':5, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3}}),\n",
    "    'hat-enc-all' : ('../data/quality_models/hat-models/hat-model-all-encoder/', {'dlg_act_label': {'num_tokens':11, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3},\n",
    "                                                                                        'exp_act_label': {'num_tokens':11, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3},\n",
    "                                                                                        'topic_func_label':{'num_tokens':5, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3}}),\n",
    "    'longformer-baseline' : ('../data/quality_models/longformer-models/longformer-model-baseline/', {}),\n",
    "    'longformer-enc-dlg-act' : ('../data/quality_models/longformer-models/longformer-model-dlg-act-encoder/', {'dlg_act_label': {'num_tokens':11, 'flow_model_hidden_size': 128, 'nhead':4, 'nlayers':6}}),\n",
    "    'longformer-enc-exp-act' : ('../data/quality_models/longformer-models/longformer-model-exp-act-encoder/', {'exp_act_label': {'num_tokens':11, 'flow_model_hidden_size': 128, 'nhead':4, 'nlayers':6}}),\n",
    "    'longformer-enc-topic-func' : ('../data/quality_models/longformer-models/longformer-model-topic-func-encoder/', {'topic_func_label':{'num_tokens':5, 'flow_model_hidden_size': 128, 'nhead':4, 'nlayers':6}}),\n",
    "    'longformer-enc-all' : ('../data/quality_models/longformer-models/longformer-model-all-encoder/', {'dlg_act_label': {'num_tokens':11, 'flow_model_hidden_size': 128, 'nhead':4, 'nlayers':6},\n",
    "                                                                                     'exp_act_label': {'num_tokens':11, 'flow_model_hidden_size': 128, 'nhead':4, 'nlayers':6},\n",
    "                                                                                     'topic_func_label':{'num_tokens':5, 'flow_model_hidden_size': 128, 'nhead':4, 'nlayers':6}})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_all_models(evaluated_models, dlgs_df, cross_fold=False):\n",
    "    eval_scores = {}\n",
    "    for key, value in evaluated_models.items():\n",
    "        model_path = value[0]\n",
    "        config = value[1]\n",
    "        model_name = key\n",
    "        if cross_fold:\n",
    "            mse, mae, _, _ = cross_fold_evaluate_model(dlgs_df, model_path, 'hatformer' if 'hat' in model_path else 'longformer', config)\n",
    "        else:\n",
    "            mse, mae, _, _ = evaluate_model(dlgs_df, model_path, 'hatformer' if 'hat' in model_path else 'longformer', config)\n",
    "\n",
    "        eval_scores[model_name] = (round(mse, 3), round(mae, 3))\n",
    "    return eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_scores = evaluate_all_models(evaluated_models, eli5_testing_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate single folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_clms=dict_keys([])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  []\n",
      "Using input_clm=input_texts\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 180.00 MiB (GPU 0; 39.59 GiB total capacity; 7.23 GiB already allocated; 20.69 MiB free; 7.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cc5980c26fdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#Single-fold evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0meval_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluated_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meli5_testing_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-848dd8a58a3f>\u001b[0m in \u001b[0;36mevaluate_all_models\u001b[0;34m(evaluated_models, dlgs_df, cross_fold)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_fold_evaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlgs_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hatformer'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'hat'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'longformer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdlgs_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hatformer'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'hat'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'longformer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0meval_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-436c8150f339>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(test_df, model_path, model_type, extra_encoder_configs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'topic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'input_texts'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_clms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----- Evalauting model {} ------'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model_on_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_encoder_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/0-fold/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-436c8150f339>\u001b[0m in \u001b[0;36mevaluate_model_on_fold\u001b[0;34m(test_df, model_type, extra_encoder_configs, model_path, max_seq_length)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mall_predictions\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sile2804/explanation_assessment/eli5-experiments/src-ipynb/../../models/longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, flow_ids, flow_ids_mask, attention_mask, global_attention_mask, head_mask, token_type_ids, exp_moves_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0mglobal_attention_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         outputs = self.longformer(\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1705\u001b[0m         )\n\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1707\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1708\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1709\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, padding_len, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1287\u001b[0m                 )\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1290\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m     ):\n\u001b[0;32m-> 1213\u001b[0;31m         self_attn_outputs = self.attention(\n\u001b[0m\u001b[1;32m   1214\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     ):\n\u001b[0;32m-> 1149\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m   1150\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mkey_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         attn_scores = self._sliding_chunks_query_key_matmul(\n\u001b[0m\u001b[1;32m    584\u001b[0m             \u001b[0mquery_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_sided_attn_window_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36m_sliding_chunks_query_key_matmul\u001b[0;34m(self, query, key, window_overlap)\u001b[0m\n\u001b[1;32m    825\u001b[0m         \u001b[0;31m# bcyd: batch_size * num_heads x chunks x 2window_overlap x head_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# bcxy: batch_size * num_heads x chunks x 2window_overlap x 2window_overlap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0mdiagonal_chunked_attention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bcxd,bcyd->bcxy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# multiply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;31m# convert diagonals into columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;31m# recurse incase operands contains value that has torch function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m# in the original implementation this line is omitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_operands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mequation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;31m# Wrapper around _histogramdd and _histogramdd_bin_edges needed due to (Tensor, Tensor[]) return type.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 180.00 MiB (GPU 0; 39.59 GiB total capacity; 7.23 GiB already allocated; 20.69 MiB free; 7.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "evaluated_models = {\n",
    "#    'hat-baseline' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline', {}),\n",
    "#    'hat-enc-dlg-act' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder/', {'dlg_act_label': {}}),\n",
    "#     'hat-enc-exp-act' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder/', {'exp_act_label': {}}),\n",
    "#     'hat-enc-topic-func' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder/', {'topic_func_label':{}}),\n",
    "#     'hat-enc-all' : ('../data/quality_models/single-fold/hat-models/hat-model-all-encoder/', {'dlg_act_label': {},\n",
    "#                                                                                   'exp_act_label': {},\n",
    "#                                                                                   'topic_func_label':{}}),\n",
    "    \n",
    "    'longformer-baseline' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline/', {}),\n",
    "    'longformer-enc-dlg-act' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder/', {'dlg_act_label': {}}),\n",
    "    'longformer-enc-exp-act' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder/', {'exp_act_label': {}}),\n",
    "    'longformer-enc-topic-func' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder/', {'topic_func_label':{}}),\n",
    "    'longformer-enc-all' : ('../data/quality_models/single-fold/longformer-models/longformer-model-all-encoder/', {'dlg_act_label': {},\n",
    "                                                                                     'exp_act_label': {},\n",
    "                                                                                     'topic_func_label':{}})\n",
    "}\n",
    "\n",
    "#Single-fold evaluation\n",
    "eval_scores = evaluate_all_models(evaluated_models, eli5_testing_df,cross_fold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate([[key] + list(value) for key, value in eval_scores.items()] , headers=['Approach', 'RMSE', 'MAE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Early Prediction of Dialogue Quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_models = {\n",
    "    'hat-baseline' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline', {}),\n",
    "    'hat-enc-dlg-act' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder/', {'dlg_act_label': {}}),\n",
    "    'hat-enc-exp-act' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder/', {'exp_act_label': {}}),\n",
    "    'hat-enc-topic-func' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder/', {'topic_func_label':{}}),\n",
    "    \n",
    "    'longformer-baseline' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline/', {}),\n",
    "    'longformer-enc-dlg-act' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder/', {'dlg_act_label': {}}),\n",
    "    'longformer-enc-exp-act' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder/', {'exp_act_label': {}}),\n",
    "    'longformer-enc-topic-func' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder/', {'topic_func_label':{}}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum seq num: 40\n",
      "Maximum seq len: 1303\n",
      "Data size: 122\n"
     ]
    }
   ],
   "source": [
    "eli5_testing_df = load_and_prepare_df('../../data/eli5_ds/annotation-results/MACE-measure/final_mace_predictions_testing.pkl', \n",
    "                                      '../../data/eli5_ds/annotation-results/MACE-measure/final_mace_rating_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5_testing_df['turn_text_25'] = eli5_testing_df.input_texts.apply(lambda turns: turns[:math.ceil(len(turns) * 0.25)])\n",
    "eli5_testing_df['turn_text_50'] = eli5_testing_df.input_texts.apply(lambda turns: turns[:math.ceil(len(turns) * 0.50)])\n",
    "eli5_testing_df['turn_text_75'] = eli5_testing_df.input_texts.apply(lambda turns: turns[:math.ceil(len(turns) * 0.75)])\n",
    "eli5_testing_df['turn_text_100'] = eli5_testing_df.input_texts.apply(lambda turns: turns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_clms=dict_keys([])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline/0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  []\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e578f4a7dc4fe1acd77b379b1f398d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_clms=dict_keys(['dlg_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 12, 'num_tokens': 11}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90faff6f75a4c5f8a2ea68a7f0ccbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dlg_act_label to the flows\n",
      "feats_clms=dict_keys(['exp_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 3, 'num_tokens': 11}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e63d710351584b07a232a8d832c97eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "feats_clms=dict_keys(['topic_func_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 12, 'num_tokens': 5}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e5ab65eea243a5a305ccdbadb6d386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding topic_func_label to the flows\n",
      "feats_clms=dict_keys([])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  []\n",
      "Using input_clm=input_texts\n",
      "feats_clms=dict_keys(['dlg_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 3, 'num_tokens': 11}]\n",
      "Using input_clm=input_texts\n",
      "adding dlg_act_label to the flows\n",
      "feats_clms=dict_keys(['exp_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 3, 'num_tokens': 11}]\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "feats_clms=dict_keys(['topic_func_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 1, 'nlayers': 6, 'num_tokens': 5}]\n",
      "Using input_clm=input_texts\n",
      "adding topic_func_label to the flows\n",
      "feats_clms=dict_keys([])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline/0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  []\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ebed8fe2f54ebcbc745fdc25b5934f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_clms=dict_keys(['dlg_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 12, 'num_tokens': 11}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e3cfa6579145d2a022d2e97abd475e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dlg_act_label to the flows\n",
      "feats_clms=dict_keys(['exp_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 3, 'num_tokens': 11}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5576373aff2a46d9ab89d3932e28954f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "feats_clms=dict_keys(['topic_func_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 12, 'num_tokens': 5}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73d7f4e4e9b4762a6137da3ba0dd1e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding topic_func_label to the flows\n",
      "feats_clms=dict_keys([])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  []\n",
      "Using input_clm=input_texts\n",
      "feats_clms=dict_keys(['dlg_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 3, 'num_tokens': 11}]\n",
      "Using input_clm=input_texts\n",
      "adding dlg_act_label to the flows\n",
      "feats_clms=dict_keys(['exp_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 3, 'num_tokens': 11}]\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "feats_clms=dict_keys(['topic_func_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 1, 'nlayers': 6, 'num_tokens': 5}]\n",
      "Using input_clm=input_texts\n",
      "adding topic_func_label to the flows\n",
      "feats_clms=dict_keys([])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline/0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  []\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec5d5d4120f447eba893780b3eee170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_clms=dict_keys(['dlg_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 12, 'num_tokens': 11}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5555d7af429948d39cc12495c645aaf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dlg_act_label to the flows\n",
      "feats_clms=dict_keys(['exp_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 3, 'num_tokens': 11}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04641bd6ed8e42da827b2174bdab5069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "feats_clms=dict_keys(['topic_func_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 12, 'num_tokens': 5}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e26c94a2d841208063b253864a9a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding topic_func_label to the flows\n",
      "feats_clms=dict_keys([])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  []\n",
      "Using input_clm=input_texts\n",
      "feats_clms=dict_keys(['dlg_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 3, 'num_tokens': 11}]\n",
      "Using input_clm=input_texts\n",
      "adding dlg_act_label to the flows\n",
      "feats_clms=dict_keys(['exp_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 3, 'num_tokens': 11}]\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "feats_clms=dict_keys(['topic_func_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 1, 'nlayers': 6, 'num_tokens': 5}]\n",
      "Using input_clm=input_texts\n",
      "adding topic_func_label to the flows\n",
      "feats_clms=dict_keys([])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline/0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  []\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf71362eaed4b9ab2b8811ca968eeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_clms=dict_keys(['dlg_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 12, 'num_tokens': 11}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8007d442597a4de092a0568e61015033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding dlg_act_label to the flows\n",
      "feats_clms=dict_keys(['exp_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 3, 'num_tokens': 11}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7ce38a5fa34fbfa6ebeb59c3ab799d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "feats_clms=dict_keys(['topic_func_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder//0-fold/\n",
      "None\n",
      "PreTrainedTokenizer(name_or_path='kiddothe2b/hierarchical-transformer-base-4096', vocab_size=50265, model_max_len=4096, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})\n",
      "============\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 12, 'num_tokens': 5}]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530b0ddb49f6410b9300bd0c57834127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding topic_func_label to the flows\n",
      "feats_clms=dict_keys([])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  []\n",
      "Using input_clm=input_texts\n",
      "feats_clms=dict_keys(['dlg_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 3, 'num_tokens': 11}]\n",
      "Using input_clm=input_texts\n",
      "adding dlg_act_label to the flows\n",
      "feats_clms=dict_keys(['exp_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 3, 'num_tokens': 11}]\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "feats_clms=dict_keys(['topic_func_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 1, 'nlayers': 6, 'num_tokens': 5}]\n",
      "Using input_clm=input_texts\n",
      "adding topic_func_label to the flows\n"
     ]
    }
   ],
   "source": [
    "all_eval_scores = {}\n",
    "for perc in ['turn_text_25', 'turn_text_50', 'turn_text_75', 'turn_text_100']:\n",
    "    copied_df = eli5_testing_df.copy()\n",
    "    copied_df['input_texts'] = copied_df[perc]\n",
    "    eval_scores = evaluate_all_models(evaluated_models, copied_df,cross_fold=False)\n",
    "    all_eval_scores[perc] = eval_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspected_models =['hat-baseline', 'hat-enc-exp-act', 'longformer-baseline', 'longformer-enc-topic-func']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_scores = {x : [] for x in inspected_models}\n",
    "for model in inspected_models:\n",
    "    models_scores[model] = [all_eval_scores[x][model] for x in ['turn_text_25', 'turn_text_50', 'turn_text_75', 'turn_text_100']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "i=-0.5\n",
    "for model, scores in models_scores.items():\n",
    "    xs  = [x+i for x in range(1, 8, 2)]\n",
    "    plt.bar(xs, [x[0] for x in scores], width=0.2, label=model)\n",
    "    i+=0.25\n",
    "\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Predicting on predicted labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum seq num: 40\n",
      "Maximum seq len: 1303\n",
      "Data size: 122\n"
     ]
    }
   ],
   "source": [
    "eli5_df  = pd.read_pickle('../data/final_mace_predictions_testing_with_predictions.pkl')\n",
    "eli5_dlg_quality_df = pd.read_csv('../../data/eli5_ds/annotation-results/MACE-measure/final_mace_rating_predictions.csv')\n",
    "quality_scores = pd.Series(eli5_dlg_quality_df.rating_label.values, index = eli5_dlg_quality_df.task_id).to_dict()\n",
    "\n",
    "eli5_df = eli5_df.groupby('task_id').agg({'turn_text': lambda rows: list(rows),\n",
    "                                      'topic': lambda rows: list(rows)[0],\n",
    "                                      'topic_func_label_predictions': lambda rows: list(rows),\n",
    "                                      'dlg_act_label_predictions': lambda rows: list(rows),\n",
    "                                      'exp_type_label' : lambda rows: list(rows),\n",
    "                                      'exp_act_label_predictions': lambda rows: list(rows)}).reset_index()\n",
    "\n",
    "eli5_df['labels'] = eli5_df.task_id.apply(lambda x: quality_scores[x])\n",
    "eli5_df['input_texts'] = eli5_df.turn_text.apply(lambda row: [x['text'] for x in row])\n",
    "\n",
    "eli5_df['exp_act_label'] =  eli5_df['exp_act_label_predictions'].apply(lambda row: [int(0) for x in row])\n",
    "eli5_df['dlg_act_label'] =  eli5_df['dlg_act_label_predictions'].apply(lambda row: [int(0) for x in row])\n",
    "eli5_df['topic_func_label'] =  eli5_df['topic_func_label_predictions'].apply(lambda row: [int(0) for x in row])\n",
    "\n",
    "print('Maximum seq num:', max([len(x) for x in eli5_df.input_texts.tolist()]))\n",
    "print('Maximum seq len:', max([len(turn.split(' ')) for turns in eli5_df.input_texts.tolist() for turn in turns]))\n",
    "print('Data size:', len(eli5_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluated_models = {\n",
    "#    'hat-baseline' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-baseline', {}),\n",
    "#    'hat-enc-dlg-act' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-dlg-act-encoder/', {'dlg_act_label': {}}),\n",
    "#     'hat-enc-exp-act' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-exp-act-encoder/', {'exp_act_label': {}}),\n",
    "#     'hat-enc-topic-func' : ('../data/quality_models/single-fold/hat-models/single-fold-hat-model-topic-func-encoder/', {'topic_func_label':{}}),\n",
    "#     'hat-enc-all' : ('../data/quality_models/single-fold/hat-models/hat-model-all-encoder/', {'dlg_act_label': {},\n",
    "#                                                                                   'exp_act_label': {},\n",
    "#                                                                                   'topic_func_label':{}}),\n",
    "    \n",
    "     'longformer-baseline' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline/', {}),\n",
    "     'longformer-enc-dlg-act' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder/', {'dlg_act_label': {}}),\n",
    "     'longformer-enc-exp-act' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder/', {'exp_act_label': {}}),\n",
    "     'longformer-enc-topic-func' : ('../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder/', {'topic_func_label':{}}),\n",
    "#     'longformer-enc-all' : ('../data/quality_models/single-fold/longformer-models/longformer-model-all-encoder/', {'dlg_act_label': {},\n",
    "#                                                                                      'exp_act_label': {},\n",
    "#                                                                                      'topic_func_label':{}})\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_clms=dict_keys([])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-baseline//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  []\n",
      "Using input_clm=input_texts\n",
      "feats_clms=dict_keys(['dlg_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-dlg-act-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 128, 'nhead': 1, 'nlayers': 3, 'num_tokens': 11}]\n",
      "Using input_clm=input_texts\n",
      "adding dlg_act_label to the flows\n",
      "feats_clms=dict_keys(['exp_act_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-exp-act-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 4, 'nlayers': 3, 'num_tokens': 11}]\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "feats_clms=dict_keys(['topic_func_label'])\n",
      "----- Evalauting model ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder/ ------\n",
      "Loading model: ../data/quality_models/single-fold/longformer-models/single-fold-longformer-model-topic-func-encoder//0-fold/\n",
      "Loading extra encoder configs from the config file...\n",
      "Extra encoders:  [{'flow_model_hidden_size': 64, 'nhead': 1, 'nlayers': 6, 'num_tokens': 5}]\n",
      "Using input_clm=input_texts\n",
      "adding topic_func_label to the flows\n"
     ]
    }
   ],
   "source": [
    "#Single-fold evaluation\n",
    "eval_scores = evaluate_all_models(evaluated_models, eli5_df,cross_fold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach                     RMSE    MAE\n",
      "-------------------------  ------  -----\n",
      "longformer-baseline         1.46   1.176\n",
      "longformer-enc-dlg-act      1.273  1.026\n",
      "longformer-enc-exp-act      1.366  1.187\n",
      "longformer-enc-topic-func   1.181  0.943\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[key] + list(value) for key, value in eval_scores.items()] , headers=['Approach', 'RMSE', 'MAE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach                     RMSE    MAE\n",
      "-------------------------  ------  -----\n",
      "longformer-baseline         1.46   1.176\n",
      "longformer-enc-dlg-act      1.281  1.031\n",
      "longformer-enc-exp-act      1.364  1.187\n",
      "longformer-enc-topic-func   1.18   0.943\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[key] + list(value) for key, value in eval_scores.items()] , headers=['Approach', 'RMSE', 'MAE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approach                     RMSE    MAE\n",
      "-------------------------  ------  -----\n",
      "hat-baseline                1.716  1.433\n",
      "hat-enc-dlg-act             1.603  1.37\n",
      "hat-enc-exp-act             1.577  1.393\n",
      "hat-enc-topic-func          1.753  1.466\n",
      "hat-enc-all                 1.719  1.455\n",
      "longformer-baseline         1.46   1.176\n",
      "longformer-enc-dlg-act      1.273  1.026\n",
      "longformer-enc-exp-act      1.366  1.187\n",
      "longformer-enc-topic-func   1.181  0.943\n",
      "longformer-enc-all          1.465  1.251\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([[key] + list(value) for key, value in eval_scores.items()] , headers=['Approach', 'RMSE', 'MAE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Singificance Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "#from statsmodels.stats import weightstats \n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "#Check wither v1s are signficantly less than v2s\n",
    "def check_sig(v1s, v2s, alpha=0.05):\n",
    "\n",
    "    diff = list(map(lambda x1 , x2: x1 - x2, v1s, v2s))\n",
    "    is_normal = stats.shapiro(diff)[1] > alpha\n",
    "    \n",
    "    if is_normal:\n",
    "        print('Distribution is normal, so using ttest_rel')\n",
    "        #tstat, pvalue, df = ttest_rel(v1s, v2s, alternative='greater')\n",
    "        #https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html\n",
    "        result = ttest_rel(v1s, v2s, alternative='greater')\n",
    "        tstat, pvalue, df = result.statistics, result.pvalue, result.df\n",
    "        print(tstat, pvalue)\n",
    "        if tstat >=0:\n",
    "            if (pvalue) <= alpha:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    else:\n",
    "        print('Distribution is not normal, so using wilcoxon')\n",
    "        ttest = stats.wilcoxon(v1s, v2s, alternative='greater')\n",
    "        print(ttest)\n",
    "        if ttest.statistic >=0:\n",
    "            if (ttest.pvalue) <= alpha:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_models = {\n",
    "    'hat-baseline' : ('../data/quality_models/hat-models/hat-model-baseline', {}),\n",
    "    'hat-enc-exp-act' : ('../data/quality_models/hat-models/hat-model-exp-act-encoder/', {'exp_act_label': {'num_tokens':11, 'flow_model_hidden_size': 256, 'nhead':1, 'nlayers':3}}),\n",
    "    'longformer-baseline' : ('../data/quality_models/longformer-models/longformer-model-baseline/', {}),\n",
    "    'longformer-enc-exp-act' : ('../data/quality_models/longformer-models/longformer-model-exp-act-encoder/', {'exp_act_label': {'num_tokens':11, 'flow_model_hidden_size': 128, 'nhead':4, 'nlayers':6}}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evalauting model ../data/quality_models/hat-models/hat-model-baseline ------\n",
      "----- testing fold 0 ------\n",
      "Loading model: ../data/quality_models/hat-models/hat-model-baseline/0-fold/\n",
      "Extra encoders:  dict_values([])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function evaluate_model_on_fold.<locals>.<lambda> at 0x7f7b6c04f160> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a103022a29c4433abee4da20f58c316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- testing fold 1 ------\n",
      "Loading model: ../data/quality_models/hat-models/hat-model-baseline/1-fold/\n",
      "Extra encoders:  dict_values([])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014520545f1a4ef3aa1cfa5f800d0bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- testing fold 2 ------\n",
      "Loading model: ../data/quality_models/hat-models/hat-model-baseline/2-fold/\n",
      "Extra encoders:  dict_values([])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4857c30c4cc45258c3d2fe1074601ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- testing fold 3 ------\n",
      "Loading model: ../data/quality_models/hat-models/hat-model-baseline/3-fold/\n",
      "Extra encoders:  dict_values([])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8376076c904b8bb27c8be23e28d8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- testing fold 4 ------\n",
      "Loading model: ../data/quality_models/hat-models/hat-model-baseline/4-fold/\n",
      "Extra encoders:  dict_values([])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dda9c13e4d14a238be44cc53edccc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4618192356678288, 1.473890971507695, 1.3343427223167772, 1.4117480213327431, 1.3252707529048111]\n",
      "----- Evalauting model ../data/quality_models/hat-models/hat-model-exp-act-encoder/ ------\n",
      "----- testing fold 0 ------\n",
      "Loading model: ../data/quality_models/hat-models/hat-model-exp-act-encoder//0-fold/\n",
      "Extra encoders:  dict_values([{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d5bfb03d1149ea80dbae2d22ff4af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "----- testing fold 1 ------\n",
      "Loading model: ../data/quality_models/hat-models/hat-model-exp-act-encoder//1-fold/\n",
      "Extra encoders:  dict_values([{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a314377c00d48ecbaa583a4dddcde68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "----- testing fold 2 ------\n",
      "Loading model: ../data/quality_models/hat-models/hat-model-exp-act-encoder//2-fold/\n",
      "Extra encoders:  dict_values([{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d41ccaf828433a9ecfc93d62b072e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "----- testing fold 3 ------\n",
      "Loading model: ../data/quality_models/hat-models/hat-model-exp-act-encoder//3-fold/\n",
      "Extra encoders:  dict_values([{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab86526108aa4ad5bba236fc63031df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "----- testing fold 4 ------\n",
      "Loading model: ../data/quality_models/hat-models/hat-model-exp-act-encoder//4-fold/\n",
      "Extra encoders:  dict_values([{'num_tokens': 11, 'flow_model_hidden_size': 256, 'nhead': 1, 'nlayers': 3}])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56aeec43ea3463b83f8b4290907ce8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding exp_act_label to the flows\n",
      "[1.4322048569157984, 1.3731532843629626, 1.4886627748720904, 1.388803826993592, 1.260746213148131]\n"
     ]
    }
   ],
   "source": [
    "_, _, true_labels, hat_baseline_model_preds = evaluate_model(eli5_annotation_df, evaluated_models['hat-baseline'][0], 'hatformer', evaluated_models['hat-baseline'][1])\n",
    "_, _, true_labels, hat_exp_encoder_model_preds = evaluate_model(eli5_annotation_df, evaluated_models['hat-enc-exp-act'][0], 'hatformer', evaluated_models['hat-enc-exp-act'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Evalauting model ../data/quality_models/longformer-models/longformer-model-baseline/ ------\n",
      "----- testing fold 0 ------\n",
      "Loading model: ../data/quality_models/longformer-models/longformer-model-baseline//0-fold/\n",
      "Extra encoders:  ModuleList()\n",
      "Using input_clm=input_texts\n",
      "----- testing fold 1 ------\n",
      "Loading model: ../data/quality_models/longformer-models/longformer-model-baseline//1-fold/\n",
      "Extra encoders:  ModuleList()\n",
      "Using input_clm=input_texts\n",
      "----- testing fold 2 ------\n",
      "Loading model: ../data/quality_models/longformer-models/longformer-model-baseline//2-fold/\n",
      "Extra encoders:  ModuleList()\n",
      "Using input_clm=input_texts\n",
      "----- testing fold 3 ------\n",
      "Loading model: ../data/quality_models/longformer-models/longformer-model-baseline//3-fold/\n",
      "Extra encoders:  ModuleList()\n",
      "Using input_clm=input_texts\n",
      "----- testing fold 4 ------\n",
      "Loading model: ../data/quality_models/longformer-models/longformer-model-baseline//4-fold/\n",
      "Extra encoders:  ModuleList()\n",
      "Using input_clm=input_texts\n",
      "[1.3392726575994696, 1.2243405999374415, 1.2260572230183169, 1.4551204268425666, 1.1982525337311858]\n",
      "----- Evalauting model ../data/quality_models/longformer-models/longformer-model-exp-act-encoder/ ------\n",
      "----- testing fold 0 ------\n",
      "Loading model: ../data/quality_models/longformer-models/longformer-model-exp-act-encoder//0-fold/\n",
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "----- testing fold 1 ------\n",
      "Loading model: ../data/quality_models/longformer-models/longformer-model-exp-act-encoder//1-fold/\n",
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "----- testing fold 2 ------\n",
      "Loading model: ../data/quality_models/longformer-models/longformer-model-exp-act-encoder//2-fold/\n",
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "----- testing fold 3 ------\n",
      "Loading model: ../data/quality_models/longformer-models/longformer-model-exp-act-encoder//3-fold/\n",
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "----- testing fold 4 ------\n",
      "Loading model: ../data/quality_models/longformer-models/longformer-model-exp-act-encoder//4-fold/\n",
      "Extra encoders:  ModuleList(\n",
      "  (0): MyTransformerEncoder(\n",
      "    (pos_encoder): PositionalEncoding(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "    )\n",
      "    (transformer_encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (1): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (2): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (3): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (4): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (5): TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "          (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.5, inplace=False)\n",
      "          (dropout2): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (embedding): Embedding(11, 128)\n",
      "  )\n",
      ")\n",
      "Using input_clm=input_texts\n",
      "adding exp_act_label to the flows\n",
      "[1.149118792350466, 1.2888728328584278, 1.222237055257749, 1.4241945635129831, 1.1837841010214312]\n"
     ]
    }
   ],
   "source": [
    "_, _, true_labels, longformer_baseline_model_preds = evaluate_model(eli5_annotation_df, evaluated_models['longformer-baseline'][0], 'longformer', evaluated_models['longformer-baseline'][1])\n",
    "_, _, true_labels, longformer_exp_encoder_model_preds = evaluate_model(eli5_annotation_df, evaluated_models['longformer-enc-exp-act'][0], 'longformer', evaluated_models['longformer-enc-exp-act'][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hat-model vs Hat-baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  1.0927091165738902 1.1202387881227938\n",
      "Distribution is not normal, so using wilcoxon\n",
      "WilcoxonResult(statistic=56992.0, pvalue=0.21001154986849457)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_baseline_mse = [mean_squared_error([x[0]], [x[1]], squared=False) for x in zip(true_labels, hat_baseline_model_preds)]\n",
    "hat_model_mse    = [mean_squared_error([x[0]], [x[1]], squared=False) for x in zip(true_labels, hat_exp_encoder_model_preds)]\n",
    "print('MSE: ', np.mean(hat_model_mse), np.mean(hat_baseline_mse))\n",
    "check_sig(hat_baseline_mse, hat_model_mse, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 1.0927091165738902 1.1202387881227938\n",
      "Distribution is not normal, so using wilcoxon\n",
      "WilcoxonResult(statistic=56992.0, pvalue=0.21001154986849457)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_baseline_mae = [mean_absolute_error([x[0]], [x[1]]) for x in zip(true_labels, hat_baseline_model_preds)]\n",
    "hat_model_mae    = [mean_absolute_error([x[0]], [x[1]]) for x in zip(true_labels, hat_exp_encoder_model_preds)]\n",
    "print('MAE', np.mean(hat_model_mae), np.mean(hat_baseline_mae))\n",
    "check_sig(hat_baseline_mae, hat_model_mae, alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Longformer-model vs longformer-baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9753592260644574 1.0142662260976543\n",
      "Distribution is not normal, so using wilcoxon\n",
      "WilcoxonResult(statistic=58251.0, pvalue=0.10788680833178338)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longformer_baseline_mse = [mean_squared_error([x[0]], [x[1]], squared=False) for x in zip(true_labels, longformer_baseline_model_preds)]\n",
    "longformer_model_mse    = [mean_squared_error([x[0]], [x[1]], squared=False) for x in zip(true_labels, longformer_exp_encoder_model_preds)]\n",
    "print(np.mean(longformer_model_mse), np.mean(longformer_baseline_mse))\n",
    "check_sig(longformer_baseline_mse, longformer_model_mse, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9753592260644574 1.0142662260976543\n",
      "Distribution is not normal, so using wilcoxon\n",
      "WilcoxonResult(statistic=58251.0, pvalue=0.10788680833178338)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longformer_baseline_mae = [mean_absolute_error([x[0]], [x[1]]) for x in zip(true_labels, longformer_baseline_model_preds)]\n",
    "longformer_model_mae    = [mean_absolute_error([x[0]], [x[1]]) for x in zip(true_labels, longformer_exp_encoder_model_preds)]\n",
    "print(np.mean(longformer_model_mae), np.mean(longformer_baseline_mae))\n",
    "check_sig(longformer_baseline_mae, longformer_model_mae, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
